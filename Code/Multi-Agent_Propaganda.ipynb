{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexible Multi-Agent Propaganda Detection System\n",
    "\n",
    "## Core Features\n",
    "\n",
    "### ‚ú® Feature1: Automatically discover languages and techniques\n",
    "- Add a new language by creating a folder\n",
    "- Add a new technique by adding a file\n",
    "- Zero code changes\n",
    "\n",
    "### ‚ú® Feature2: Automatically append output-format instructions\n",
    "- Prompt files only need the technique description\n",
    "- The system automatically appends output-format requirements (by language)\n",
    "- Supports multi-language instructions (Russian, Polish, English, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from typing import List, Dict, Optional, Set, Tuple\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from ollama import Client\n",
    "\n",
    "from typing import Dict, List, Union\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# AutoGen imports\n",
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "print(\"‚úì TODO: translate to EnglishÔºÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Define data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TechniquePrompt:\n",
    "    \"\"\"Persuasion-technique prompt data structure\"\"\"\n",
    "    name: str                    # Technique name\n",
    "    language: str                # Language code\n",
    "    prompt_content: str          # Prompt content\n",
    "    file_path: str              # TODO: translate to English\n",
    "    category: Optional[str] = None  # TODO: translate to English\n",
    "\n",
    "print(\"‚úì TODO: translate to EnglishÔºÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Create a flexible prompt loader\n",
    "\n",
    "This loader automatically discovers all languages and techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FlexiblePromptLoaderTODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "class FlexiblePromptLoader:\n",
    "    \"\"\"TODO: translate to English - Automatically discover languages and techniques\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dir: str,\n",
    "        languages: Optional[List[str]] = None,\n",
    "        techniques: Optional[List[str]] = None,\n",
    "        exclude_languages: Optional[List[str]] = None,\n",
    "        exclude_techniques: Optional[List[str]] = None,\n",
    "        config_file: Optional[str] = None,\n",
    "        prompt_file_suffix: str = \"_prompt.md\",\n",
    "        verbose: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            base_dir: TODO: translate to English\n",
    "            languages: TODO: translate to EnglishÔºàNoneTODO: translate to EnglishÔºâ\n",
    "            techniques: TODO: translate to EnglishÔºàNoneTODO: translate to EnglishÔºâ\n",
    "            exclude_languages: TODO: translate to EnglishExcludeTODO: translate to English\n",
    "            exclude_techniques: TODO: translate to EnglishExcludeTODO: translate to English\n",
    "            config_file: TODO: translate to English\n",
    "            prompt_file_suffix: TODO: translate to English\n",
    "            verbose: TODO: translate to English\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.prompt_file_suffix = prompt_file_suffix\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # TODO: translate to EnglishÔºåTODO: translate to English\n",
    "        if config_file and os.path.exists(config_file):\n",
    "            self._load_from_config(config_file)\n",
    "        else:\n",
    "            self.specified_languages = languages\n",
    "            self.specified_techniques = techniques\n",
    "            self.exclude_languages = exclude_languages or []\n",
    "            self.exclude_techniques = exclude_techniques or []\n",
    "        \n",
    "        if not os.path.exists(base_dir):\n",
    "            raise FileNotFoundError(f\"TODO: translate to English: {base_dir}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        self.prompts = {}  # {(technique, language): TechniquePrompt}\n",
    "        self.discovered_languages = set()\n",
    "        self.discovered_techniques = set()\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        self._discover_and_load()\n",
    "    \n",
    "    def _load_from_config(self, config_file: str):\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        self.specified_languages = config.get('languages')\n",
    "        self.specified_techniques = config.get('techniques')\n",
    "        self.exclude_languages = config.get('exclude_languages', [])\n",
    "        self.exclude_techniques = config.get('exclude_techniques', [])\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"‚úì TODO: translate to English: {config_file}\")\n",
    "    \n",
    "    def _discover_languages(self) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        languages = []\n",
    "        for item in os.listdir(self.base_dir):\n",
    "            item_path = os.path.join(self.base_dir, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                # TODO: translate to English\n",
    "                prompt_files = glob.glob(\n",
    "                    os.path.join(item_path, f\"*{self.prompt_file_suffix}\")\n",
    "                )\n",
    "                if prompt_files:\n",
    "                    languages.append(item.lower())\n",
    "        return sorted(languages)\n",
    "    \n",
    "    def _discover_techniques_for_language(self, language: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        techniques = []\n",
    "        lang_dir = os.path.join(self.base_dir, language)\n",
    "        \n",
    "        if not os.path.exists(lang_dir):\n",
    "            return []\n",
    "        \n",
    "        pattern = os.path.join(lang_dir, f\"*{self.prompt_file_suffix}\")\n",
    "        prompt_files = glob.glob(pattern)\n",
    "        \n",
    "        for filepath in prompt_files:\n",
    "            filename = os.path.basename(filepath)\n",
    "            technique_name = filename[:-len(self.prompt_file_suffix)]\n",
    "            techniques.append(technique_name)\n",
    "        \n",
    "        return sorted(techniques)\n",
    "    \n",
    "    def _should_include_language(self, language: str) -> bool:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if language in self.exclude_languages:\n",
    "            return False\n",
    "        if self.specified_languages is not None:\n",
    "            return language in self.specified_languages\n",
    "        return True\n",
    "    \n",
    "    def _should_include_technique(self, technique: str) -> bool:\n",
    "        \"\"\"TODO: translate to Englishtechnique(s)\"\"\"\n",
    "        if technique in self.exclude_techniques:\n",
    "            return False\n",
    "        if self.specified_techniques is not None:\n",
    "            return technique in self.specified_techniques\n",
    "        return True\n",
    "    \n",
    "    def _discover_and_load(self):\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"üîç TODO: translate to English\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"TODO: translate to English: {self.base_dir}\")\n",
    "            print(f\"TODO: translate to English: {self.prompt_file_suffix}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        all_languages = self._discover_languages()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\nüìÇ TODO: translate to English: {', '.join(all_languages) if all_languages else 'TODO: translate to English'}\")\n",
    "        \n",
    "        if not all_languages:\n",
    "            print(\"‚ö†Ô∏è TODO: translate to English: TODO: translate to EnglishÔºÅ\")\n",
    "            return\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        languages_to_load = [\n",
    "            lang for lang in all_languages \n",
    "            if self._should_include_language(lang)\n",
    "        ]\n",
    "        \n",
    "        if self.verbose and languages_to_load:\n",
    "            print(f\"‚úì TODO: translate to English: {', '.join(languages_to_load)}\")\n",
    "            if set(all_languages) - set(languages_to_load):\n",
    "                excluded = set(all_languages) - set(languages_to_load)\n",
    "                print(f\"‚äò ExcludeTODO: translate to English: {', '.join(excluded)}\")\n",
    "        \n",
    "        loaded_count = 0\n",
    "        total_techniques_set = set()\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        for language in languages_to_load:\n",
    "            if self.verbose:\n",
    "                print(f\"\\nüìÅ TODO: translate to English: {language.upper()}\")\n",
    "            \n",
    "            all_techniques = self._discover_techniques_for_language(language)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"  TODO: translate to English {len(all_techniques)} technique(s)TODO: translate to English\")\n",
    "            \n",
    "            techniques_to_load = [\n",
    "                tech for tech in all_techniques\n",
    "                if self._should_include_technique(tech)\n",
    "            ]\n",
    "            \n",
    "            if self.verbose and techniques_to_load:\n",
    "                print(f\"  TODO: translate to English {len(techniques_to_load)} technique(s)\")\n",
    "                if set(all_techniques) - set(techniques_to_load):\n",
    "                    excluded_count = len(set(all_techniques) - set(techniques_to_load))\n",
    "                    print(f\"  Exclude {excluded_count} technique(s)\")\n",
    "            \n",
    "            # TODO: translate to Englishtechnique(s)TODO: translate to English\n",
    "            for technique in techniques_to_load:\n",
    "                filename = f\"{technique}{self.prompt_file_suffix}\"\n",
    "                filepath = os.path.join(self.base_dir, language, filename)\n",
    "                \n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read().strip()\n",
    "                    \n",
    "                    if content:\n",
    "                        self.prompts[(technique, language)] = TechniquePrompt(\n",
    "                            name=technique,\n",
    "                            language=language,\n",
    "                            prompt_content=content,\n",
    "                            file_path=filepath\n",
    "                        )\n",
    "                        loaded_count += 1\n",
    "                        total_techniques_set.add(technique)\n",
    "                        self.discovered_languages.add(language)\n",
    "                        self.discovered_techniques.add(technique)\n",
    "                    else:\n",
    "                        if self.verbose:\n",
    "                            print(f\"  ‚ö†Ô∏è Skip empty file: {filename}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    if self.verbose:\n",
    "                        print(f\"  ‚úó Read failed {filename}: {e}\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"üìä TODO: translate to English\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"‚úì TODO: translate to English: {len(self.discovered_languages)}\")\n",
    "            print(f\"  {', '.join(sorted(self.discovered_languages))}\")\n",
    "            print(f\"\\n‚úì TODO: translate to English: {len(total_techniques_set)}\")\n",
    "            techniques_list = sorted(total_techniques_set)\n",
    "            for i in range(0, len(techniques_list), 3):\n",
    "                batch = techniques_list[i:i+3]\n",
    "                print(f\"  {', '.join(batch)}\")\n",
    "            print(f\"\\n‚úì TODO: translate to English: {loaded_count} TODO: translate to English\")\n",
    "            print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def get_prompt(self, technique: str, language: str) -> Optional[TechniquePrompt]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return self.prompts.get((technique, language))\n",
    "    \n",
    "    def get_available_techniques(self, language: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return sorted([\n",
    "            tech for (tech, lang) in self.prompts \n",
    "            if lang == language\n",
    "        ])\n",
    "    \n",
    "    def get_all_techniques(self) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return sorted(list(self.discovered_techniques))\n",
    "    \n",
    "    def get_languages(self) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return sorted(list(self.discovered_languages))\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        stats = {\n",
    "            'total_prompts': len(self.prompts),\n",
    "            'total_languages': len(self.discovered_languages),\n",
    "            'total_techniques': len(self.discovered_techniques),\n",
    "            'languages': sorted(list(self.discovered_languages)),\n",
    "            'techniques': sorted(list(self.discovered_techniques)),\n",
    "            'coverage': {}\n",
    "        }\n",
    "        \n",
    "        for lang in self.discovered_languages:\n",
    "            stats['coverage'][lang] = len(self.get_available_techniques(lang))\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def save_config(self, output_path: str):\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        config = {\n",
    "            'base_dir': self.base_dir,\n",
    "            'languages': sorted(list(self.discovered_languages)),\n",
    "            'techniques': sorted(list(self.discovered_techniques)),\n",
    "            'prompt_file_suffix': self.prompt_file_suffix,\n",
    "            'stats': self.get_stats()\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"‚úì TODO: translate to English: {output_path}\")\n",
    "\n",
    "print(\"‚úì FlexiblePromptLoaderTODO: translate to EnglishÔºÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Create a flexible multi-agent system\n",
    "\n",
    "**Key point**: This class automatically appends output-format instructions to promptsÔºÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FlexibleTechniqueAgentSystemTODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "class FlexibleTechniqueAgentSystem:\n",
    "    \"\"\"\n",
    "    TODO: translate to English Multi-Agent TODO: translate to English\n",
    "    \n",
    "    Core Features:\n",
    "    1. TODO: translate to English\n",
    "    2. TODO: translate to English\n",
    "    3. TODO: translate to EnglishÔºàRussian/Polish/EnglishÔºâ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        prompt_loader,\n",
    "        language: str,\n",
    "        api_key: str,\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0,\n",
    "        use_ollama: bool = False,\n",
    "        ollama_host: str = \"https://ollama-ui.pagoda.liris.cnrs.fr/ollama\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishMulti-AgentTODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            prompt_loader: TODO: translate to English\n",
    "            language: TODO: translate to English\n",
    "            api_key: OpenAI APITODO: translate to English\n",
    "            model: TODO: translate to English\n",
    "            temperature: TODO: translate to English\n",
    "            use_ollama: TODO: translate to EnglishOllama\n",
    "            ollama_host: OllamaTODO: translate to English\n",
    "        \"\"\"\n",
    "        self.prompt_loader = prompt_loader\n",
    "        self.language = language.lower()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.use_ollama = use_ollama\n",
    "        self.ollama_host = ollama_host\n",
    "        \n",
    "        # ‚úÖ TODO: translate to English4TODO: translate to EnglishÔºàTODO: translate to English __init__ TODO: translate to EnglishÔºâ\n",
    "        # TODO: translate to EnglishLLM\n",
    "        if use_ollama:\n",
    "            # OllamaTODO: translate to English\n",
    "            self.ollama_client = Client(\n",
    "                host=ollama_host,\n",
    "                headers={'Authorization': f'Bearer {api_key}'}\n",
    "            )\n",
    "            self.llm_config = None\n",
    "            self.api_key = api_key\n",
    "            print(f\"üîå TODO: translate to EnglishOllamaTODO: translate to English: {model}\")\n",
    "            print(f\"üåê TODO: translate to English: {ollama_host}\")\n",
    "        else:\n",
    "            # OpenAITODO: translate to English\n",
    "            self.llm_config = {\n",
    "                \"model\": model,\n",
    "                \"api_key\": api_key,\n",
    "                \"temperature\": temperature\n",
    "            }\n",
    "            self.ollama_client = None\n",
    "            print(f\"üîå TODO: translate to EnglishOpenAITODO: translate to English: {model}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        available_techniques = self.prompt_loader.get_available_techniques(self.language)\n",
    "        \n",
    "        if not available_techniques:\n",
    "            raise ValueError(\n",
    "                f\"TODO: translate to English '{self.language}' TODO: translate to EnglishÔºÅ\\n\"\n",
    "                f\"TODO: translate to English: {', '.join(self.prompt_loader.get_languages())}\"\n",
    "            )\n",
    "        \n",
    "        self.techniques = available_techniques\n",
    "        \n",
    "        print(f\"\\nüöÄ TODO: translate to English {len(self.techniques)} technique(s)TODO: translate to EnglishAgentTODO: translate to English\")\n",
    "        print(f\"TODO: translate to English: {self.language.upper()}\")\n",
    "        print(f\"TODO: translate to English: {model}\")\n",
    "        \n",
    "        # TODO: translate to Englishagents\n",
    "        self.agents = {}\n",
    "        self._initialize_agents()\n",
    "        \n",
    "        print(f\"‚úì TODO: translate to EnglishagentsTODO: translate to EnglishÔºÅ\\n\")\n",
    "\n",
    "    # ====================\n",
    "    # TODO: translate to EnglishÔºåTODO: translate to EnglishÔºåTODO: translate to English\n",
    "    # ====================\n",
    "    # def _get_output_instruction(self, technique_name: str) -> str:\n",
    "    #     \"\"\"\n",
    "    #     TODO: translate to EnglishÔºàEnglishTODO: translate to EnglishÔºâ\n",
    "        \n",
    "    #     Args:\n",
    "    #         technique_name: Technique name\n",
    "        \n",
    "    #     Returns:\n",
    "    #         TODO: translate to English\n",
    "    #     \"\"\"\n",
    "    #     return f\"\"\"\n",
    "    # {'='*70}\n",
    "    # CRITICAL OUTPUT INSTRUCTIONS:\n",
    "    # {'='*70}\n",
    "\n",
    "    # Your ONLY task is to determine if the technique \"{technique_name}\" is present in the given text.\n",
    "\n",
    "    # RESPONSE FORMAT (STRICT):\n",
    "    # 1. You MUST respond with ONLY '1' or '0'\n",
    "    # 2. '1' = technique \"{technique_name}\" IS present in the text\n",
    "    # 3. '0' = technique \"{technique_name}\" IS NOT present in the text\n",
    "    # 4. NO explanations, NO justifications, NO additional text whatsoever\n",
    "    # 5. If uncertain, respond with '0'\n",
    "\n",
    "    # Your response must be exactly one character: either '1' or '0'.\n",
    "\n",
    "    # EXAMPLES OF CORRECT RESPONSES:\n",
    "    # - 1\n",
    "    # - 0\n",
    "\n",
    "    # EXAMPLES OF INCORRECT RESPONSES:\n",
    "    # - 1 (technique is present)  ‚Üê DO NOT add explanations\n",
    "    # - Yes, it's present  ‚Üê ONLY '1' or '0'\n",
    "    # - 0, because...  ‚Üê DO NOT add justification\n",
    "\n",
    "    # RESPOND WITH ONLY '1' OR '0':\n",
    "    # \"\"\"\n",
    "\n",
    "    def _get_output_instruction(self, technique_name: str) -> str:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return f\"\"\"\n",
    "    {'='*70}\n",
    "    CRITICAL OUTPUT INSTRUCTIONS:\n",
    "    {'='*70}\n",
    "\n",
    "    Your task is to determine if the technique \"{technique_name}\" is CLEARLY and SIGNIFICANTLY present in the TARGET PARAGRAPH.\n",
    "\n",
    "    STRICT EVALUATION CRITERIA:\n",
    "    1. The technique must be EXPLICIT and OBVIOUS in the target paragraph\n",
    "    2. There must be CLEAR EVIDENCE, not just vague similarities\n",
    "    3. The technique must be CENTRAL to the paragraph's message, not just tangentially related\n",
    "    4. When in doubt or if the evidence is weak, respond with '0'\n",
    "    5. Only respond '1' if you are HIGHLY CONFIDENT the technique is present\n",
    "\n",
    "    RESPONSE FORMAT:\n",
    "    - '1' = technique \"{technique_name}\" is CLEARLY and SIGNIFICANTLY present\n",
    "    - '0' = technique is absent OR evidence is weak/uncertain\n",
    "\n",
    "    Be CONSERVATIVE in your judgment. It's better to miss a technique than to falsely detect one.\n",
    "\n",
    "    Your response must be exactly one character: either '1' or '0'.\n",
    "\n",
    "    RESPOND WITH ONLY '1' OR '0':\n",
    "    \"\"\"\n",
    "    \n",
    "    def _create_agent_system_prompt(self, technique_name: str) -> str:\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishagentTODO: translate to English\n",
    "        \n",
    "        TODO: translate to English:\n",
    "        1. TODO: translate to English\n",
    "        2. TODO: translate to English\n",
    "        3. TODO: translate to English\n",
    "        \n",
    "        TODO: translate to EnglishÔºåTODO: translate to EnglishÔºÅ\n",
    "        \n",
    "        Args:\n",
    "            technique_name: Technique name\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to EnglishÔºàTODO: translate to English + TODO: translate to EnglishÔºâ\n",
    "        \"\"\"\n",
    "        # 1. TODO: translate to English\n",
    "        technique_prompt = self.prompt_loader.get_prompt(technique_name, self.language)\n",
    "        \n",
    "        if not technique_prompt:\n",
    "            raise ValueError(\n",
    "                f\"TODO: translate to English {technique_name} TODO: translate to English {self.language} TODO: translate to English\"\n",
    "            )\n",
    "        \n",
    "        # 2. TODO: translate to EnglishPrompt contentÔºàTODO: translate to EnglishÔºâ\n",
    "        original_content = technique_prompt.prompt_content\n",
    "        \n",
    "        # 3. TODO: translate to English\n",
    "        output_instruction = self._get_output_instruction(technique_name)\n",
    "        \n",
    "        # 4. TODO: translate to English\n",
    "        # TODO: translate to English + TODO: translate to English + TODO: translate to English\n",
    "        full_prompt = f\"\"\"{original_content}\n",
    "\n",
    "{output_instruction}\"\"\"\n",
    "        \n",
    "        return full_prompt\n",
    "    \n",
    "    def _initialize_agents(self):\n",
    "        \"\"\"TODO: translate to Englishagents\"\"\"\n",
    "        for technique in self.techniques:\n",
    "            # TODO: translate to EnglishÔºàAutomatically append output-format instructionsÔºâ\n",
    "            system_message = self._create_agent_system_prompt(technique)\n",
    "            if self.use_ollama:\n",
    "                # TODO: translate to EnglishOllamaÔºåTODO: translate to EnglishAutoGen agent\n",
    "                # TODO: translate to Englishsystem messageTODO: translate to English\n",
    "                self.agents[technique] = {\n",
    "                    'system_message': system_message,\n",
    "                    'type': 'ollama'\n",
    "                }\n",
    "            else:\n",
    "                # Create a standard AutoGen agent\n",
    "                agent = ConversableAgent(\n",
    "                    name=f\"{technique}_agent\",\n",
    "                    system_message=system_message,\n",
    "                    llm_config=self.llm_config,\n",
    "                    human_input_mode=\"NEVER\",\n",
    "                    max_consecutive_auto_reply=1\n",
    "                )\n",
    "                self.agents[technique] = agent\n",
    "    \n",
    "    def classify_text(self, text: str, verbose: bool = False) -> Tuple[List[str], Dict]:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            text: TODO: translate to English\n",
    "            verbose: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            (detected_techniques, chat_history)\n",
    "            - detected_techniques: DetectedTODO: translate to English\n",
    "            - chat_history: TODO: translate to English\n",
    "        \"\"\"\n",
    "        detected_techniques = []\n",
    "        chat_history = {}\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"TODO: translate to English ({len(self.techniques)} technique(s))\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, technique in enumerate(self.techniques, 1):\n",
    "            if verbose:\n",
    "                print(f\"[{i}/{len(self.techniques)}] TODO: translate to English: {technique}...\", end=\" \")\n",
    "            \n",
    "            try:\n",
    "                agent = self.agents[technique]\n",
    "\n",
    "                if self.use_ollama:\n",
    "                    system_message = agent['system_message']\n",
    "            \n",
    "                    response = self.ollama_client.chat(\n",
    "                        model=self.model,\n",
    "                        messages=[\n",
    "                            {'role': 'system', 'content': system_message},\n",
    "                            {'role': 'user', 'content': text}\n",
    "                        ]\n",
    "                    )\n",
    "                    # Extract Ollama response\n",
    "                    result = response['message']['content'].strip()\n",
    "                else:\n",
    "                    # Use an AutoGen agent\n",
    "                    response = agent.generate_reply(\n",
    "                        messages=[{\"role\": \"user\", \"content\": text}]\n",
    "                    )\n",
    "            \n",
    "                    # üîß Fix: handle None responses\n",
    "                    if response is None:\n",
    "                        # generate_replyTODO: translate to EnglishNoneÔºåTODO: translate to English\n",
    "                        result = '0'\n",
    "                        if verbose:\n",
    "                            print(\"‚ö†Ô∏è (AgentTODO: translate to EnglishNoneÔºåTODO: translate to English0) \", end=\"\")\n",
    "                    elif isinstance(response, str):\n",
    "                        result = response.strip()\n",
    "                    else:\n",
    "                        result = str(response).strip()\n",
    "                \n",
    "                # üîß TODO: translate to EnglishÔºöTODO: translate to English\n",
    "                # TODO: translate to English'0'/'1'ÔºåTODO: translate to English\n",
    "                result_clean = result.strip()\n",
    "                \n",
    "                # Save history\n",
    "                chat_history[technique] = {\n",
    "                    'response': result_clean,\n",
    "                    'detected': result_clean == '1'\n",
    "                }\n",
    "\n",
    "                # TODO: translate to EnglishDetected\n",
    "                if result_clean == '1':\n",
    "                    detected_techniques.append(technique)\n",
    "                    if verbose:\n",
    "                        print(\"‚úì Detected\")\n",
    "                elif result_clean == '0':\n",
    "                    if verbose:\n",
    "                        print(\"‚úó TODO: translate to EnglishDetected\")\n",
    "                else:\n",
    "                    # Response format is invalid; attempting to extract\n",
    "                    if '1' in result_clean and '0' not in result_clean:\n",
    "                        detected_techniques.append(technique)\n",
    "                        if verbose:\n",
    "                            print(f\"‚ö†Ô∏è Detected (TODO: translate to English: '{result_clean[:30]}')\")\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(f\"‚ö†Ô∏è TODO: translate to EnglishDetected (TODO: translate to English: '{result_clean[:30]}')\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"‚ùå Error: {e}\")\n",
    "                chat_history[technique] = {\n",
    "                    'response': None,\n",
    "                    'error': str(e),\n",
    "                    'detected': False\n",
    "                }\n",
    "                \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"TODO: translate to EnglishÔºÅDetected {len(detected_techniques)} technique(s)\")\n",
    "            if detected_techniques:\n",
    "                print(f\"DetectedTODO: translate to English: {', '.join(detected_techniques)}\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return detected_techniques, chat_history\n",
    "    def classify_batch(\n",
    "        self,\n",
    "        fragments: List[Dict],\n",
    "        text_key: str = 'text',\n",
    "        verbose: bool = True\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            fragments: TODO: translate to EnglishÔºåTODO: translate to English\n",
    "            text_key: TODO: translate to English\n",
    "            verbose: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to EnglishÔºåTODO: translate to English\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        total = len(fragments)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"TODO: translate to English: {total} TODO: translate to English\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, fragment in enumerate(fragments, 1):\n",
    "            if verbose:\n",
    "                print(f\"\\nTODO: translate to English {i}/{total}...\")\n",
    "            \n",
    "            text = fragment.get(text_key, '')\n",
    "            \n",
    "            if not text:\n",
    "                if verbose:\n",
    "                    print(\"  ‚ö†Ô∏è Skip empty text\")\n",
    "                results.append({\n",
    "                    **fragment,\n",
    "                    'detected_techniques': [],\n",
    "                    'chat_history': {},\n",
    "                    'error': 'Empty text'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                detected, history = self.classify_text(text, verbose=False)\n",
    "                \n",
    "                results.append({\n",
    "                    **fragment,\n",
    "                    'detected_techniques': detected,\n",
    "                    'chat_history': history\n",
    "                })\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Detected {len(detected)} technique(s)\")\n",
    "                    if detected:\n",
    "                        print(f\"    {', '.join(detected)}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Error: {e}\")\n",
    "                results.append({\n",
    "                    **fragment,\n",
    "                    'detected_techniques': [],\n",
    "                    'chat_history': {},\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"TODO: translate to EnglishÔºÅ\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úì FlexibleTechniqueAgentSystemTODO: translate to EnglishÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ContextAwareParagraphDetectorTODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step1: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class ContextAwareParagraphDetector:\n",
    "    \"\"\"\n",
    "    TODO: translate to Englishparagraph(s)TODO: translate to EnglishpropagandaTODO: translate to English\n",
    "    \n",
    "    Core Features:\n",
    "    - TODO: translate to Englishparagraph(s)\n",
    "    - TODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºåTODO: translate to English\n",
    "    - TODO: translate to Englishparagraph(s)ÔºåTODO: translate to EnglishLLMTODO: translate to Englishparagraph(s)\n",
    "    \"\"\"\n",
    "    \n",
    "# TODO: translate to EnglishÔºåTODO: translate to English __init__ TODO: translate to English\n",
    "\n",
    "    def __init__(self, agent_system, language: str = None):\n",
    "        self.agent_system = agent_system\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        if language is None and hasattr(agent_system, 'language'):\n",
    "            self.language = agent_system.language.lower()\n",
    "        else:\n",
    "            self.language = language.lower() if language else 'en'\n",
    "        \n",
    "        print(f\"‚úì TODO: translate to English (TODO: translate to English: {self.language.upper()})\")\n",
    "    \n",
    "    def split_into_paragraphs(self, text: str, min_length: int = None):\n",
    "        # TODO: translate to English\n",
    "        if min_length is None:\n",
    "            min_length = 1 if self.language == 'en' else 50\n",
    "\n",
    "        paragraphs = []\n",
    "\n",
    "        if self.language == 'en':\n",
    "            raw_paragraphs = text.split('\\n')  # EnglishÔºöTODO: translate to English\n",
    "        else:\n",
    "            raw_paragraphs = re.split(r'\\n\\s*\\n', text)  # TODO: translate to EnglishÔºöTODO: translate to English\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        current_pos = 0\n",
    "        # paragraph_id = 0\n",
    "        \n",
    "        for line_number, raw_para in enumerate(raw_paragraphs, start=1):\n",
    "            raw_para = raw_para.strip()\n",
    "            \n",
    "            # TODO: translate to Englishparagraph(s)\n",
    "\n",
    "            if len(raw_para) < min_length:\n",
    "                current_pos = text.find(raw_para, current_pos)\n",
    "                if current_pos != -1:\n",
    "                    current_pos += len(raw_para)\n",
    "                continue\n",
    "            \n",
    "            # TODO: translate to Englishparagraph(s)TODO: translate to EnglishPosition\n",
    "            start_pos = text.find(raw_para, current_pos)\n",
    "            if start_pos == -1:\n",
    "                continue\n",
    "            \n",
    "            end_pos = start_pos + len(raw_para) - 1\n",
    "            \n",
    "            # paragraph_id += 1\n",
    "            paragraphs.append({\n",
    "                'paragraph_id': line_number,\n",
    "                'start_pos': start_pos,\n",
    "                'end_pos': end_pos,\n",
    "                'text': raw_para,\n",
    "                'char_count': len(raw_para),\n",
    "                'word_count': len(raw_para.split())\n",
    "            })\n",
    "            \n",
    "            current_pos = end_pos + 1\n",
    "        \n",
    "        return paragraphs\n",
    "    \n",
    "    def create_context_prompt(\n",
    "        self, \n",
    "        full_article: str, \n",
    "        target_paragraph: str, \n",
    "        paragraph_id: int, \n",
    "        total_paragraphs: int\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        TODO: translate to Englishparagraph(s)ÔºåTODO: translate to EnglishLLMTODO: translate to Englishparagraph(s)\n",
    "        \n",
    "        Args:\n",
    "            full_article: TODO: translate to English\n",
    "            target_paragraph: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "            paragraph_id: paragraph(s)TODO: translate to English\n",
    "            total_paragraphs: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to English\n",
    "        \"\"\"\n",
    "        # TODO: translate to Englishparagraph(s)\n",
    "        marked_article = full_article.replace(\n",
    "            target_paragraph,\n",
    "            f\"\\n{'='*70}\\n>>> TARGET PARAGRAPH (paragraph(s) {paragraph_id}/{total_paragraphs}) <<<\\n{'='*70}\\n{target_paragraph}\\n{'='*70}\\n>>> END OF TARGET PARAGRAPH <<<\\n{'='*70}\\n\",\n",
    "            1  # TODO: translate to English\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"CONTEXT: You are analyzing paragraph {paragraph_id} out of {total_paragraphs} paragraphs in the following article.\n",
    "\n",
    "FULL ARTICLE (for context):\n",
    "{'‚îÄ'*70}\n",
    "{marked_article}\n",
    "{'‚îÄ'*70}\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. The article above is provided as CONTEXT to help you understand the overall narrative, tone, and argumentation strategy.\n",
    "2. Your task is to determine if the propaganda technique is present in the marked TARGET PARAGRAPH ONLY (between the === markers).\n",
    "3. You may use the full article context to better understand the TARGET PARAGRAPH, but you should ONLY evaluate whether the technique appears in the TARGET PARAGRAPH itself.\n",
    "4. Consider the context when making your judgment, but base your decision on the TARGET PARAGRAPH content.\n",
    "\n",
    "TARGET PARAGRAPH TO ANALYZE:\n",
    "{target_paragraph}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def detect_paragraph_with_context(\n",
    "        self,\n",
    "        full_article: str,\n",
    "        target_paragraph: str,\n",
    "        paragraph_id: int,\n",
    "        total_paragraphs: int,\n",
    "        verbose: bool = False\n",
    "    ) -> Tuple[List[str], Dict]:\n",
    "        \"\"\"\n",
    "        TODO: translate to Englishparagraph(s)\n",
    "        \n",
    "        Args:\n",
    "            full_article: TODO: translate to English\n",
    "            target_paragraph: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "            paragraph_id: paragraph(s)TODO: translate to English\n",
    "            total_paragraphs: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "            verbose: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            (detected_techniques, responses)\n",
    "        \"\"\"\n",
    "        # TODO: translate to English\n",
    "        context_prompt = self.create_context_prompt(\n",
    "            full_article, \n",
    "            target_paragraph, \n",
    "            paragraph_id, \n",
    "            total_paragraphs\n",
    "        )\n",
    "        \n",
    "        # TODO: translate to EnglishagentTODO: translate to English\n",
    "        detected, responses = self.agent_system.classify_text(\n",
    "            context_prompt,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        return detected, responses\n",
    "    \n",
    "    def detect_article_by_paragraphs(\n",
    "        self, \n",
    "        article_id: str,\n",
    "        full_text: str,\n",
    "        min_paragraph_length: int = 50,\n",
    "        verbose: bool = True\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        TODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "        \n",
    "        Args:\n",
    "            article_id: TODO: translate to EnglishIDÔºàTODO: translate to EnglishÔºâ\n",
    "            full_text: TODO: translate to English\n",
    "            min_paragraph_length: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "            verbose: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to EnglishÔºåTODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"üìÑ TODO: translate to English: {article_id}\")\n",
    "            print(f\"{'='*70}\")\n",
    "        \n",
    "        # 1. TODO: translate to Englishparagraph(s)\n",
    "        paragraphs = self.split_into_paragraphs(full_text, min_paragraph_length)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üìä TODO: translate to English:\")\n",
    "            print(f\"  - TODO: translate to English: {len(full_text):,}\")\n",
    "            print(f\"  - paragraph(s)TODO: translate to English: {len(paragraphs)}\")\n",
    "            if paragraphs:\n",
    "                avg_para_len = sum(p['char_count'] for p in paragraphs) / len(paragraphs)\n",
    "                print(f\"  - TODO: translate to Englishparagraph(s)TODO: translate to English: {avg_para_len:.0f} TODO: translate to English\")\n",
    "            print(f\"\\nüîç TODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºàTODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºâ...\")\n",
    "        \n",
    "        # 2. TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "        results = []\n",
    "        total_paragraphs = len(paragraphs)\n",
    "        \n",
    "        for i, para in enumerate(paragraphs, 1):\n",
    "            if verbose:\n",
    "                print(f\"\\n{'‚îÄ'*70}\")\n",
    "                print(f\"[paragraph(s) {i}/{total_paragraphs}]\")\n",
    "                print(f\"  Position: {para['start_pos']}-{para['end_pos']}\")\n",
    "                print(f\"  TODO: translate to English: {para['char_count']} TODO: translate to English\")\n",
    "                print(f\"  TODO: translate to English: {para['text'][:100]}...\")\n",
    "            \n",
    "            # TODO: translate to Englishparagraph(s)\n",
    "            detected, responses = self.detect_paragraph_with_context(\n",
    "                full_article=full_text,\n",
    "                target_paragraph=para['text'],\n",
    "                paragraph_id=para['paragraph_id'],\n",
    "                total_paragraphs=total_paragraphs,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            result = {\n",
    "                'article_id': article_id,\n",
    "                'paragraph_id': para['paragraph_id'],\n",
    "                'start_pos': para['start_pos'],\n",
    "                'end_pos': para['end_pos'],\n",
    "                'char_count': para['char_count'],\n",
    "                'detected_techniques': detected,\n",
    "                'num_techniques': len(detected),\n",
    "                'text': para['text'],  # TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "                'text_preview': para['text'][:150]\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            if verbose:\n",
    "                if detected:\n",
    "                    print(f\"  ‚úì Detected {len(detected)} technique(s):\")\n",
    "                    for tech in detected:\n",
    "                        print(f\"    ‚Ä¢ {tech}\")\n",
    "                else:\n",
    "                    print(f\"  ‚óã TODO: translate to EnglishDetectedpropagandaTODO: translate to English\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"‚úÖ TODO: translate to English\")\n",
    "            total_techniques = sum(r['num_techniques'] for r in results)\n",
    "            paras_with_tech = sum(1 for r in results if r['num_techniques'] > 0)\n",
    "            print(f\"  TODO: translate to Englishparagraph(s)TODO: translate to English: {len(results)}\")\n",
    "            print(f\"  TODO: translate to Englishparagraph(s): {paras_with_tech} ({paras_with_tech/len(results)*100:.1f}%)\")\n",
    "            print(f\"  TODO: translate to Englishtechnique instance(s)TODO: translate to English: {total_techniques}\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'total_paragraphs': len(paragraphs),\n",
    "            'full_text_length': len(full_text),\n",
    "            'full_text': full_text,  # TODO: translate to English\n",
    "            'paragraph_results': results\n",
    "        }\n",
    "    \n",
    "    def format_output_tsv(self, detection_result: Dict) -> List[str]:\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishTSVTODO: translate to English\n",
    "        TODO: translate to English: article_id    start_pos    end_pos    technique1    technique2    ...\n",
    "        \n",
    "        Args:\n",
    "            detection_result: detect_article_by_paragraphsTODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TSVTODO: translate to English\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        article_id = detection_result['article_id']\n",
    "        \n",
    "        for para_result in detection_result['paragraph_results']:\n",
    "            # TODO: translate to EnglishDetectedTODO: translate to Englishparagraph(s)\n",
    "            if para_result['detected_techniques']:\n",
    "                techniques_str = '\\t'.join(para_result['detected_techniques'])\n",
    "                line = f\"{article_id}\\t{para_result['start_pos']}\\t{para_result['end_pos']}\\t{techniques_str}\"\n",
    "                lines.append(line)\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    def save_results_tsv(self, detection_results: List[Dict], output_file: str):\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishTSVTODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            detection_results: TODO: translate to English\n",
    "            output_file: TODO: translate to English\n",
    "        \"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            # TODO: translate to English\n",
    "            f.write(\"article_id\\tstart_pos\\tend_pos\\ttechniques\\n\")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            for result in detection_results:\n",
    "                tsv_lines = self.format_output_tsv(result)\n",
    "                for line in tsv_lines:\n",
    "                    f.write(line + '\\n')\n",
    "        \n",
    "        print(f\"‚úì TSVTODO: translate to English: {output_file}\")\n",
    "    \n",
    "    def save_results_detailed(self, detection_results: List[Dict], output_file: str):\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishJSONTODO: translate to EnglishÔºàTODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºâ\n",
    "        \n",
    "        Args:\n",
    "            detection_results: TODO: translate to English\n",
    "            output_file: TODO: translate to English\n",
    "        \"\"\"\n",
    "        import json\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        total_articles = len(detection_results)\n",
    "        total_paragraphs = sum(r['total_paragraphs'] for r in detection_results)\n",
    "        total_paras_with_tech = sum(\n",
    "            sum(1 for pr in r['paragraph_results'] if pr['num_techniques'] > 0)\n",
    "            for r in detection_results\n",
    "        )\n",
    "        total_technique_instances = sum(\n",
    "            sum(pr['num_techniques'] for pr in r['paragraph_results'])\n",
    "            for r in detection_results\n",
    "        )\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        technique_counter = {}\n",
    "        for result in detection_results:\n",
    "            for para_result in result['paragraph_results']:\n",
    "                for tech in para_result['detected_techniques']:\n",
    "                    technique_counter[tech] = technique_counter.get(tech, 0) + 1\n",
    "        \n",
    "        sorted_techniques = sorted(technique_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        output_data = {\n",
    "            'summary': {\n",
    "                'total_articles': total_articles,\n",
    "                'total_paragraphs': total_paragraphs,\n",
    "                'paragraphs_with_techniques': total_paras_with_tech,\n",
    "                'paragraphs_with_techniques_percentage': (total_paras_with_tech/total_paragraphs*100) if total_paragraphs > 0 else 0,\n",
    "                'total_technique_instances': total_technique_instances,\n",
    "                'avg_techniques_per_paragraph': total_technique_instances/total_paragraphs if total_paragraphs > 0 else 0,\n",
    "                'technique_frequency': dict(sorted_techniques)\n",
    "            },\n",
    "            'detection_method': 'context-aware paragraph detection',\n",
    "            'note': 'Each paragraph was analyzed with full article context',\n",
    "            'articles': detection_results\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"‚úì TODO: translate to EnglishJSONTODO: translate to English: {output_file}\")\n",
    "\n",
    "print(\"‚úì ContextAwareParagraphDetectorTODO: translate to EnglishÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì VotingContextAwareParagraphDetector TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TODO: translate to EnglishContextAwareParagraphDetectorTODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "class VotingContextAwareParagraphDetector(ContextAwareParagraphDetector):\n",
    "    \"\"\"\n",
    "    TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        agent_system: FlexibleTechniqueAgentSystem,\n",
    "        voting_rounds: int = 3,\n",
    "        voting_threshold: float = 0.6,\n",
    "        use_temperature: bool = True,\n",
    "        temperature: float = 0.3\n",
    "    ):\n",
    "        super().__init__(agent_system)\n",
    "        self.voting_rounds = voting_rounds\n",
    "        self.voting_threshold = voting_threshold\n",
    "        self.use_temperature = use_temperature\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if use_temperature:\n",
    "            self.original_temperature = agent_system.temperature\n",
    "            agent_system.temperature = temperature\n",
    "    \n",
    "    def detect_paragraph_with_voting(\n",
    "        self,\n",
    "        full_article: str,\n",
    "        target_paragraph: str,\n",
    "        paragraph_id: int,\n",
    "        total_paragraphs: int,\n",
    "        verbose: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"TODO: translate to Englishparagraph(s)\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\nüó≥Ô∏è  TODO: translate to English ({self.voting_rounds}TODO: translate to English)...\")\n",
    "        \n",
    "        all_round_results = []\n",
    "        technique_vote_counts = Counter()\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        for round_num in range(self.voting_rounds):\n",
    "            if verbose:\n",
    "                print(f\"  TODO: translate to English {round_num + 1}/{self.voting_rounds}...\", end=\" \")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            detected_techniques, _ = self.detect_paragraph_with_context(\n",
    "                full_article=full_article,\n",
    "                target_paragraph=target_paragraph,\n",
    "                paragraph_id=paragraph_id,\n",
    "                total_paragraphs=total_paragraphs,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            all_round_results.append(detected_techniques)\n",
    "            \n",
    "            for tech in detected_techniques:\n",
    "                technique_vote_counts[tech] += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Detected {len(detected_techniques)} technique(s)\")\n",
    "            \n",
    "            if round_num < self.voting_rounds - 1:\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        min_votes = int(self.voting_rounds * self.voting_threshold)\n",
    "        final_techniques = [\n",
    "            tech for tech, count in technique_vote_counts.items()\n",
    "            if count >= min_votes\n",
    "        ]\n",
    "        \n",
    "        final_techniques.sort(\n",
    "            key=lambda t: technique_vote_counts[t],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        if verbose and final_techniques:\n",
    "            print(f\"\\n  üìä TODO: translate to English:\")\n",
    "            print(f\"     TODO: translate to English: {min_votes}/{self.voting_rounds} TODO: translate to English\")\n",
    "            print(f\"     TODO: translate to English: {len(final_techniques)}\")\n",
    "            for tech in final_techniques:\n",
    "                votes = technique_vote_counts[tech]\n",
    "                print(f\"       ‚Ä¢ {tech}: {votes}/{self.voting_rounds} TODO: translate to English ({votes/self.voting_rounds:.0%})\")\n",
    "        \n",
    "        return {\n",
    "            'detected_techniques': final_techniques,\n",
    "            'num_techniques': len(final_techniques),\n",
    "            'voting_details': {\n",
    "                'rounds': self.voting_rounds,\n",
    "                'threshold': self.voting_threshold,\n",
    "                'all_round_results': all_round_results,\n",
    "                'vote_counts': dict(technique_vote_counts),\n",
    "                'passed_techniques': final_techniques\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def detect_article_by_paragraphs(\n",
    "        self,\n",
    "        article_id: str,\n",
    "        full_text: str,\n",
    "        min_paragraph_length: int = 50,\n",
    "        verbose: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"üìÑ TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ: {article_id}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"‚öôÔ∏è  TODO: translate to English:\")\n",
    "            print(f\"   - TODO: translate to English: {self.voting_rounds}\")\n",
    "            print(f\"   - TODO: translate to English: {self.voting_threshold} ({int(self.voting_rounds * self.voting_threshold)}/{self.voting_rounds}TODO: translate to English)\")\n",
    "            if self.use_temperature:\n",
    "                print(f\"   - TODO: translate to English: {self.temperature}\")\n",
    "        \n",
    "        # TODO: translate to Englishparagraph(s)\n",
    "        paragraphs = self.split_into_paragraphs(full_text, min_paragraph_length)\n",
    "        total_paragraphs = len(paragraphs)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üìä TODO: translate to English:\")\n",
    "            print(f\"  - TODO: translate to English: {len(full_text):,}\")\n",
    "            print(f\"  - paragraph(s)TODO: translate to English: {total_paragraphs}\")\n",
    "            if paragraphs:\n",
    "                avg_len = sum(p['char_count'] for p in paragraphs) // total_paragraphs\n",
    "                print(f\"  - TODO: translate to Englishparagraph(s)TODO: translate to English: {avg_len} TODO: translate to English\")\n",
    "            print(f\"\\nüîç TODO: translate to Englishparagraph(s)TODO: translate to English...\")\n",
    "        \n",
    "        paragraph_results = []\n",
    "        \n",
    "        for i, para_info in enumerate(paragraphs, 1):\n",
    "            if verbose:\n",
    "                print(f\"\\n{'‚îÄ'*70}\")\n",
    "                print(f\"[paragraph(s) {i}/{total_paragraphs}]\")\n",
    "                print(f\"  Position: {para_info['start_pos']}-{para_info['end_pos']}\")\n",
    "                print(f\"  TODO: translate to English: {para_info['char_count']} TODO: translate to English\")\n",
    "                print(f\"  TODO: translate to English: {para_info['text'][:70]}...\")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            result = self.detect_paragraph_with_voting(\n",
    "                full_article=full_text,\n",
    "                target_paragraph=para_info['text'],\n",
    "                paragraph_id=para_info['paragraph_id'],\n",
    "                total_paragraphs=total_paragraphs,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            # TODO: translate to EnglishPositionTODO: translate to English\n",
    "            result['article_id'] = article_id\n",
    "            result['start_pos'] = para_info['start_pos']\n",
    "            result['end_pos'] = para_info['end_pos']\n",
    "            result['paragraph_text'] = para_info['text']\n",
    "            \n",
    "            paragraph_results.append(result)\n",
    "            \n",
    "            if result['num_techniques'] > 0:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Final confirmation {result['num_techniques']} technique(s):\")\n",
    "                    for tech in result['detected_techniques']:\n",
    "                        votes = result['voting_details']['vote_counts'][tech]\n",
    "                        print(f\"    ‚Ä¢ {tech} ({votes}/{self.voting_rounds})\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚óã TODO: translate to EnglishDetectedpropagandaTODO: translate to English\")\n",
    "        \n",
    "        total_techniques = sum(r['num_techniques'] for r in paragraph_results)\n",
    "        paragraphs_with_techniques = sum(1 for r in paragraph_results if r['num_techniques'] > 0)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"‚úÖ TODO: translate to English\")\n",
    "            print(f\"  TODO: translate to Englishparagraph(s)TODO: translate to English: {len(paragraph_results)}\")\n",
    "            print(f\"  TODO: translate to Englishparagraph(s): {paragraphs_with_techniques} ({paragraphs_with_techniques/len(paragraph_results):.1%})\")\n",
    "            print(f\"  TODO: translate to Englishtechnique instance(s)TODO: translate to English: {total_techniques}\")\n",
    "            print(f\"{'='*70}\")\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'full_text': full_text,\n",
    "            'num_paragraphs': len(paragraph_results),\n",
    "            'paragraphs_with_techniques': paragraphs_with_techniques,\n",
    "            'total_techniques': total_techniques,\n",
    "            'paragraph_results': paragraph_results,\n",
    "            'voting_config': {\n",
    "                'rounds': self.voting_rounds,\n",
    "                'threshold': self.voting_threshold,\n",
    "                'temperature': self.temperature if self.use_temperature else 0.0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'use_temperature') and self.use_temperature:\n",
    "            if hasattr(self, 'original_temperature'):\n",
    "                self.agent_system.temperature = self.original_temperature\n",
    "\n",
    "\n",
    "print(\"‚úì VotingContextAwareParagraphDetector TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: TODO: translate to EnglishAPITODO: translate to English\n",
    "\n",
    "**TODO: translate to EnglishÔºÅ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: translate to EnglishAPITODO: translate to English...\n",
      "‚úì TODO: translate to EnglishOpenAITODO: translate to English\n",
      "  TODO: translate to English: gpt-4o-mini\n",
      "‚úì APITODO: translate to EnglishÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TODO: translate to English\n",
    "# ========================================\n",
    "\n",
    "# TODO: translate to English\n",
    "USE_OLLAMA = False  # True=Ollama, False=OpenAI\n",
    "\n",
    "# TODO: translate to English\n",
    "API_CONFIG_PATH = \"your_api_config_file_location\"\n",
    "PROMPTS_BASE_DIR = \"your_autogen_propaganda_analysis_results_directory\"\n",
    "# DATA_BASE_DIR = \"your_trial_annotated_directory\"\n",
    "DATA_CONFIGS = {\n",
    "    'checkthat_base': 'your_data_directory',\n",
    "    'train_base': 'your_all_original_articlestrain_version_directory',\n",
    "    'trial_base': 'your_trial_annotated_directory'  # TODO: translate to English\n",
    "}\n",
    "\n",
    "# TODO: translate to EnglishAPITODO: translate to English\n",
    "print(\"TODO: translate to EnglishAPITODO: translate to English...\")\n",
    "try:\n",
    "    with open(API_CONFIG_PATH, 'r') as f:\n",
    "        api_config = json.load(f)\n",
    "    \n",
    "    # ‚úÖ TODO: translate to English api_keys TODO: translate to English\n",
    "    api_keys = api_config.get('api_keys', {})\n",
    "    \n",
    "    if USE_OLLAMA:\n",
    "        # TODO: translate to EnglishOllama\n",
    "        api_key = api_keys.get('ollama_api_key')\n",
    "        \n",
    "        # TODO: translate to Englishollama_api_keyÔºåTODO: translate to Englishopenai_api_key\n",
    "        if not api_key:\n",
    "            api_key = api_keys.get('openai_api_key')\n",
    "            print(\"‚ö†Ô∏è TODO: translate to Englishollama_api_keyÔºåTODO: translate to Englishopenai_api_keyTODO: translate to English\")\n",
    "        \n",
    "        model = 'llama3:70b'  # TODO: translate to EnglishOllamaTODO: translate to English\n",
    "        print(\"‚úì TODO: translate to EnglishOllamaTODO: translate to English\")\n",
    "        print(f\"  TODO: translate to English: {model}\")\n",
    "    else:\n",
    "        # TODO: translate to EnglishOpenAI\n",
    "        api_key = api_keys.get('openai_api_key')\n",
    "        model = 'gpt-4o-mini'\n",
    "        print(\"‚úì TODO: translate to EnglishOpenAITODO: translate to English\")\n",
    "        print(f\"  TODO: translate to English: {model}\")\n",
    "    \n",
    "    if not api_key:\n",
    "        raise ValueError(f\"TODO: translate to English{'Ollama' if USE_OLLAMA else 'OpenAI'}TODO: translate to EnglishAPITODO: translate to EnglishÔºÅ\")\n",
    "    \n",
    "    print(\"‚úì APITODO: translate to EnglishÔºÅ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó TODO: translate to EnglishAPITODO: translate to English: {e}\")\n",
    "    print(\"TODO: translate to EnglishÔºÅ\")\n",
    "    api_key = None\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: TODO: translate to English\n",
    "\n",
    "TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç TODO: translate to English\n",
      "======================================================================\n",
      "TODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/data_analy/keyword_find/autogen_propaganda_analysis_results\n",
      "TODO: translate to English: _prompt.md\n",
      "\n",
      "üìÇ TODO: translate to English: en, po, ru\n",
      "‚úì TODO: translate to English: en, po, ru\n",
      "\n",
      "üìÅ TODO: translate to English: EN\n",
      "  TODO: translate to English 19 technique(s)TODO: translate to English\n",
      "  TODO: translate to English 19 technique(s)\n",
      "\n",
      "üìÅ TODO: translate to English: PO\n",
      "  TODO: translate to English 23 technique(s)TODO: translate to English\n",
      "  TODO: translate to English 23 technique(s)\n",
      "\n",
      "üìÅ TODO: translate to English: RU\n",
      "  TODO: translate to English 23 technique(s)TODO: translate to English\n",
      "  TODO: translate to English 23 technique(s)\n",
      "\n",
      "======================================================================\n",
      "üìä TODO: translate to English\n",
      "======================================================================\n",
      "‚úì TODO: translate to English: 3\n",
      "  en, po, ru\n",
      "\n",
      "‚úì TODO: translate to English: 23\n",
      "  Appeal_to_Authority, Appeal_to_Fear_Prejudice, Appeal_to_Hypocrisy\n",
      "  Appeal_to_Popularity, Appeal_to_Time, Appeal_to_Values\n",
      "  Causal_Oversimplification, Consequential_Oversimplification, Conversation_Killer\n",
      "  Doubt, Exaggeration_Minimisation, False_Dilemma_No_Choice\n",
      "  Flag_Waving, Guilt_by_Association, Loaded_Language\n",
      "  Name_Calling_Labeling, Obfuscation_Vagueness_Confusion, Questioning_the_Reputation\n",
      "  Red_Herring, Repetition, Slogans\n",
      "  Straw_Man, Whataboutism\n",
      "\n",
      "‚úì TODO: translate to English: 65 TODO: translate to English\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "loader = FlexiblePromptLoader(\n",
    "    base_dir=PROMPTS_BASE_DIR,\n",
    "    languages=['ru', 'po','en'],  # TODO: translate to EnglishRussianTODO: translate to EnglishPolish\n",
    "    # exclude_techniques=['Slogans'],  # TODO: translate to EnglishÔºöExcludeTODO: translate to English\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä TODO: translate to English:\n",
      "TODO: translate to English: 65\n",
      "TODO: translate to English: 3\n",
      "TODO: translate to English: 23\n",
      "\n",
      "üìÇ TODO: translate to English:\n",
      "  RU: 23 technique(s)\n",
      "  PO: 23 technique(s)\n",
      "  EN: 19 technique(s)\n"
     ]
    }
   ],
   "source": [
    "# TODO: translate to English\n",
    "stats = loader.get_stats()\n",
    "\n",
    "print(\"\\nüìä TODO: translate to English:\")\n",
    "print(f\"TODO: translate to English: {stats['total_prompts']}\")\n",
    "print(f\"TODO: translate to English: {stats['total_languages']}\")\n",
    "\n",
    "print(f\"TODO: translate to English: {stats['total_techniques']}\")\n",
    "\n",
    "print(\"\\nüìÇ TODO: translate to English:\")\n",
    "for lang, count in stats['coverage'].items():\n",
    "    print(f\"  {lang.upper()}: {count} technique(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8: TODO: translate to English\n",
    "\n",
    "**TODO: translate to English**: TODO: translate to EnglishAutomatically append output-format instructionsÔºÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå TODO: translate to EnglishOpenAITODO: translate to English: gpt-4o-mini\n",
      "\n",
      "üöÄ TODO: translate to English 23 technique(s)TODO: translate to EnglishAgentTODO: translate to English\n",
      "TODO: translate to English: PO\n",
      "TODO: translate to English: gpt-4o-mini\n",
      "‚úì TODO: translate to EnglishagentsTODO: translate to EnglishÔºÅ\n",
      "\n",
      "# Straw_Man - po\n",
      "\n",
      "**TODO: translate to English**: 8\n",
      "**TODO: translate to English**: success\n",
      "\n",
      "---\n",
      "\n",
      "## LLM Classification Prompt\n",
      "\n",
      "The 'Straw Man' fallacy is a common rhetorical technique used in arguments where one party misrepresents an opponent's position to make it easier to attack or refute. In essence, the 'Straw Man' distorts the original argument, creating a false version of it that can be easily dismantled. This technique is particularly prevalent in political discourse and can manifest in various forms, such as oversimplifying complex arguments, exaggerating them, or attributing extreme views to opponents that they do not actually hold.\n",
      "\n",
      "When training a language model to detect the 'Straw Man' technique in Polish (po), the following criteria should be used for identification:\n",
      "\n",
      "1. **Misrepresentation of Arguments**: Look for instances where an author simplifies or distorts an opposing viewpoint. This could include exaggerating the implications of that viewpoint or stating it in a way that is easier to criticize.\n",
      "\n",
      "2. **Lack of Engagement with the Original Argument**: Identify if the article fails to address the actual position of the opponent. Instead, it should focus on a version that the author finds more manageable to counter.\n",
      "\n",
      "3. **Use of Loaded Language**: Check for emotionally charged or biased language that serves to ridicule or demean the opposing perspective rather than engage with it thoughtfully.\n",
      "\n",
      "4. **Simplistic Binary Choices**: Determine if the argument presents issues in a black-and-white manner, ignoring nuances and complexities that are essential for a fair representation of the opposing view.\n",
      "\n",
      "5. **Rhetorical Questions or Satire**: Note if the text employs rhetorical questions or satirical commentary to belittle the opponent's stance without providing a substantive response.\n",
      "\n",
      "### Positive Examples:\n",
      "1. **Example 1**: \"Critics argue that increasing military support for Ukraine will escalate tensions. However, those who support this view actually want a world war.\" This statement misrepresents the critics' position by suggesting they advocate for an extreme outcome that they do not actually support.\n",
      "\n",
      "2. **Example 2**: \"Some say we should stop all trade with Russia, but do they really want to see our economy collapse?\" Here, the argument simplifies the complex issue of trade relations into an extreme choice.\n",
      "\n",
      "3. **Example 3**: \"Opponents of sanctions claim they harm the innocent, but do they actually care about the victims of Russian aggression?\" This statement shifts focus from the actual argument about economic repercussions to an emotional appeal against the opponents' character.\n",
      "\n",
      "## Keywords and Patterns\n",
      "\n",
      "### Important Keywords/Phrases:\n",
      "1. \"Ale przecie≈º\" (But after all)\n",
      "2. \"W rzeczywisto≈õci\" (In reality)\n",
      "3. \"Niekt√≥rzy m√≥wiƒÖ, ≈ºe\" (Some say that)\n",
      "4. \"Zamiast tego\" (Instead of that)\n",
      "5. \"To tylko pretekst\" (That's just an excuse)\n",
      "6. \"W rzeczywisto≈õci chodzi o\" (In reality, it's about)\n",
      "7. \"Przykro mi, ale\" (I‚Äôm sorry, but)\n",
      "8. \"Jak mo≈ºna tak my≈õleƒá?\" (How can one think like that?)\n",
      "9. \"Na pewno nie chcƒÖ\" (They definitely don‚Äôt want)\n",
      "10. \"To absurd\" (That‚Äôs absurd)\n",
      "\n",
      "### Linguistic Patterns:\n",
      "1. **Contrasting Statements**: Look for phrases that set up a dichotomy between the author‚Äôs view and the misrepresented opposing view.\n",
      "2. **Exaggerated Claims**: Identify instances where an argument is presented in an exaggerated way to make it seem ridiculous or extreme.\n",
      "3. **Rhetorical Questions**: Watch for questions that challenge the validity of an opposing viewpoint without providing evidence or deeper reasoning.\n",
      "4. **Dismissive Language**: Analyze the use of condescending or mocking language that does not engage with the merits of the opposing argument.\n",
      "5. **Simplified Causes and Effects**: Find statements that suggest a direct and simplistic cause and effect relationship where the reality is much more complicated.\n",
      "\n",
      "### Contextual Clues:\n",
      "1. **Political Context**: Articles discussing contentious political figures or policies can often reveal 'Straw Man' arguments, especially in polarized environments.\n",
      "2. **Emotional Appeals**: Look for language that invokes strong emotions, which may indicate an attempt to distract from a rational discussion of the argument.\n",
      "3. **Lack of Sources**: If the argument presents claims without credible sources or data to support them, it may be indicative of a 'Straw Man' approach.\n",
      "\n",
      "## Language-Specific Insights\n",
      "\n",
      "### Cultural Context in Polish (po):\n",
      "The Polish political landscape is heavily influenced by historical narratives and national identity, particularly regarding issues like sovereignty, foreign relations, and historical grievances. As such, discussions about Russia and Ukraine often evoke strong emotional responses and polarized viewpoints. This context can lead to the use of 'Straw Man' arguments as parties seek to rally support for their positions by misrepresenting their opponents‚Äô views, especially in the context of national security and identity.\n",
      "\n",
      "### Key Grammar/Vocabulary Features:\n",
      "Polish language structure often allows for complex sentences, which can be used to build nuanced arguments. However, in 'Straw Man' arguments, simplifications are prevalent. The use of colloquial expressions or rhetorical questions is common, which can serve to belittle the opposing stance without engaging critically.\n",
      "\n",
      "### Concrete Examples from Articles:\n",
      "1. In Article 1, Bolsonaro's statement about neutrality implicitly caricatures the pro-sanction viewpoint by framing it as an extreme position that ignores the complexities of international relations.\n",
      "2. Article 2 discusses Orb√°n's actions towards sanctions and includes phrases like \"absurdalny argument,\" which serves to undermine the seriousness of the opposing viewpoint without addressing its merits.\n",
      "3. The use of loaded terms such as \"komik\" (comic) in relation to Zelensky in Article 1 is an attempt to diminish his political stature and misrepresent the argument for supporting Ukraine by creating a stereotype that is easier to criticize. \n",
      "\n",
      "Overall, the detection of 'Straw Man' arguments in Polish requires careful analysis of language use, cultural context, and the structure of arguments presented in political discourse.\n",
      "\n",
      "\n",
      "    ======================================================================\n",
      "    CRITICAL OUTPUT INSTRUCTIONS:\n",
      "    ======================================================================\n",
      "\n",
      "    Your task is to determine if the technique \"Straw_Man\" is CLEARLY and SIGNIFICANTLY present in the TARGET PARAGRAPH.\n",
      "\n",
      "    STRICT EVALUATION CRITERIA:\n",
      "    1. The technique must be EXPLICIT and OBVIOUS in the target paragraph\n",
      "    2. There must be CLEAR EVIDENCE, not just vague similarities\n",
      "    3. The technique must be CENTRAL to the paragraph's message, not just tangentially related\n",
      "    4. When in doubt or if the evidence is weak, respond with '0'\n",
      "    5. Only respond '1' if you are HIGHLY CONFIDENT the technique is present\n",
      "\n",
      "    RESPONSE FORMAT:\n",
      "    - '1' = technique \"Straw_Man\" is CLEARLY and SIGNIFICANTLY present\n",
      "    - '0' = technique is absent OR evidence is weak/uncertain\n",
      "\n",
      "    Be CONSERVATIVE in your judgment. It's better to miss a technique than to falsely detect one.\n",
      "\n",
      "    Your response must be exactly one character: either '1' or '0'.\n",
      "\n",
      "    RESPOND WITH ONLY '1' OR '0':\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# TODO: translate to Englishtechnique(s)TODO: translate to English\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# TODO: translate to EnglishAutoGenTODO: translate to EnglishAPITODO: translate to English\n",
    "warnings.filterwarnings('ignore', message='The API key specified is not a valid OpenAI format')\n",
    "\n",
    "# TODO: translate to EnglishautogenTODO: translate to EnglishloggingTODO: translate to English\n",
    "logging.getLogger('autogen.oai.client').setLevel(logging.ERROR)\n",
    "\n",
    "prompt = loader.get_prompt('Straw_Man', 'po')\n",
    "# print(prompt.prompt_content)  # ‚Üê TODO: translate to English.mdTODO: translate to English\n",
    "\n",
    "# TODO: translate to English(TODO: translate to English)\n",
    "agent_system = FlexibleTechniqueAgentSystem(\n",
    "    prompt_loader=loader,\n",
    "    language='po',\n",
    "    api_key=api_key,\n",
    "    model=model\n",
    ")\n",
    "full_prompt = agent_system._create_agent_system_prompt('Straw_Man')\n",
    "print(full_prompt)  # ‚Üê TODO: translate to English + TODO: translate to English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9: TODO: translate to EnglishAgentTODO: translate to English\n",
    "\n",
    "TODO: translate to Englishtechnique(s)TODO: translate to EnglishÔºÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå TODO: translate to EnglishOpenAITODO: translate to English: gpt-4o-mini\n",
      "\n",
      "üöÄ TODO: translate to English 23 technique(s)TODO: translate to EnglishAgentTODO: translate to English\n",
      "TODO: translate to English: PO\n",
      "TODO: translate to English: gpt-4o-mini\n",
      "‚úì TODO: translate to EnglishagentsTODO: translate to EnglishÔºÅ\n",
      "\n",
      "üîå TODO: translate to EnglishOpenAITODO: translate to English: gpt-4o-mini\n",
      "\n",
      "üöÄ TODO: translate to English 23 technique(s)TODO: translate to EnglishAgentTODO: translate to English\n",
      "TODO: translate to English: RU\n",
      "TODO: translate to English: gpt-4o-mini\n",
      "‚úì TODO: translate to EnglishagentsTODO: translate to EnglishÔºÅ\n",
      "\n",
      "üîå TODO: translate to EnglishOpenAITODO: translate to English: gpt-4o-mini\n",
      "\n",
      "üöÄ TODO: translate to English 19 technique(s)TODO: translate to EnglishAgentTODO: translate to English\n",
      "TODO: translate to English: EN\n",
      "TODO: translate to English: gpt-4o-mini\n",
      "‚úì TODO: translate to EnglishagentsTODO: translate to EnglishÔºÅ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "# TODO: translate to EnglishautogenTODO: translate to EnglishERRORÔºåTODO: translate to EnglishWARNING\n",
    "logging.getLogger(\"autogen.oai.client\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "#TODO: translate to EnglishPolish\n",
    "# TODO: translate to EnglishAPITODO: translate to English\n",
    "if api_key is None:\n",
    "    print(\"‚ö†Ô∏è APITODO: translate to EnglishÔºåTODO: translate to EnglishÔºÅ\")\n",
    "    print(\"TODO: translate to EnglishStep5TODO: translate to EnglishAPITODO: translate to English„ÄÇ\")\n",
    "else:\n",
    "    # TODO: translate to EnglishPolishTODO: translate to English\n",
    "    system_po = FlexibleTechniqueAgentSystem(\n",
    "        prompt_loader=loader,\n",
    "        language='po',  # Polish\n",
    "        api_key=api_key,\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "if api_key:\n",
    "    # TODO: translate to EnglishRussianTODO: translate to English\n",
    "    system_ru = FlexibleTechniqueAgentSystem(\n",
    "        prompt_loader=loader,\n",
    "        language='ru',  # Russian\n",
    "        api_key=api_key,\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    system_en = FlexibleTechniqueAgentSystem(\n",
    "        prompt_loader=loader,\n",
    "        language='en',  # English (English)\n",
    "        api_key=api_key,\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0\n",
    "    )\n",
    "    # TODO: translate to EnglishRussianTODO: translate to English\n",
    "    # ru_prompt = system_ru._create_agent_system_prompt(\"Straw_Man\")\n",
    "    \n",
    "    # print(\"\\nRussianTODO: translate to EnglishÔºàTODO: translate to English500TODO: translate to EnglishÔºâ:\")\n",
    "    # print(\"=\"*70)\n",
    "    # print(ru_prompt[-500:])\n",
    "    # print(\"\\n‚úì TODO: translate to EnglishRussianTODO: translate to EnglishPolishTODO: translate to EnglishÔºÅ\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TODO: translate to EnglishAPITODO: translate to EnglishÔºàTODO: translate to EnglishStep5Ôºâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ TODO: translate to English\n",
      "======================================================================\n",
      "‚úì TODO: translate to English (TODO: translate to English: RU)\n",
      "‚úì RussianTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
      "‚úì TODO: translate to English (TODO: translate to English: PO)\n",
      "‚úì PolishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
      "‚úì TODO: translate to English (TODO: translate to English: EN)\n",
      "‚úì EnglishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n"
     ]
    }
   ],
   "source": [
    "# TODO: translate to English12\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ TODO: translate to English\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# RussianTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "context_detector_ru = ContextAwareParagraphDetector(system_ru, language='ru')\n",
    "print(\"‚úì RussianTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\")\n",
    "\n",
    "# PolishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "context_detector_po = ContextAwareParagraphDetector(system_po, language='po')\n",
    "print(\"‚úì PolishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\")\n",
    "\n",
    "# EnglishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "context_detector_en = ContextAwareParagraphDetector(system_en, language='en')\n",
    "print(\"‚úì EnglishTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TODO: translate to English:\n",
      "  paragraph(s)TODO: translate to English: 32\n",
      "  paragraph(s)IDTODO: translate to English: 1 - 33\n",
      "  TODO: translate to English10TODO: translate to EnglishID: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "test_article_path = \"your_article813494037_file_location\"\n",
    "\n",
    "with open(test_article_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "paragraphs = context_detector_en.split_into_paragraphs(text)\n",
    "\n",
    "print(f\"üìä TODO: translate to English:\")\n",
    "print(f\"  paragraph(s)TODO: translate to English: {len(paragraphs)}\")\n",
    "print(f\"  paragraph(s)IDTODO: translate to English: {paragraphs[0]['paragraph_id']} - {paragraphs[-1]['paragraph_id']}\")\n",
    "\n",
    "# TODO: translate to English\n",
    "para_ids = [p['paragraph_id'] for p in paragraphs]\n",
    "print(f\"  TODO: translate to English10TODO: translate to EnglishID: {para_ids[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üó≥Ô∏è  TODO: translate to English(TODO: translate to English)\n",
      "======================================================================\n",
      "\n",
      "[1/3] Create a Russian voting detector...\n",
      "‚úì TODO: translate to English (TODO: translate to English: RU)\n",
      "‚úì TODO: translate to English (TODO: translate to English: RU)\n",
      "‚úì TODO: translate to English (TODO: translate to English: RU)\n",
      "‚úì RussianTODO: translate to English(3TODO: translate to English)\n",
      "\n",
      "[2/3] Create a Polish voting detector...\n",
      "‚úì TODO: translate to English (TODO: translate to English: PO)\n",
      "‚úì TODO: translate to English (TODO: translate to English: PO)\n",
      "‚úì TODO: translate to English (TODO: translate to English: PO)\n",
      "‚úì PolishTODO: translate to English(3TODO: translate to English)\n",
      "\n",
      "[3/3] Create an English voting detector...\n",
      "‚úì TODO: translate to English (TODO: translate to English: EN)\n",
      "‚úì TODO: translate to English (TODO: translate to English: EN)\n",
      "‚úì TODO: translate to English (TODO: translate to English: EN)\n",
      "‚úì EnglishTODO: translate to English(3TODO: translate to English)\n",
      "\n",
      "‚úì TODO: translate to English!\n",
      "\n",
      "TODO: translate to English:\n",
      "  Russian: voting_detector_ru_{balanced/conservative/aggressive}\n",
      "  Polish: voting_detector_po_{balanced/conservative/aggressive}\n",
      "  English: voting_detector_en_{balanced/conservative/aggressive}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# TODO: translate to EnglishautogenTODO: translate to EnglishERROR,TODO: translate to EnglishWARNING\n",
    "logging.getLogger(\"autogen.oai.client\").setLevel(logging.ERROR)\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üó≥Ô∏è  TODO: translate to English(TODO: translate to English)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# RussianTODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n[1/3] Create a Russian voting detector...\")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_ru_balanced = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_ru,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.67,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_ru_conservative = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_ru,\n",
    "    voting_rounds=5,\n",
    "    voting_threshold=0.8,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_ru_aggressive = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_ru,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.34,\n",
    "    use_temperature=True,\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "print(\"‚úì RussianTODO: translate to English(3TODO: translate to English)\")\n",
    "\n",
    "# ============================================================\n",
    "# PolishTODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n[2/3] Create a Polish voting detector...\")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_po_balanced = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_po,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.67,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_po_conservative = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_po,\n",
    "    voting_rounds=5,\n",
    "    voting_threshold=0.8,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_po_aggressive = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_po,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.34,\n",
    "    use_temperature=True,\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "print(\"‚úì PolishTODO: translate to English(3TODO: translate to English)\")\n",
    "\n",
    "# ============================================================\n",
    "# EnglishTODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n[3/3] Create an English voting detector...\")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_en_balanced = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_en,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.67,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_en_conservative = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_en,\n",
    "    voting_rounds=5,\n",
    "    voting_threshold=0.8,\n",
    "    use_temperature=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# TODO: translate to English\n",
    "voting_detector_en_aggressive = VotingContextAwareParagraphDetector(\n",
    "    agent_system=system_en,\n",
    "    voting_rounds=3,\n",
    "    voting_threshold=0.34,\n",
    "    use_temperature=True,\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "print(\"‚úì EnglishTODO: translate to English(3TODO: translate to English)\")\n",
    "\n",
    "# TODO: translate to English(TODO: translate to English)\n",
    "voting_detector_balanced = voting_detector_po_balanced\n",
    "voting_detector_conservative = voting_detector_po_conservative\n",
    "voting_detector_aggressive = voting_detector_po_aggressive\n",
    "\n",
    "print(\"\\n‚úì TODO: translate to English!\")\n",
    "print(\"\\nTODO: translate to English:\")\n",
    "print(\"  Russian: voting_detector_ru_{balanced/conservative/aggressive}\")\n",
    "print(\"  Polish: voting_detector_po_{balanced/conservative/aggressive}\")\n",
    "print(\"  English: voting_detector_en_{balanced/conservative/aggressive}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ TODO: translate to English\n",
      "======================================================================\n",
      "‚úì TODO: translate to English\n",
      "\n",
      "======================================================================\n",
      "üìÇ TODO: translate to English\n",
      "======================================================================\n",
      "‚úì TODO: translate to English 15 TODO: translate to English\n",
      "‚úì TODO: translate to English: 195\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "  TODO: translate to English: 15\n",
      "  TODO: translate to English: 195\n",
      "  technique instance(s)TODO: translate to English: 609\n",
      "  TODO: translate to English: 13.0 TODO: translate to English\n",
      "  TODO: translate to English: 3.1 technique(s)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Set, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "class PropagandaEvaluator:\n",
    "    \"\"\"PropagandaTODO: translate to English\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Technique nameTODO: translate to English\n",
    "        self.technique_normalization = {\n",
    "            'Appeal_to_Fear-Prejudice': 'Appeal_to_Fear_Prejudice',\n",
    "            'Repetitions': 'Repetition',\n",
    "            'Name_Calling-Labeling': 'Name_Calling_Labeling',\n",
    "            'Exaggeration-Minimisation': 'Exaggeration_Minimisation',\n",
    "            # TODO: translate to English\n",
    "        }\n",
    "    \n",
    "    def normalize_technique_name(self, technique: str) -> str:\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishTechnique name\n",
    "        \n",
    "        Args:\n",
    "            technique: TODO: translate to EnglishTechnique name\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to EnglishTechnique name\n",
    "        \"\"\"\n",
    "        # TODO: translate to English\n",
    "        if technique in self.technique_normalization:\n",
    "            return self.technique_normalization[technique]\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        technique = technique.replace('-', '_')\n",
    "        \n",
    "        return technique\n",
    "    \n",
    "    def load_gold_annotations(self, annotation_file: str) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            annotation_file: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to EnglishÔºö{article_id: [annotation1, annotation2, ...]}\n",
    "        \"\"\"\n",
    "        annotations = defaultdict(list)\n",
    "        \n",
    "        if not os.path.exists(annotation_file):\n",
    "            print(f\"‚úó TODO: translate to English: {annotation_file}\")\n",
    "            return {}\n",
    "        \n",
    "        with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) < 4:  # TODO: translate to EnglishÔºöarticle_id, start, end, technique\n",
    "                    continue\n",
    "                \n",
    "                article_id = parts[0]\n",
    "                start_pos = int(parts[1])\n",
    "                end_pos = int(parts[2])\n",
    "                techniques = [self.normalize_technique_name(t) for t in parts[3:]]\n",
    "                \n",
    "                annotations[article_id].append({\n",
    "                    'article_id': article_id,\n",
    "                    'start_pos': start_pos,\n",
    "                    'end_pos': end_pos,\n",
    "                    'techniques': techniques,\n",
    "                    'num_techniques': len(techniques)\n",
    "                })\n",
    "        \n",
    "        print(f\"‚úì TODO: translate to English {len(annotations)} TODO: translate to English\")\n",
    "        total_spans = sum(len(spans) for spans in annotations.values())\n",
    "        print(f\"‚úì TODO: translate to English: {total_spans}\")\n",
    "        \n",
    "        return dict(annotations)\n",
    "    \n",
    "    def calculate_overlap(self, span1: Tuple[int, int], span2: Tuple[int, int]) -> float:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            span1: (start, end)\n",
    "            span2: (start, end)\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to English (0.0 TODO: translate to English 1.0)\n",
    "        \"\"\"\n",
    "        start1, end1 = span1\n",
    "        start2, end2 = span2\n",
    "        \n",
    "        # Compute overlap region\n",
    "        overlap_start = max(start1, start2)\n",
    "        overlap_end = min(end1, end2)\n",
    "        \n",
    "        if overlap_start >= overlap_end:\n",
    "            return 0.0  # No overlap\n",
    "        \n",
    "        overlap_length = overlap_end - overlap_start\n",
    "        \n",
    "        # Compute overlap ratio relative to the shorter span\n",
    "        span1_length = end1 - start1\n",
    "        span2_length = end2 - start2\n",
    "        min_length = min(span1_length, span2_length)\n",
    "        \n",
    "        if min_length == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return overlap_length / min_length\n",
    "    \n",
    "    def match_spans(\n",
    "        self, \n",
    "        detected_spans: List[Dict], \n",
    "        gold_spans: List[Dict],\n",
    "        overlap_threshold: float = 0.5\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            detected_spans: TODO: translate to English\n",
    "            gold_spans: TODO: translate to English\n",
    "            overlap_threshold: TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to English\n",
    "        \"\"\"\n",
    "        matched_pairs = []\n",
    "        unmatched_detected = []\n",
    "        unmatched_gold = []\n",
    "        \n",
    "        # TODO: translate to Englishgold spansTODO: translate to English\n",
    "        gold_matched = [False] * len(gold_spans)\n",
    "        \n",
    "        # TODO: translate to EnglishÔºåTODO: translate to Englishgold span\n",
    "        for detected in detected_spans:\n",
    "            detected_span = (detected['start_pos'], detected['end_pos'])\n",
    "            \n",
    "            best_overlap = 0.0\n",
    "            best_gold_idx = -1\n",
    "            \n",
    "            for idx, gold in enumerate(gold_spans):\n",
    "                if gold_matched[idx]:\n",
    "                    continue  # TODO: translate to English\n",
    "                \n",
    "                gold_span = (gold['start_pos'], gold['end_pos'])\n",
    "                overlap = self.calculate_overlap(detected_span, gold_span)\n",
    "                \n",
    "                if overlap > best_overlap:\n",
    "                    best_overlap = overlap\n",
    "                    best_gold_idx = idx\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            if best_overlap >= overlap_threshold and best_gold_idx >= 0:\n",
    "                matched_pairs.append({\n",
    "                    'detected': detected,\n",
    "                    'gold': gold_spans[best_gold_idx],\n",
    "                    'overlap': best_overlap\n",
    "                })\n",
    "                gold_matched[best_gold_idx] = True\n",
    "            else:\n",
    "                unmatched_detected.append(detected)\n",
    "        \n",
    "        # TODO: translate to Englishgold spans\n",
    "        for idx, gold in enumerate(gold_spans):\n",
    "            if not gold_matched[idx]:\n",
    "                unmatched_gold.append(gold)\n",
    "        \n",
    "        return {\n",
    "            'matched_pairs': matched_pairs,\n",
    "            'unmatched_detected': unmatched_detected,\n",
    "            'unmatched_gold': unmatched_gold\n",
    "        }\n",
    "    \n",
    "    def evaluate_techniques(self, matched_pairs: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "        \n",
    "        Args:\n",
    "            matched_pairs: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to English\n",
    "        \"\"\"\n",
    "        total_detected = 0\n",
    "        total_gold = 0\n",
    "        total_correct = 0\n",
    "        \n",
    "        technique_stats = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})\n",
    "        \n",
    "        for pair in matched_pairs:\n",
    "            detected_techs = set(pair['detected']['detected_techniques'])\n",
    "            gold_techs = set(pair['gold']['techniques'])\n",
    "            \n",
    "            total_detected += len(detected_techs)\n",
    "            total_gold += len(gold_techs)\n",
    "            \n",
    "            # TODO: translate to EnglishÔºöTODO: translate to EnglishÔºåTODO: translate to English\n",
    "            correct = detected_techs & gold_techs\n",
    "            total_correct += len(correct)\n",
    "            \n",
    "            # TODO: translate to EnglishÔºöTODO: translate to EnglishÔºåTODO: translate to English\n",
    "            false_positive = detected_techs - gold_techs\n",
    "            \n",
    "            # TODO: translate to EnglishÔºöTODO: translate to EnglishÔºåTODO: translate to English\n",
    "            false_negative = gold_techs - detected_techs\n",
    "            \n",
    "            # TODO: translate to Englishtechnique(s)TODO: translate to English\n",
    "            for tech in correct:\n",
    "                technique_stats[tech]['tp'] += 1\n",
    "            \n",
    "            for tech in false_positive:\n",
    "                technique_stats[tech]['fp'] += 1\n",
    "            \n",
    "            for tech in false_negative:\n",
    "                technique_stats[tech]['fn'] += 1\n",
    "        \n",
    "        # Compute overall metrics\n",
    "        precision = total_correct / total_detected if total_detected > 0 else 0.0\n",
    "        recall = total_correct / total_gold if total_gold > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'total_detected': total_detected,\n",
    "            'total_gold': total_gold,\n",
    "            'total_correct': total_correct,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'technique_stats': dict(technique_stats)\n",
    "        }\n",
    "    \n",
    "    def evaluate_article(\n",
    "        self,\n",
    "        detected_result: Dict,\n",
    "        gold_annotations: List[Dict],\n",
    "        overlap_threshold: float = 0.5\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            detected_result: TODO: translate to EnglishÔºàTODO: translate to Englishdetect_article_by_paragraphsÔºâ\n",
    "            gold_annotations: TODO: translate to English\n",
    "            overlap_threshold: TODO: translate to English\n",
    "        \n",
    "        Returns:\n",
    "            TODO: translate to English\n",
    "        \"\"\"\n",
    "        article_id = detected_result['article_id']\n",
    "        \n",
    "        # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "        detected_spans = [\n",
    "            span for span in detected_result['paragraph_results']\n",
    "            if span['num_techniques'] > 0\n",
    "        ]\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        matching_result = self.match_spans(detected_spans, gold_annotations, overlap_threshold)\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        technique_eval = self.evaluate_techniques(matching_result['matched_pairs'])\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        num_detected_spans = len(detected_spans)\n",
    "        num_gold_spans = len(gold_annotations)\n",
    "        num_matched_spans = len(matching_result['matched_pairs'])\n",
    "        \n",
    "        span_precision = num_matched_spans / num_detected_spans if num_detected_spans > 0 else 0.0\n",
    "        span_recall = num_matched_spans / num_gold_spans if num_gold_spans > 0 else 0.0\n",
    "        span_f1 = 2 * span_precision * span_recall / (span_precision + span_recall) if (span_precision + span_recall) > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'span_level': {\n",
    "                'detected': num_detected_spans,\n",
    "                'gold': num_gold_spans,\n",
    "                'matched': num_matched_spans,\n",
    "                'precision': span_precision,\n",
    "                'recall': span_recall,\n",
    "                'f1': span_f1\n",
    "            },\n",
    "            'technique_level': technique_eval,\n",
    "            'matching_details': matching_result\n",
    "        }\n",
    "    \n",
    "    def print_evaluation_report(self, eval_result: Dict, detailed: bool = True):\n",
    "        \"\"\"\n",
    "        TODO: translate to English\n",
    "        \n",
    "        Args:\n",
    "            eval_result: TODO: translate to English\n",
    "            detailed: TODO: translate to English\n",
    "        \"\"\"\n",
    "        article_id = eval_result['article_id']\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TODO: translate to English: {article_id}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        span = eval_result['span_level']\n",
    "        print(f\"\\nüìç TODO: translate to English:\")\n",
    "        print(f\"  TODO: translate to English: {span['detected']}\")\n",
    "        print(f\"  TODO: translate to English: {span['gold']}\")\n",
    "        print(f\"  TODO: translate to English: {span['matched']}\")\n",
    "        print(f\"  TODO: translate to English: {span['precision']:.2%}\")\n",
    "        print(f\"  TODO: translate to English: {span['recall']:.2%}\")\n",
    "        print(f\"  F1TODO: translate to English: {span['f1']:.2%}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        tech = eval_result['technique_level']\n",
    "        print(f\"\\nüéØ TODO: translate to English:\")\n",
    "        print(f\"  TODO: translate to English: {tech['total_detected']}\")\n",
    "        print(f\"  TODO: translate to English: {tech['total_gold']}\")\n",
    "        print(f\"  TODO: translate to English: {tech['total_correct']}\")\n",
    "        print(f\"  TODO: translate to English: {tech['precision']:.2%}\")\n",
    "        print(f\"  TODO: translate to English: {tech['recall']:.2%}\")\n",
    "        print(f\"  F1TODO: translate to English: {tech['f1']:.2%}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        if detailed and tech['technique_stats']:\n",
    "            print(f\"\\nüìä TODO: translate to English:\")\n",
    "            print(f\"{'Technique name':<35} {'TP':>4} {'FP':>4} {'FN':>4} {'TODO: translate to English':>7} {'TODO: translate to English':>7} {'F1':>7}\")\n",
    "            print(f\"{'-'*70}\")\n",
    "            \n",
    "            for tech_name, stats in sorted(tech['technique_stats'].items()):\n",
    "                tp = stats['tp']\n",
    "                fp = stats['fp']\n",
    "                fn = stats['fn']\n",
    "                \n",
    "                prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "                rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "                f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "                \n",
    "                print(f\"{tech_name:<35} {tp:>4} {fp:>4} {fn:>4} {prec:>6.1%} {rec:>6.1%} {f1:>6.1%}\")\n",
    "        \n",
    "        # ErrorTODO: translate to English\n",
    "        if detailed:\n",
    "            matching = eval_result['matching_details']\n",
    "            \n",
    "            if matching['unmatched_detected']:\n",
    "                print(f\"\\n‚ö†Ô∏è  TODO: translate to English ({len(matching['unmatched_detected'])} TODO: translate to English):\")\n",
    "                for span in matching['unmatched_detected'][:3]:  # TODO: translate to English3TODO: translate to English\n",
    "                    print(f\"  Position {span['start_pos']}-{span['end_pos']}: {', '.join(span['detected_techniques'][:3])}\")\n",
    "            \n",
    "            if matching['unmatched_gold']:\n",
    "                print(f\"\\n‚ö†Ô∏è  TODO: translate to English ({len(matching['unmatched_gold'])} TODO: translate to English):\")\n",
    "                for span in matching['unmatched_gold'][:3]:  # TODO: translate to English3TODO: translate to English\n",
    "                    print(f\"  Position {span['start_pos']}-{span['end_pos']}: {', '.join(span['techniques'][:3])}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéØ TODO: translate to English\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = PropagandaEvaluator()\n",
    "\n",
    "print(\"‚úì TODO: translate to English\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÇ TODO: translate to English\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# PolishTODO: translate to English\n",
    "PL_ANNOTATION_FILE = \"your_subtask_2_annotations_file_location\"\n",
    "\n",
    "pl_gold_annotations = evaluator.load_gold_annotations(PL_ANNOTATION_FILE)\n",
    "\n",
    "if pl_gold_annotations:\n",
    "    total_spans = sum(len(spans) for spans in pl_gold_annotations.values())\n",
    "    total_techniques = sum(\n",
    "        sum(len(span['techniques']) for span in spans)\n",
    "        for spans in pl_gold_annotations.values()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä TODO: translate to English:\")\n",
    "    print(f\"  TODO: translate to English: {len(pl_gold_annotations)}\")\n",
    "    print(f\"  TODO: translate to English: {total_spans}\")\n",
    "    print(f\"  technique instance(s)TODO: translate to English: {total_techniques}\")\n",
    "    print(f\"  TODO: translate to English: {total_spans/len(pl_gold_annotations):.1f} TODO: translate to English\")\n",
    "    print(f\"  TODO: translate to English: {total_techniques/total_spans:.1f} technique(s)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "# # ============================================================\n",
    "\n",
    "# if 'result' in locals() and pl_gold_annotations:\n",
    "#     article_id = result['article_id']\n",
    "    \n",
    "#     if article_id in pl_gold_annotations:\n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"üß™ TODO: translate to English\")\n",
    "#         print(\"=\"*70)\n",
    "        \n",
    "#         eval_result = evaluator.evaluate_article(\n",
    "#             detected_result=result,\n",
    "#             gold_annotations=pl_gold_annotations[article_id],\n",
    "#             overlap_threshold=0.5\n",
    "#         )\n",
    "        \n",
    "#         evaluator.print_evaluation_report(eval_result, detailed=True)\n",
    "#     else:\n",
    "#         print(f\"\\n‚ö†Ô∏è  TODO: translate to English {article_id} TODO: translate to English\")\n",
    "#         print(f\"   TODO: translate to English: {list(pl_gold_annotations.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TODO: translate to English batch_detect_unified TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TODO: translate to English batch_detect_unified - TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def batch_detect_unified(\n",
    "    articles_dict: Dict[str, Dict[str, str]],\n",
    "    detector,\n",
    "    detector_name: str = \"TODO: translate to English\",\n",
    "    languages_to_test: List[str] = None,\n",
    "    num_articles_per_language: int = None,\n",
    "    min_paragraph_length: int = 50,\n",
    "    # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    evaluator = None,\n",
    "    gold_annotations: Dict[str, List] = None,\n",
    "    overlap_threshold: float = 0.5,\n",
    "    # TODO: translate to English\n",
    "    output_dir: str = None,  # üÜï TODO: translate to EnglishÔºöTODO: translate to English\n",
    "    save_tsv: bool = True,\n",
    "    save_json: bool = True,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    TODO: translate to English - TODO: translate to English\n",
    "    \n",
    "    Args:\n",
    "        articles_dict: TODO: translate to English\n",
    "        detector: TODO: translate to English\n",
    "        detector_name: TODO: translate to English\n",
    "        languages_to_test: TODO: translate to English\n",
    "        num_articles_per_language: TODO: translate to English\n",
    "        min_paragraph_length: TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "        \n",
    "        evaluator: TODO: translate to English\n",
    "        gold_annotations: TODO: translate to English\n",
    "        overlap_threshold: TODO: translate to English\n",
    "        \n",
    "        output_dir: TODO: translate to EnglishÔºàNoneTODO: translate to EnglishÔºâ\n",
    "        save_tsv: TODO: translate to EnglishTSVTODO: translate to English\n",
    "        save_json: TODO: translate to EnglishJSONTODO: translate to English\n",
    "        verbose: TODO: translate to English\n",
    "    \n",
    "    Returns:\n",
    "        TODO: translate to English\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import json\n",
    "    \n",
    "    # üÜï TODO: translate to English\n",
    "    if output_dir:\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\nüìÅ TODO: translate to English: {output_dir}\")\n",
    "    else:\n",
    "        output_path = Path(\".\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    evaluation_mode = (evaluator is not None and gold_annotations is not None)\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    language_display = {\n",
    "        'ru': {'name': 'Russian', 'flag': 'üá∑üá∫'},\n",
    "        'po': {'name': 'Polish', 'flag': 'üáµüá±'},\n",
    "        'pl': {'name': 'Polish', 'flag': 'üáµüá±'},\n",
    "        'en': {'name': 'English', 'flag': 'üá¨üáß'},\n",
    "        'bg': {'name': 'TODO: translate to English', 'flag': 'üáßüá¨'},\n",
    "    }\n",
    "    \n",
    "    if languages_to_test is None:\n",
    "        languages_to_test = list(articles_dict.keys())\n",
    "    \n",
    "    all_results = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    mode_str = \"TODO: translate to English\" if evaluation_mode else \"TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\"\n",
    "    print(f\"üöÄ {mode_str}: {detector_name}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"TODO: translate to English: {', '.join(languages_to_test)}\")\n",
    "    print(f\"TODO: translate to English: {'TODO: translate to English' if num_articles_per_language is None else num_articles_per_language}\")\n",
    "    if save_tsv:\n",
    "        print(f\"‚úì TODO: translate to EnglishTSVTODO: translate to English\")\n",
    "    if save_json:\n",
    "        print(f\"‚úì TODO: translate to EnglishJSONTODO: translate to English\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    for idx, lang_code in enumerate(languages_to_test, 1):\n",
    "        lang_info = language_display.get(lang_code, {'name': lang_code.upper(), 'flag': 'üåê'})\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"{lang_info['flag']} [{idx}/{len(languages_to_test)}] TODO: translate to English {lang_info['name']} ({lang_code.upper()})\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "            \n",
    "            lang_start_time = time.time()\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            if lang_code not in articles_dict:\n",
    "                print(f\"‚ùå TODO: translate to English '{lang_code}' TODO: translate to English\")\n",
    "                all_results[lang_code] = {'error': f\"TODO: translate to English '{lang_code}' TODO: translate to English\"}\n",
    "                continue\n",
    "            \n",
    "            articles = articles_dict[lang_code]\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            if isinstance(articles, list):\n",
    "                print(f\"  ‚ÑπÔ∏è  DetectedTODO: translate to EnglishÔºåTODO: translate to English...\")\n",
    "                articles_dict_converted = {}\n",
    "                for item in articles:\n",
    "                    if isinstance(item, dict):\n",
    "                        article_id = item.get('filename') or item.get('id') or item.get('article_id')\n",
    "                        article_text = item.get('text') or item.get('content') or item.get('body')\n",
    "                        if article_id and article_text:\n",
    "                            articles_dict_converted[article_id] = article_text\n",
    "                articles = articles_dict_converted\n",
    "                print(f\"  ‚úì TODO: translate to English: {len(articles)} TODO: translate to English\")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            if num_articles_per_language is not None and isinstance(articles, dict):\n",
    "                articles_items = list(articles.items())[:num_articles_per_language]\n",
    "                articles = dict(articles_items)\n",
    "            \n",
    "            if not articles:\n",
    "                print(f\"‚ùå TODO: translate to English\")\n",
    "                all_results[lang_code] = {'error': 'TODO: translate to English'}\n",
    "                continue\n",
    "            \n",
    "            print(f\"‚úì TODO: translate to English {len(articles)} TODO: translate to English\")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            print(f\"\\nüîç TODO: translate to English...\")\n",
    "            \n",
    "            article_results = []\n",
    "            tsv_outputs = []\n",
    "            \n",
    "            for i, (article_id, article_text) in enumerate(articles.items(), 1):\n",
    "                if verbose:\n",
    "                    print(f\"\\nProcessing article {i}/{len(articles)}: {article_id}\")\n",
    "                \n",
    "                try:\n",
    "                    result = detector.detect_article_by_paragraphs(\n",
    "                        article_id=article_id,\n",
    "                        full_text=article_text,\n",
    "                        min_paragraph_length=min_paragraph_length,\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    article_results.append(result)\n",
    "                    \n",
    "                    if save_tsv:\n",
    "                        tsv_lines = detector.format_output_tsv(result)\n",
    "                        tsv_outputs.extend(tsv_lines)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        num_paragraphs = len(result['paragraph_results'])\n",
    "                        num_with_tech = sum(1 for p in result['paragraph_results'] if p['num_techniques'] > 0)\n",
    "                        total_techniques = sum(p['num_techniques'] for p in result['paragraph_results'])\n",
    "                        print(f\"  ‚úì TODO: translate to English: {num_with_tech}/{num_paragraphs} paragraph(s)TODO: translate to English, total {total_techniques} TODO: translate to Englishtechnique instance(s)\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ùå Error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # TODO: translate to EnglishTSV üÜï TODO: translate to English\n",
    "            if save_tsv and tsv_outputs:\n",
    "                detector_name_safe = detector_name.replace(' ', '_').replace(':', '').replace('(', '').replace(')', '')\n",
    "                tsv_filename = output_path / f\"results_{lang_code}_{detector_name_safe}.tsv\"\n",
    "                \n",
    "                with open(tsv_filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"article_id\\tstart_pos\\tend_pos\\ttechniques\\n\")\n",
    "                    for line in tsv_outputs:\n",
    "                        f.write(line + '\\n')\n",
    "                \n",
    "                print(f\"\\nüíæ TSVTODO: translate to English: {tsv_filename}\")\n",
    "            \n",
    "            # TODO: translate to EnglishJSON üÜï TODO: translate to English\n",
    "            if save_json and article_results:\n",
    "                detector_name_safe = detector_name.replace(' ', '_').replace(':', '').replace('(', '').replace(')', '')\n",
    "                json_filename = output_path / f\"results_{lang_code}_{detector_name_safe}_detailed.json\"\n",
    "                \n",
    "                total_paragraphs = sum(len(r['paragraph_results']) for r in article_results)\n",
    "                total_paras_with_tech = sum(\n",
    "                    sum(1 for p in r['paragraph_results'] if p['num_techniques'] > 0)\n",
    "                    for r in article_results\n",
    "                )\n",
    "                total_technique_instances = sum(\n",
    "                    sum(p['num_techniques'] for p in r['paragraph_results'])\n",
    "                    for r in article_results\n",
    "                )\n",
    "                \n",
    "                technique_counter = {}\n",
    "                for result in article_results:\n",
    "                    for para_result in result['paragraph_results']:\n",
    "                        for tech in para_result['detected_techniques']:\n",
    "                            technique_counter[tech] = technique_counter.get(tech, 0) + 1\n",
    "                \n",
    "                json_data = {\n",
    "                    'metadata': {\n",
    "                        'language': lang_info['name'],\n",
    "                        'language_code': lang_code,\n",
    "                        'detector_name': detector_name,\n",
    "                        'total_articles': len(article_results),\n",
    "                        'total_paragraphs': total_paragraphs,\n",
    "                        'paragraphs_with_techniques': total_paras_with_tech,\n",
    "                        'total_technique_instances': total_technique_instances,\n",
    "                        'technique_frequency': dict(sorted(technique_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "                    },\n",
    "                    'articles': article_results\n",
    "                }\n",
    "                \n",
    "                with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                print(f\"üíæ JSONTODO: translate to English: {json_filename}\")\n",
    "            \n",
    "            # TODO: translate to English\n",
    "            lang_elapsed = time.time() - lang_start_time\n",
    "            \n",
    "            if article_results:\n",
    "                total_paragraphs = sum(len(r['paragraph_results']) for r in article_results)\n",
    "                total_paras_with_tech = sum(\n",
    "                    sum(1 for p in r['paragraph_results'] if p['num_techniques'] > 0)\n",
    "                    for r in article_results\n",
    "                )\n",
    "                total_technique_instances = sum(\n",
    "                    sum(p['num_techniques'] for p in r['paragraph_results'])\n",
    "                    for r in article_results\n",
    "                )\n",
    "                \n",
    "                technique_counter = {}\n",
    "                for result in article_results:\n",
    "                    for para_result in result['paragraph_results']:\n",
    "                        for tech in para_result['detected_techniques']:\n",
    "                            technique_counter[tech] = technique_counter.get(tech, 0) + 1\n",
    "                \n",
    "                summary = {\n",
    "                    'language': lang_code,\n",
    "                    'language_name': lang_info['name'],\n",
    "                    'detector_name': detector_name,\n",
    "                    'num_articles_processed': len(article_results),\n",
    "                    'total_paragraphs': total_paragraphs,\n",
    "                    'paragraphs_with_techniques': total_paras_with_tech,\n",
    "                    'total_technique_instances': total_technique_instances,\n",
    "                    'technique_frequency': dict(sorted(technique_counter.items(), key=lambda x: x[1], reverse=True)),\n",
    "                    'elapsed_time': lang_elapsed\n",
    "                }\n",
    "                \n",
    "                print(f\"\\n‚úì {lang_info['name']}TODO: translate to English (TODO: translate to English: {lang_elapsed:.1f}TODO: translate to English):\")\n",
    "                print(f\"  Processing articleTODO: translate to English: {len(article_results)}\")\n",
    "                print(f\"  TODO: translate to Englishparagraph(s)TODO: translate to English: {total_paragraphs}\")\n",
    "                print(f\"  TODO: translate to Englishparagraph(s): {total_paras_with_tech} ({(total_paras_with_tech/total_paragraphs*100):.1f}%)\")\n",
    "                print(f\"  TODO: translate to Englishtechnique instance(s)TODO: translate to English: {total_technique_instances}\")\n",
    "                \n",
    "                if technique_counter:\n",
    "                    print(f\"\\n  üîù Most common techniques (Top 5):\")\n",
    "                    for tech, count in list(sorted(technique_counter.items(), key=lambda x: x[1], reverse=True))[:5]:\n",
    "                        percentage = (count / total_technique_instances) * 100 if total_technique_instances > 0 else 0\n",
    "                        print(f\"    {tech}: {count} ({percentage:.1f}%)\")\n",
    "            else:\n",
    "                summary = {'language': lang_code, 'error': 'TODO: translate to English'}\n",
    "            \n",
    "            all_results[lang_code] = summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå {lang_info['name']}TODO: translate to English: {e}\")\n",
    "            all_results[lang_code] = {'error': str(e)}\n",
    "    \n",
    "    total_elapsed = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üìä TODO: translate to English - {detector_name}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'TODO: translate to English':<15} {'TODO: translate to English':<8} {'TODO: translate to Englishparagraph(s)':<10} {'TODO: translate to Englishparagraph(s)':<12} {'technique instance(s)':<10} {'TODO: translate to English':<10}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for lang_code in languages_to_test:\n",
    "        if lang_code not in all_results:\n",
    "            continue\n",
    "        \n",
    "        result = all_results[lang_code]\n",
    "        lang_info = language_display.get(lang_code, {'name': lang_code.upper()})\n",
    "        lang_name = lang_info['name']\n",
    "        \n",
    "        if 'error' in result:\n",
    "            error_msg = result['error'][:20]\n",
    "            print(f\"{lang_name:<15} {'N/A':<8} {'N/A':<10} {'N/A':<12} {'N/A':<10} {error_msg:<10}\")\n",
    "        else:\n",
    "            num_articles = result['num_articles_processed']\n",
    "            total_paras = result.get('total_paragraphs', 0)\n",
    "            paras_with_tech = result.get('paragraphs_with_techniques', 0)\n",
    "            tech_instances = result.get('total_technique_instances', 0)\n",
    "            elapsed = result.get('elapsed_time', 0)\n",
    "            print(f\"{lang_name:<15} {num_articles:<8} {total_paras:<10} {paras_with_tech:<12} {tech_instances:<10} {elapsed:<9.1f}s\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'TODO: translate to English':<15} {'':<8} {'':<10} {'':<12} {'':<10} {total_elapsed:<9.1f}s\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "print(\"‚úì TODO: translate to English batch_detect_unified TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TODO: translate to English!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "def compare_detectors(\n",
    "    data_base_dir: str,\n",
    "    language_configs: Dict,\n",
    "    detectors: Dict,  # {'TODO: translate to English': TODO: translate to English}\n",
    "    evaluator: PropagandaEvaluator,\n",
    "    languages_to_test: List[str] = None,\n",
    "    num_articles_per_language: int = None,\n",
    "    min_paragraph_length: int = 50,\n",
    "    overlap_threshold: float = 0.5,\n",
    "    save_tsv: bool = False\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    TODO: translate to English\n",
    "    \n",
    "    Args:\n",
    "        detectors: TODO: translate to EnglishÔºåTODO: translate to English {'TODO: translate to English': TODO: translate to English}\n",
    "        TODO: translate to English batch_test_all_languages\n",
    "    \n",
    "    Returns:\n",
    "        TODO: translate to English\n",
    "    \"\"\"\n",
    "    \n",
    "    all_detector_results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üî¨ TODO: translate to English\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"TODO: translate to English: {len(detectors)}\")\n",
    "    print(f\"TODO: translate to English: {', '.join(detectors.keys())}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    for detector_name, detector in detectors.items():\n",
    "        print(f\"\\n{'#'*70}\")\n",
    "        print(f\"# TODO: translate to English: {detector_name}\")\n",
    "        print(f\"{'#'*70}\\n\")\n",
    "        \n",
    "        results = batch_test_all_languages(\n",
    "            data_base_dir=data_base_dir,\n",
    "            language_configs=language_configs,\n",
    "            detector=detector,\n",
    "            evaluator=evaluator,\n",
    "            detector_name=detector_name,\n",
    "            languages_to_test=languages_to_test,\n",
    "        \n",
    "            num_articles_per_language=num_articles_per_language,\n",
    "            min_paragraph_length=min_paragraph_length,\n",
    "            overlap_threshold=overlap_threshold,\n",
    "            verbose=False,  # TODO: translate to English\n",
    "            save_tsv=save_tsv\n",
    "        )\n",
    "        \n",
    "        all_detector_results[detector_name] = results\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä TODO: translate to English\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if languages_to_test is None:\n",
    "        languages_to_test = list(language_configs.keys())\n",
    "    \n",
    "    for lang_code in languages_to_test:\n",
    "        lang_name = language_configs[lang_code]['name']\n",
    "        print(f\"\\n{lang_name}:\")\n",
    "        print(f\"{'TODO: translate to English':<25} {'TODO: translate to EnglishF1':<12} {'TODO: translate to EnglishF1':<12} {'TODO: translate to English/TODO: translate to English':<15}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        for detector_name in detectors.keys():\n",
    "            result = all_detector_results[detector_name].get(lang_code, {})\n",
    "            \n",
    "            if 'error' in result:\n",
    "                print(f\"{detector_name:<25} {'N/A':<12} {'N/A':<12} {'N/A':<15}\")\n",
    "            else:\n",
    "                span_f1 = result.get('avg_span_f1', 0)\n",
    "                tech_f1 = result.get('avg_tech_f1', 0)\n",
    "                detected = result.get('total_detected_spans', 0)\n",
    "                gold = result.get('total_gold_spans', 0)\n",
    "                \n",
    "                print(f\"{detector_name:<25} {span_f1:<11.1%} {tech_f1:<11.1%} {detected}/{gold:<13}\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return all_detector_results\n",
    "\n",
    "\n",
    "print(\"‚úì TODO: translate to English!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Language codeTODO: translate to EnglishÔºöTODO: translate to English -> TODO: translate to English\n",
    "LANGUAGE_CONFIGS = {\n",
    "    'ru': {\n",
    "        'name': 'Russian',\n",
    "        'code': 'RU',\n",
    "        'flag': 'üá∑üá∫',\n",
    "        'annotation_file': 'subtask-2-annotations.txt'\n",
    "    },\n",
    "    'po': {\n",
    "        'name': 'Polish', \n",
    "        'code': 'PL',\n",
    "        'flag': 'üáµüá±',\n",
    "        'annotation_file': 'subtask-2-annotations.txt'\n",
    "    },\n",
    "    'bg': {\n",
    "        'name': 'TODO: translate to English',\n",
    "        'code': 'BG', \n",
    "        'flag': 'üáßüá¨',\n",
    "        'annotation_file': 'subtask-2-annotations.txt'\n",
    "    },\n",
    "    'en': {\n",
    "        'name': 'English',\n",
    "        'code': 'EN',\n",
    "        'flag': 'üá∫üá∏',  # TODO: translate to English üá∫üá∏\n",
    "        'annotation_file': 'subtask-2-annotations.txt'\n",
    "    },\n",
    "}\n",
    "\n",
    "LANGUAGE_CODE_MAP = {lang: config['code'] for lang, config in LANGUAGE_CONFIGS.items()}\n",
    "\n",
    "\n",
    "def load_articles_from_path(article_dir: str, language: str = None, label: str = None):\n",
    "    \"\"\"\n",
    "    TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    \n",
    "    Args:\n",
    "        article_dir: TODO: translate to English\n",
    "        language: Language codeÔºàTODO: translate to EnglishÔºåTODO: translate to EnglishÔºâ\n",
    "        label: TODO: translate to EnglishÔºàTODO: translate to EnglishÔºåTODO: translate to English 'train', 'dev', 'test' TODO: translate to EnglishÔºâ\n",
    "    \n",
    "    Returns:\n",
    "        list: TODO: translate to English\n",
    "    \"\"\"\n",
    "    if not os.path.exists(article_dir):\n",
    "        print(f\"‚úó TODO: translate to English: {article_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÇ TODO: translate to English: {article_dir}\")\n",
    "    if language:\n",
    "        lang_info = LANGUAGE_CONFIGS.get(language, {})\n",
    "        print(f\"üåç TODO: translate to English: {lang_info.get('flag', '')} {lang_info.get('name', language)}\")\n",
    "    if label:\n",
    "        print(f\"üè∑Ô∏è  TODO: translate to English: {label}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # TODO: translate to English .txt TODO: translate to English\n",
    "    articles = []\n",
    "    all_txt_files = list(Path(article_dir).glob('*.txt'))\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    txt_files = [\n",
    "        f for f in all_txt_files \n",
    "        if not f.name.startswith('._') and not f.name.startswith('.')\n",
    "    ]\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"‚úó TODO: translate to English .txt TODO: translate to English\")\n",
    "        if all_txt_files:\n",
    "            print(f\"  (TODO: translate to English {len(all_txt_files)} TODO: translate to EnglishÔºåTODO: translate to English)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÑ TODO: translate to English {len(txt_files)} TODO: translate to English\", end='')\n",
    "    if len(all_txt_files) > len(txt_files):\n",
    "        print(f\" (TODO: translate to English {len(all_txt_files) - len(txt_files)} TODO: translate to English)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    failed_count = 0\n",
    "    for txt_file in txt_files:\n",
    "        try:\n",
    "            # TODO: translate to English\n",
    "            content = None\n",
    "            for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:\n",
    "                try:\n",
    "                    with open(txt_file, 'r', encoding=encoding) as f:\n",
    "                        content = f.read().strip()\n",
    "                    break  # TODO: translate to EnglishÔºåTODO: translate to English\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            \n",
    "            if content is None:\n",
    "                print(f\"  ‚ö†Ô∏è TODO: translate to English {txt_file.name}\")\n",
    "                failed_count += 1\n",
    "                continue\n",
    "            \n",
    "            if content:  # TODO: translate to English\n",
    "                articles.append({\n",
    "                    'filename': txt_file.name,\n",
    "                    'text': content,\n",
    "                    'language': language if language else 'unknown',\n",
    "                    'label': label if label else 'unlabeled',\n",
    "                    'source_path': str(article_dir),\n",
    "                    'char_count': len(content),\n",
    "                    'word_count': len(content.split())\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è TODO: translate to English {txt_file.name}: {e}\")\n",
    "            failed_count += 1\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úì TODO: translate to English {len(articles)} TODO: translate to English\", end='')\n",
    "    if failed_count > 0:\n",
    "        print(f\" (TODO: translate to English: {failed_count})\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    if articles:\n",
    "        total_chars = sum(a['char_count'] for a in articles)\n",
    "        total_words = sum(a['word_count'] for a in articles)\n",
    "        avg_chars = total_chars / len(articles)\n",
    "        avg_words = total_words / len(articles)\n",
    "        \n",
    "        print(f\"\\nüìä TODO: translate to English:\")\n",
    "        print(f\"  - TODO: translate to English: {len(articles)}\")\n",
    "        print(f\"  - TODO: translate to English: {total_chars:,}\")\n",
    "        print(f\"  - TODO: translate to English: {total_words:,}\")\n",
    "        print(f\"  - TODO: translate to English/TODO: translate to English: {avg_chars:.0f}\")\n",
    "        print(f\"  - TODO: translate to English/TODO: translate to English: {avg_words:.0f}\")\n",
    "    \n",
    "    return articles\n",
    "\n",
    "\n",
    "def load_multiple_sources(sources: list):\n",
    "    \"\"\"\n",
    "    TODO: translate to English\n",
    "    \n",
    "    Args:\n",
    "        sources: TODO: translate to EnglishÔºåTODO: translate to EnglishÔºåTODO: translate to English:\n",
    "                - 'path': TODO: translate to English\n",
    "                - 'language': Language codeÔºàTODO: translate to EnglishÔºâ\n",
    "                - 'label': TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    \n",
    "    Returns:\n",
    "        dict: TODO: translate to EnglishÔºåTODO: translate to English\n",
    "    \"\"\"\n",
    "    all_articles = {}\n",
    "    \n",
    "    for source in sources:\n",
    "        path = source['path']\n",
    "        language = source.get('language')\n",
    "        label = source.get('label', 'default')\n",
    "        \n",
    "        articles = load_articles_from_path(path, language, label)\n",
    "        \n",
    "        if articles:\n",
    "            all_articles[label] = articles\n",
    "    \n",
    "    return all_articles\n",
    "\n",
    "\n",
    "def show_article_sample(articles, index=0):\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    if not articles or index >= len(articles):\n",
    "        print(\"‚úó TODO: translate to English\")\n",
    "        return\n",
    "    \n",
    "    article = articles[index]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TODO: translate to English [{index+1}/{len(articles)}]\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"üìÑ TODO: translate to English: {article['filename']}\")\n",
    "    print(f\"üåç TODO: translate to English: {article['language']}\")\n",
    "    print(f\"üè∑Ô∏è  TODO: translate to English: {article['label']}\")\n",
    "    print(f\"üìÇ TODO: translate to English: {article['source_path']}\")\n",
    "    print(f\"üìè TODO: translate to English: {article['char_count']} TODO: translate to English, {article['word_count']} TODO: translate to English\")\n",
    "    # print(f\"{'‚îÄ'*70}\")\n",
    "    # print(\"TODO: translate to English300TODO: translate to English:\")\n",
    "    # print(f\"{'‚îÄ'*70}\")\n",
    "    # print(article['text'][:300])\n",
    "    # if len(article['text']) > 300:\n",
    "    #     print(f\"\\n... (TODO: translate to English {len(article['text']) - 300} TODO: translate to English)\")\n",
    "    # print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "def print_summary(all_articles: dict):\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä TODO: translate to English\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_articles = 0\n",
    "    for label, articles in all_articles.items():\n",
    "        print(f\"‚úì {label}: {len(articles)} TODO: translate to English\")\n",
    "        total_articles += len(articles)\n",
    "    \n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    print(f\"TODO: translate to English: {total_articles} TODO: translate to English\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: translate to English\n",
    "# ============================================================\n",
    "# TODO: translate to EnglishRussianTODO: translate to EnglishPolishÔºàTODO: translate to EnglishÔºâ\n",
    "# ============================================================\n",
    "\n",
    "# # TODO: translate to English\n",
    "# test_data_sources = [\n",
    "#     {\n",
    "#         'path': 'your_dev_articles_subtask_3_directory__ru',\n",
    "#         'language': 'ru',\n",
    "#         'label': 'ru'\n",
    "#     },\n",
    "#     {\n",
    "#         'path': 'your_dev_articles_subtask_3_directory',\n",
    "#         'language': 'po',\n",
    "#         'label': 'po'\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # TODO: translate to English\n",
    "# test_articles = load_multiple_sources(test_data_sources)\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to EnglishRussianÔºàTODO: translate to EnglishRussianTODO: translate to EnglishÔºâ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"üá∑üá∫\"*35)\n",
    "print(\"TODO: translate to EnglishRussianTODO: translate to English - TODO: translate to EnglishRussianTODO: translate to English\")\n",
    "print(\"üá∑üá∫\"*35 + \"\\n\")\n",
    "\n",
    "results_ru = batch_detect_unified(\n",
    "    # ============================================================\n",
    "    # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    # ============================================================\n",
    "    \n",
    "    articles_dict={'ru': test_articles['ru']},\n",
    "    # üìö TODO: translate to English\n",
    "    # TODO: translate to EnglishÔºö{Language code: TODO: translate to English/TODO: translate to English}\n",
    "    \n",
    "    detector=context_detector_ru,\n",
    "    # üîç TODO: translate to English\n",
    "    # TODO: translate to Englishpropaganda\n",
    "    # TODO: translate to EnglishÔºÅRussianTODO: translate to EnglishRussianTODO: translate to English\n",
    "    # TODO: translate to EnglishÔºö\n",
    "    # context_detector_po                  # TODO: translate to English\n",
    "    # voting_detector_po_balanced          # TODO: translate to English-TODO: translate to English\n",
    "    # voting_detector_po_conservative      # TODO: translate to English-TODO: translate to English  \n",
    "    # voting_detector_po_aggressive        # TODO: translate to English-TODO: translate to English\n",
    "\n",
    "    # # TODO: translate to EnglishÔºàTODO: translate to EnglishPolishTODO: translate to EnglishÔºâ\n",
    "    # context_detector                     # = context_detector_po\n",
    "    # voting_detector_balanced             # = voting_detector_po_balanced\n",
    "    # voting_detector_conservative         # = voting_detector_po_conservative\n",
    "    # voting_detector_aggressive           # = voting_detector_po_aggressive\n",
    "    \n",
    "    # ============================================================\n",
    "    # TODO: translate to English\n",
    "    # ============================================================\n",
    "    \n",
    "    detector_name=\"results_po_checkthat2024_dev_Ordinary_strict\",\n",
    "    # - TODO: translate to English\n",
    "    # TODO: translate to EnglishÔºöresults_ru_RussianTODO: translate to English.tsv\n",
    "    \n",
    "    languages_to_test=['ru'],\n",
    "    # üåç TODO: translate to English\n",
    "    # TODO: translate to English articles_dict TODO: translate to English\n",
    "    \n",
    "    num_articles_per_language=1,\n",
    "    # üìä TODO: translate to English\n",
    "    # - 10: TODO: translate to English10TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    # - None: TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    \n",
    "    # ============================================================\n",
    "    # TODO: translate to English\n",
    "    # ============================================================\n",
    "    \n",
    "    save_tsv=True,\n",
    "    # üíæ TODO: translate to EnglishTSVTODO: translate to English\n",
    "    # True: TODO: translate to English results_ru_RussianTODO: translate to English.tsv\n",
    "    # TSVTODO: translate to EnglishÔºöarticle_id    start_pos    end_pos    techniques\n",
    "    \n",
    "    save_json=True,\n",
    "    # üíæ TODO: translate to EnglishJSONTODO: translate to English\n",
    "    # True: TODO: translate to English results_ru_RussianTODO: translate to English_detailed.json\n",
    "    # TODO: translate to EnglishÔºöTODO: translate to English„ÄÅTODO: translate to English„ÄÅTODO: translate to English\n",
    "    \n",
    "    verbose=True,\n",
    "    # üì¢ TODO: translate to English\n",
    "    # True: TODO: translate to English\n",
    "    #   \"Processing article 1/10: article3428.txt\"\n",
    "    #   \"‚úì TODO: translate to English: 3/13 paragraph(s)TODO: translate to English, total 8 TODO: translate to Englishtechnique instance(s)\"\n",
    "    # False: TODO: translate to English\n",
    "    \n",
    "    # ============================================================\n",
    "    # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    # ============================================================\n",
    "    \n",
    "    # evaluator=None,\n",
    "    # üéØ TODO: translate to EnglishÔºàTODO: translate to English None = TODO: translate to EnglishÔºâ\n",
    "    # TODO: translate to EnglishÔºöTODO: translate to EnglishF1/TODO: translate to English/TODO: translate to English\n",
    "    # NoneÔºöTODO: translate to EnglishÔºåTODO: translate to English\n",
    "    \n",
    "    # gold_annotations=None,\n",
    "    # üìã TODO: translate to EnglishÔºàTODO: translate to English NoneÔºâ\n",
    "    # TODO: translate to EnglishÔºö{'ru': {article_id: [TODO: translate to English]}}\n",
    "    # TODO: translate to English\n",
    "    \n",
    "    # min_paragraph_length=50,\n",
    "    # üìè TODO: translate to Englishparagraph(s)TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    # TODO: translate to Englishparagraph(s)TODO: translate to English\n",
    "    # TODO: translate to EnglishÔºö50\n",
    "    \n",
    "    # overlap_threshold=0.5,\n",
    "    # üéöÔ∏è TODO: translate to English\n",
    "    # TODO: translate to English\n",
    "    # TODO: translate to EnglishÔºö0.5\n",
    ")\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # TODO: translate to English\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"üìä TODO: translate to English\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# print(f\"\\n{'TODO: translate to English':<15} {'TODO: translate to English':<10} {'technique instance(s)':<10} {'TODO: translate to Englishparagraph(s)':<15}\")\n",
    "# print(\"-\"*50)\n",
    "\n",
    "# if 'ru' in results_ru and 'error' not in results_ru['ru']:\n",
    "#     r = results_ru['ru']\n",
    "#     print(f\"{'Russian':<15} {r['num_articles_processed']:<10} {r['total_technique_instances']:<10} {r['paragraphs_with_techniques']}/{r['total_paragraphs']}\")\n",
    "\n",
    "# if 'po' in results_po and 'error' not in results_po['po']:\n",
    "#     r = results_po['po']\n",
    "#     print(f\"{'Polish':<15} {r['num_articles_processed']:<10} {r['total_technique_instances']:<10} {r['paragraphs_with_techniques']}/{r['total_paragraphs']}\")\n",
    "\n",
    "# print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÇ TODO: translate to English: /home/jovyan/2023task3/data/ru/dev-articles-subtask-3\n",
      "üåç TODO: translate to English: üá∑üá∫ Russian\n",
      "üè∑Ô∏è  TODO: translate to English: ru\n",
      "======================================================================\n",
      "üìÑ TODO: translate to English 48 TODO: translate to English (TODO: translate to English 1 TODO: translate to English)\n",
      "‚úì TODO: translate to English 48 TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "  - TODO: translate to English: 48\n",
      "  - TODO: translate to English: 162,025\n",
      "  - TODO: translate to English: 22,383\n",
      "  - TODO: translate to English/TODO: translate to English: 3376\n",
      "  - TODO: translate to English/TODO: translate to English: 466\n",
      "\n",
      "======================================================================\n",
      "üìÇ TODO: translate to English: /home/jovyan/2023task3/data/po/dev-articles-subtask-3\n",
      "üåç TODO: translate to English: üáµüá± Polish\n",
      "üè∑Ô∏è  TODO: translate to English: po\n",
      "======================================================================\n",
      "üìÑ TODO: translate to English 49 TODO: translate to English (TODO: translate to English 1 TODO: translate to English)\n",
      "‚úì TODO: translate to English 49 TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "  - TODO: translate to English: 49\n",
      "  - TODO: translate to English: 263,072\n",
      "  - TODO: translate to English: 37,221\n",
      "  - TODO: translate to English/TODO: translate to English: 5369\n",
      "  - TODO: translate to English/TODO: translate to English: 760\n",
      "\n",
      "======================================================================\n",
      "üìÇ TODO: translate to English: /home/jovyan/2023task3/data/en/dev-articles-subtask-3\n",
      "üåç TODO: translate to English: üá∫üá∏ English\n",
      "üè∑Ô∏è  TODO: translate to English: en\n",
      "======================================================================\n",
      "üìÑ TODO: translate to English 90 TODO: translate to English\n",
      "‚úì TODO: translate to English 90 TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "  - TODO: translate to English: 90\n",
      "  - TODO: translate to English: 402,510\n",
      "  - TODO: translate to English: 66,938\n",
      "  - TODO: translate to English/TODO: translate to English: 4472\n",
      "  - TODO: translate to English/TODO: translate to English: 744\n"
     ]
    }
   ],
   "source": [
    "# TODO: translate to English\n",
    "test_data_sources = [\n",
    "    {\n",
    "        'path': 'your_dev_articles_subtask_3_directory__ru_2',\n",
    "        'language': 'ru',\n",
    "        'label': 'ru'\n",
    "    },\n",
    "    {\n",
    "        'path': 'your_dev_articles_subtask_3_directory__po',\n",
    "        'language': 'po',\n",
    "        'label': 'po'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'path': 'your_dev_articles_subtask_3_directory__en',\n",
    "        'language': 'en',\n",
    "        'label': 'en'\n",
    "    }\n",
    "]\n",
    "\n",
    "# TODO: translate to English\n",
    "test_articles = load_multiple_sources(test_data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: translate to English - TODO: translate to EnglishID + TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# üéØ TODO: translate to English!\n",
    "# ============================================================\n",
    "\n",
    "LANGUAGE = 'en'      # TODO: translate to English: 'ru', 'po', 'en'\n",
    "DETECTOR_TYPE = 'voting_aggressive'  # TODO: translate to English: 'context', 'voting_aggressiveTODO: translate to English', 'voting_balanced', 'voting_conservative'\n",
    "BATCH_SIZE = 24\n",
    "NUM_BATCHES = 4  # TODO: translate to English\n",
    "SLEEP_TIME = 1\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English(TODO: translate to English)\n",
    "# ============================================================\n",
    "\n",
    "# TODO: translate to English\n",
    "DETECTOR_CONFIG = {\n",
    "    'ru': {\n",
    "        'context': context_detector_ru,\n",
    "        'voting_aggressive': voting_detector_ru_aggressive,\n",
    "        'voting_balanced': voting_detector_ru_balanced,\n",
    "        'voting_conservative': voting_detector_ru_conservative\n",
    "    },\n",
    "    'po': {\n",
    "        'context': context_detector_po,\n",
    "        'voting_aggressive': voting_detector_po_aggressive,\n",
    "        'voting_balanced': voting_detector_po_balanced,\n",
    "        'voting_conservative': voting_detector_po_conservative\n",
    "    },\n",
    "    'en': {\n",
    "        'context': context_detector_en,\n",
    "        'voting_aggressive': voting_detector_en_aggressive,\n",
    "        'voting_balanced': voting_detector_en_balanced,\n",
    "        'voting_conservative': voting_detector_en_conservative\n",
    "    }\n",
    "}\n",
    "\n",
    "# TODO: translate to English\n",
    "LANGUAGE_INFO = {\n",
    "    'ru': {'name': 'Russian', 'flag': 'üá∑üá∫'},\n",
    "    'po': {'name': 'Polish', 'flag': 'üáµüá±'},\n",
    "    'en': {'name': 'English', 'flag': 'üá∫üá∏'}  # TODO: translate to English üá∫üá∏\n",
    "}\n",
    "\n",
    "# TODO: translate to English\n",
    "DETECTOR_INFO = {\n",
    "    'context': {'name': 'TODO: translate to English', 'icon': 'üîç'},\n",
    "    'voting_aggressive': {'name': 'TODO: translate to English(TODO: translate to English)', 'icon': 'üöÄ'},\n",
    "    'voting_balanced': {'name': 'TODO: translate to English(TODO: translate to English)', 'icon': '‚öñÔ∏è'},\n",
    "    'voting_conservative': {'name': 'TODO: translate to English(TODO: translate to English)', 'icon': 'üõ°Ô∏è'}\n",
    "}\n",
    "\n",
    "# TODO: translate to English\n",
    "OUTPUT_DIR = \"your_llm_tests_directory\"\n",
    "\n",
    "# ============================================================\n",
    "# TODO: translate to English(TODO: translate to English)\n",
    "# ============================================================\n",
    "\n",
    "# TODO: translate to English\n",
    "data_var = None\n",
    "data_key = None\n",
    "\n",
    "if 'all_data' in dir():\n",
    "    data_var = all_data\n",
    "    # all_data TODO: translate to English 'ru_dev', 'po_dev', 'en_dev' TODO: translate to English\n",
    "    if f'{LANGUAGE}_dev' in all_data:\n",
    "        data_key = f'{LANGUAGE}_dev'\n",
    "    elif LANGUAGE in all_data:\n",
    "        data_key = LANGUAGE\n",
    "elif 'test_articles' in dir():\n",
    "    data_var = test_articles\n",
    "    # test_articles TODO: translate to English 'ru', 'po', 'en' TODO: translate to English\n",
    "    data_key = LANGUAGE\n",
    "\n",
    "if data_var is None or data_key is None:\n",
    "    print(\"‚ùå Error: TODO: translate to English\")\n",
    "    print(\"\\nTODO: translate to English:\")\n",
    "    if 'all_data' in dir():\n",
    "        print(f\"  all_data TODO: translate to English: {list(all_data.keys())}\")\n",
    "    if 'test_articles' in dir():\n",
    "        print(f\"  test_articles TODO: translate to English: {list(test_articles.keys())}\")\n",
    "    raise ValueError(\"TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ TODO: translate to English - TODO: translate to EnglishID\n",
      "======================================================================\n",
      "TODO: translate to English: en (total 90 TODO: translate to English)\n",
      "TODO: translate to English: üá∫üá∏ English (en)\n",
      "TODO: translate to English: üöÄ TODO: translate to English(TODO: translate to English)\n",
      "TODO: translate to English: 4 TODO: translate to English √ó 24 TODO: translate to English/TODO: translate to English\n",
      "TODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üá∫üá∏ TODO: translate to English 2/4: TODO: translate to English 25-48 (total24TODO: translate to English)\n",
      "‚è∞ TODO: translate to English: 09:31:23\n",
      "\n",
      "üìã TODO: translate to English:\n",
      "    1. article833013834\n",
      "    2. article817408115\n",
      "    3. article813552066\n",
      "    4. article832926076\n",
      "    5. article832934428\n",
      "    6. article817190270\n",
      "    7. article833028146\n",
      "    8. article824684605\n",
      "    9. article833050243\n",
      "   10. article814630609\n",
      "   11. article829815104\n",
      "   12. article824256050\n",
      "   13. article813603860\n",
      "   14. article813992175\n",
      "   15. article833036176\n",
      "   16. article814404002\n",
      "   17. article818141325\n",
      "   18. article820419869\n",
      "   19. article832984694\n",
      "   20. article833036489\n",
      "   21. article830821478\n",
      "   22. article817449755\n",
      "   23. article814371058\n",
      "   24. article832920387\n",
      "\n",
      "üöÄ TODO: translate to English...\n",
      "\n",
      "üìÅ TODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests\n",
      "\n",
      "======================================================================\n",
      "üöÄ TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ: results_semeval_task3_dev_en_voting_aggressive_batch2\n",
      "======================================================================\n",
      "TODO: translate to English: en\n",
      "TODO: translate to English: TODO: translate to English\n",
      "‚úì TODO: translate to EnglishTSVTODO: translate to English\n",
      "‚úì TODO: translate to EnglishJSONTODO: translate to English\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üá¨üáß [1/1] TODO: translate to English English (EN)\n",
      "======================================================================\n",
      "\n",
      "  ‚ÑπÔ∏è  DetectedTODO: translate to EnglishÔºåTODO: translate to English...\n",
      "  ‚úì TODO: translate to English: 24 TODO: translate to English\n",
      "‚úì TODO: translate to English 24 TODO: translate to English\n",
      "\n",
      "üîç TODO: translate to English...\n",
      "\n",
      "üíæ TSVTODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests/results_en_results_semeval_task3_dev_en_voting_aggressive_batch2.tsv\n",
      "üíæ JSONTODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests/results_en_results_semeval_task3_dev_en_voting_aggressive_batch2_detailed.json\n",
      "\n",
      "‚úì EnglishTODO: translate to English (TODO: translate to English: 15647.6TODO: translate to English):\n",
      "  Processing articleTODO: translate to English: 24\n",
      "  TODO: translate to Englishparagraph(s)TODO: translate to English: 705\n",
      "  TODO: translate to Englishparagraph(s): 173 (24.5%)\n",
      "  TODO: translate to Englishtechnique instance(s)TODO: translate to English: 545\n",
      "\n",
      "  üîù Most common techniques (Top 5):\n",
      "    Loaded_Language: 113 (20.7%)\n",
      "    Name_Calling_Labeling: 53 (9.7%)\n",
      "    Exaggeration_Minimisation: 52 (9.5%)\n",
      "    Conversation_Killer: 47 (8.6%)\n",
      "    Causal_Oversimplification: 36 (6.6%)\n",
      "\n",
      "======================================================================\n",
      "üìä TODO: translate to English - results_semeval_task3_dev_en_voting_aggressive_batch2\n",
      "======================================================================\n",
      "\n",
      "TODO: translate to English              TODO: translate to English      TODO: translate to Englishparagraph(s)        TODO: translate to Englishparagraph(s)        technique instance(s)       TODO: translate to English        \n",
      "----------------------------------------------------------------------\n",
      "English              24       705        173          545        15647.6  s\n",
      "----------------------------------------------------------------------\n",
      "TODO: translate to English                                                         15647.6  s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "‚úÖ TODO: translate to English 2 TODO: translate to English!\n",
      "   üìä TODO: translate to English: 24, TODO: translate to English: 545, TODO: translate to Englishparagraph(s): 173/705\n",
      "   ‚è±Ô∏è  TODO: translate to English: 260.8 TODO: translate to English\n",
      "   üìà TODO: translate to English: 2/4 (50%)\n",
      "   üîÆ TODO: translate to English: 260.8 TODO: translate to English\n",
      "   ‚úÖ TODO: translate to English: article833013834, article817408115, article813552066, article832926076, article832934428, article817190270, article833028146, article824684605, article833050243, article814630609, article829815104, article824256050, article813603860, article813992175, article833036176, article814404002, article818141325, article820419869, article832984694, article833036489, article830821478, article817449755, article814371058, article832920387\n",
      "\n",
      "‚è∏Ô∏è  TODO: translate to English 1 TODO: translate to English...\n",
      "   ‚è≥ TODO: translate to English 1 TODO: translate to English...\n",
      "\n",
      "======================================================================\n",
      "üéâ TODO: translate to English! üá∫üá∏ English - üöÄ TODO: translate to English(TODO: translate to English)\n",
      "======================================================================\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "  ‚úÖ TODO: translate to English: 1/4\n",
      "  üìù Processing article: 24 TODO: translate to English\n",
      "  üéØ TODO: translate to English: 545 TODO: translate to English\n",
      "  ‚è±Ô∏è  TODO: translate to English: 260.8 TODO: translate to English (4.35 TODO: translate to English)\n",
      "  üöÄ TODO: translate to English: 652.0 TODO: translate to English/TODO: translate to English\n",
      "\n",
      "üíæ TODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests/\n",
      "    üìÑ TODO: translate to English1: results_semeval_task3_dev_en_voting_aggressive_batch1.tsv / .json\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nüéØ TODO: translate to English - TODO: translate to EnglishÔºÅ\\n\\n1. TODO: translate to English:\\n   LANGUAGE = 'ru'    # Russian\\n   LANGUAGE = 'po'    # Polish\\n\\n2. TODO: translate to English:\\n   DETECTOR_TYPE = 'context'              # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\\n   DETECTOR_TYPE = 'voting_aggressive'    # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\\n   DETECTOR_TYPE = 'voting_balanced'      # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\\n   DETECTOR_TYPE = 'voting_conservative'  # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "# ============================================================\n",
    "\n",
    "# TODO: translate to English\n",
    "if LANGUAGE not in DETECTOR_CONFIG:\n",
    "    print(f\"‚ùå Error: TODO: translate to English '{LANGUAGE}'\")\n",
    "    print(f\"   TODO: translate to English: {list(DETECTOR_CONFIG.keys())}\")\n",
    "    raise ValueError(f\"TODO: translate to English: {LANGUAGE}\")\n",
    "\n",
    "if DETECTOR_TYPE not in DETECTOR_CONFIG[LANGUAGE]:\n",
    "    print(f\"‚ùå Error: TODO: translate to English '{DETECTOR_TYPE}'\")\n",
    "    print(f\"   TODO: translate to English: {list(DETECTOR_CONFIG[LANGUAGE].keys())}\")\n",
    "    raise ValueError(f\"TODO: translate to English: {DETECTOR_TYPE}\")\n",
    "\n",
    "# TODO: translate to English\n",
    "detector = DETECTOR_CONFIG[LANGUAGE][DETECTOR_TYPE]\n",
    "lang_info = LANGUAGE_INFO[LANGUAGE]\n",
    "detector_info = DETECTOR_INFO[DETECTOR_TYPE]\n",
    "\n",
    "# TODO: translate to English\n",
    "articles = data_var[data_key]\n",
    "total = len(articles)\n",
    "\n",
    "# TODO: translate to English\n",
    "print(\"=\"*70)\n",
    "print(f\"üöÄ TODO: translate to English - TODO: translate to EnglishID\")\n",
    "print(\"=\"*70)\n",
    "print(f\"TODO: translate to English: {data_key} (total {total} TODO: translate to English)\")\n",
    "print(f\"TODO: translate to English: {lang_info['flag']} {lang_info['name']} ({LANGUAGE})\")\n",
    "print(f\"TODO: translate to English: {detector_info['icon']} {detector_info['name']}\")\n",
    "print(f\"TODO: translate to English: {NUM_BATCHES} TODO: translate to English √ó {BATCH_SIZE} TODO: translate to English/TODO: translate to English\")\n",
    "print(f\"TODO: translate to English: {OUTPUT_DIR}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# TODO: translate to English\n",
    "all_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# for batch in range(1, NUM_BATCHES + 1):\n",
    "for batch in range(2, 3): \n",
    "    start_idx = (batch - 1) * BATCH_SIZE\n",
    "    end_idx = min(batch * BATCH_SIZE, total)\n",
    "    batch_articles = articles[start_idx:end_idx]\n",
    "    \n",
    "    print(f\"\\n{lang_info['flag']} TODO: translate to English {batch}/{NUM_BATCHES}: TODO: translate to English {start_idx+1}-{end_idx} (total{len(batch_articles)}TODO: translate to English)\")\n",
    "    print(f\"‚è∞ TODO: translate to English: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "\n",
    "    # üÜï TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "    print(f\"\\nüìã TODO: translate to English:\")\n",
    "    for i, article in enumerate(batch_articles):\n",
    "        article_id = article.get('filename', article.get('id', f'article_{start_idx + i + 1}'))\n",
    "        if article_id.endswith('.txt'):\n",
    "            article_id = article_id[:-4]\n",
    "        print(f\"   {i+1:2d}. {article_id}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ TODO: translate to English...\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    result = batch_detect_unified(\n",
    "        articles_dict={LANGUAGE: batch_articles},\n",
    "        detector=detector,\n",
    "        detector_name=f\"results_semeval_task3_dev_{LANGUAGE}_{DETECTOR_TYPE}_batch{batch}\",\n",
    "        languages_to_test=[LANGUAGE],\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_tsv=True,\n",
    "        save_json=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    all_results.append(result)\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    if LANGUAGE in result and 'error' not in result[LANGUAGE]:\n",
    "        r = result[LANGUAGE]\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_time_per_batch = elapsed / batch\n",
    "        remaining_time = avg_time_per_batch * (NUM_BATCHES - batch)\n",
    "        \n",
    "        print(f\"\\n‚úÖ TODO: translate to English {batch} TODO: translate to English!\")\n",
    "        print(f\"   üìä TODO: translate to English: {r['num_articles_processed']}, TODO: translate to English: {r['total_technique_instances']}, TODO: translate to Englishparagraph(s): {r['paragraphs_with_techniques']}/{r['total_paragraphs']}\")\n",
    "        print(f\"   ‚è±Ô∏è  TODO: translate to English: {r['elapsed_time']/60:.1f} TODO: translate to English\")\n",
    "        print(f\"   üìà TODO: translate to English: {batch}/{NUM_BATCHES} ({batch/NUM_BATCHES*100:.0f}%)\")\n",
    "        \n",
    "        if batch < NUM_BATCHES:\n",
    "            print(f\"   üîÆ TODO: translate to English: {remaining_time/60:.1f} TODO: translate to English\")\n",
    "        \n",
    "        # üÜï TODO: translate to English\n",
    "        print(f\"   ‚úÖ TODO: translate to English: {', '.join([article.get('filename', article.get('id', f'article_{i}')).replace('.txt', '') for i, article in enumerate(batch_articles)])}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå TODO: translate to English {batch} TODO: translate to English\")\n",
    "        if 'error' in result.get(LANGUAGE, {}):\n",
    "            print(f\"   Error: {result[LANGUAGE]['error']}\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    if batch < NUM_BATCHES and SLEEP_TIME > 0:\n",
    "        print(f\"\\n‚è∏Ô∏è  TODO: translate to English {SLEEP_TIME} TODO: translate to English...\")\n",
    "        for i in range(SLEEP_TIME, 0, -1):\n",
    "            if i % 10 == 0 or i <= 5:\n",
    "                print(f\"   ‚è≥ TODO: translate to English {i} TODO: translate to English...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "# TODO: translate to English\n",
    "total_time = time.time() - start_time\n",
    "successful = [r for r in all_results if LANGUAGE in r and 'error' not in r[LANGUAGE]]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üéâ TODO: translate to English! {lang_info['flag']} {lang_info['name']} - {detector_info['icon']} {detector_info['name']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if successful:\n",
    "    total_articles = sum(r[LANGUAGE]['num_articles_processed'] for r in successful)\n",
    "    total_tech = sum(r[LANGUAGE]['total_technique_instances'] for r in successful)\n",
    "    \n",
    "    print(f\"\\nüìä TODO: translate to English:\")\n",
    "    print(f\"  ‚úÖ TODO: translate to English: {len(successful)}/{NUM_BATCHES}\")\n",
    "    print(f\"  üìù Processing article: {total_articles} TODO: translate to English\")\n",
    "    print(f\"  üéØ TODO: translate to English: {total_tech} TODO: translate to English\")\n",
    "    print(f\"  ‚è±Ô∏è  TODO: translate to English: {total_time/60:.1f} TODO: translate to English ({total_time/3600:.2f} TODO: translate to English)\")\n",
    "    print(f\"  üöÄ TODO: translate to English: {total_time/total_articles:.1f} TODO: translate to English/TODO: translate to English\")\n",
    "    \n",
    "    print(f\"\\nüíæ TODO: translate to English: {OUTPUT_DIR}/\")\n",
    "    for i in range(1, len(successful) + 1):\n",
    "        print(f\"    üìÑ TODO: translate to English{i}: results_semeval_task3_dev_{LANGUAGE}_{DETECTOR_TYPE}_batch{i}.tsv / .json\") # TODO: translate to English\n",
    "else:\n",
    "    print(f\"\\n‚ùå TODO: translate to English\")\n",
    "    print(f\"   TODO: translate to English\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# üìñ TODO: translate to English\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "üéØ TODO: translate to English - TODO: translate to EnglishÔºÅ\n",
    "\n",
    "1. TODO: translate to English:\n",
    "   LANGUAGE = 'ru'    # Russian\n",
    "   LANGUAGE = 'po'    # Polish\n",
    "\n",
    "2. TODO: translate to English:\n",
    "   DETECTOR_TYPE = 'context'              # TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "   DETECTOR_TYPE = 'voting_aggressive'    # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "   DETECTOR_TYPE = 'voting_balanced'      # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "   DETECTOR_TYPE = 'voting_conservative'  # TODO: translate to English-TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}