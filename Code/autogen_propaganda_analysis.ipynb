{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Multi-Agent Propaganda Technique Analysis System\n",
    "\n",
    "This notebook uses the AutoGen framework to create specialized agents for each language-technique combination, analyzing and summarizing LLM prompts and keywords for each technique.\n",
    "\n",
    "## System Architecture\n",
    "- **Coordinator Agent**: Coordinates the entire analysis workflow\n",
    "- **Language-Technique Agents**: A dedicated agent for each language-technique combination\n",
    "- **Reviewer Agent**: Reviews and iteratively optimizes results\n",
    "\n",
    "## Workflow\n",
    "1. Load API configuration\n",
    "2. Scan all languages and techniques\n",
    "3. Create agents for each combination\n",
    "4. Collect articles from all frequency levels (high, medium, low)\n",
    "5. Agents analyze and generate prompts and keywords\n",
    "6. Iterate 3 times to optimize results\n",
    "7. Save analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "AutoGen version: 0.2.32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import autogen\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"AutoGen version: {autogen.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: your_data_directory\n",
      "API config: your_api_config_file\n",
      "Output directory: your_output_directory\n",
      "Iteration count: 3\n",
      "âœ… Configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Configure paths\n",
    "BASE_DATA_PATH = \"your_data_directory\"\n",
    "API_CONFIG_PATH = \"your_api_config_file\"\n",
    "OUTPUT_DIR = \"your_output_directory\"\n",
    "\n",
    "# Analysis parameters\n",
    "ITERATION_COUNT = 3  # Number of iterations\n",
    "FREQUENCY_LEVELS = ['high', 'medium', 'low']  # Frequency levels\n",
    "MAX_ARTICLES_PER_TECHNIQUE = 30  # Maximum number of articles to analyze per technique\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {BASE_DATA_PATH}\")\n",
    "print(f\"API config: {API_CONFIG_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Iteration count: {ITERATION_COUNT}\")\n",
    "print(\"âœ… Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API configuration loaded!\n",
      "Available models: 3\n",
      "Timeout setting: 180 seconds\n",
      "Primary models: ['gpt-4o-mini', 'gemini-1.5-flash', 'claude-3-haiku-20240307']\n",
      "âœ… API configuration loaded!\n",
      "Available models: 1\n",
      "Primary models: ['gpt-4o-mini']\n"
     ]
    }
   ],
   "source": [
    "def load_api_config(config_path):\n",
    "    \"\"\"Load API configuration file\"\"\"\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def setup_llm_config(api_config):\n",
    "    \"\"\"Setup LLM configuration (correct parameters)\"\"\"\n",
    "    api_keys = api_config['api_keys']\n",
    "    llm_config_list = []\n",
    "    \n",
    "    # OpenAI configuration\n",
    "    if api_keys.get('openai_api_key'):\n",
    "        llm_config_list.append({\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": api_keys['openai_api_key'],\n",
    "        })\n",
    "    \n",
    "    # Google Gemini configuration (recommended: faster and more stable)\n",
    "    if api_keys.get('google_api_key'):\n",
    "        llm_config_list.append({\n",
    "            \"model\": \"gemini-1.5-flash\",\n",
    "            \"api_key\": api_keys['google_api_key'],\n",
    "            \"api_type\": \"google\"\n",
    "        })\n",
    "    \n",
    "    # Anthropic configuration\n",
    "    if api_keys.get('anthropic_api_key'):\n",
    "        llm_config_list.append({\n",
    "            \"model\": \"claude-3-haiku-20240307\",\n",
    "            \"api_key\": api_keys['anthropic_api_key'],\n",
    "            \"api_type\": \"anthropic\"\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"timeout\": 180,  # Only keep timeout parameter (3 minutes)\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": llm_config_list,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "\n",
    "# Load configuration\n",
    "api_config = load_api_config(API_CONFIG_PATH)\n",
    "llm_config = setup_llm_config(api_config)\n",
    "\n",
    "print(f\"âœ… API configuration loaded!\")\n",
    "print(f\"Available models: {len(llm_config['config_list'])}\")\n",
    "print(f\"Timeout setting: {llm_config['timeout']} seconds\")\n",
    "print(f\"Primary models: {[cfg['model'] for cfg in llm_config['config_list']]}\")\n",
    "\n",
    "# Load configuration\n",
    "api_config = load_api_config(API_CONFIG_PATH)\n",
    "llm_config = setup_llm_config(api_config)\n",
    "\n",
    "# Select model\n",
    "llm_config['config_list'] = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"api_key\": api_config['api_keys']['openai_api_key']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"âœ… API configuration loaded!\")\n",
    "print(f\"Available models: {len(llm_config['config_list'])}\")\n",
    "print(f\"Primary models: {[cfg['model'] for cfg in llm_config['config_list'][:3]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scan Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning data structure...\n",
      "\n",
      "âœ… Data scan complete!\n",
      "Number of languages: 3\n",
      "Language-technique combinations: 65\n",
      "Total articles: 1284\n",
      "\n",
      "Language list: en, po, ru\n"
     ]
    }
   ],
   "source": [
    "def scan_data_structure(base_path):\n",
    "    \"\"\"\n",
    "    Scan data directory structure\n",
    "    Returns: {language: {technique: {frequency: [article_paths]}}}\n",
    "    \"\"\"\n",
    "    data_structure = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    base_path = Path(base_path)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"âš ï¸ Warning: Data path does not exist: {base_path}\")\n",
    "        return data_structure\n",
    "    \n",
    "    # Iterate through language folders\n",
    "    for lang_dir in base_path.iterdir():\n",
    "        if not lang_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        language = lang_dir.name\n",
    "        \n",
    "        # Iterate through frequency folders\n",
    "        for freq_dir in lang_dir.iterdir():\n",
    "            if not freq_dir.is_dir() or freq_dir.name not in FREQUENCY_LEVELS:\n",
    "                continue\n",
    "            \n",
    "            frequency = freq_dir.name\n",
    "            \n",
    "            # Iterate through technique folders\n",
    "            for tech_dir in freq_dir.iterdir():\n",
    "                if not tech_dir.is_dir():\n",
    "                    continue\n",
    "                \n",
    "                technique = tech_dir.name\n",
    "                \n",
    "                # Collect article files\n",
    "                article_files = list(tech_dir.glob('*.txt'))\n",
    "                data_structure[language][technique][frequency].extend(article_files)\n",
    "    \n",
    "    return data_structure\n",
    "\n",
    "print(\"Scanning data structure...\")\n",
    "data_structure = scan_data_structure(BASE_DATA_PATH)\n",
    "\n",
    "# Calculate statistics\n",
    "total_articles = sum(\n",
    "    sum(len(articles) for freq_articles in tech_data.values() for articles in freq_articles.values())\n",
    "    for lang_data in data_structure.values()\n",
    "    for tech_data in lang_data.values()\n",
    ")\n",
    "\n",
    "total_combinations = sum(\n",
    "    len(tech_data) \n",
    "    for lang_data in data_structure.values() \n",
    "    for tech_data in lang_data.values()\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Data scan complete!\")\n",
    "print(f\"Number of languages: {len(data_structure)}\")\n",
    "print(f\"Language-technique combinations: {total_combinations}\")\n",
    "print(f\"Total articles: {total_articles}\")\n",
    "print(f\"\\nLanguage list: {', '.join(sorted(data_structure.keys()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Agent System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent prompts defined!\n"
     ]
    }
   ],
   "source": [
    "def get_coordinator_prompt():\n",
    "    \"\"\"Coordinator Agent system prompt\"\"\"\n",
    "    return \"\"\"You are the Coordinator Agent responsible for managing the propaganda technique analysis workflow.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Receive article collections for specific language-technique combinations\n",
    "2. Delegate analysis tasks to specialized Language-Technique Agents\n",
    "3. Collect and consolidate analysis results\n",
    "4. Send results to the Reviewer Agent for quality checking\n",
    "5. Iterate based on reviewer feedback\n",
    "\n",
    "For each task, ensure:\n",
    "- Clear communication with specialized agents\n",
    "- Complete information transfer\n",
    "- Tracking iteration progress\n",
    "- Final result quality assurance\n",
    "\"\"\"\n",
    "\n",
    "def get_language_technique_agent_prompt(language, technique):\n",
    "    \"\"\"Generate specialized agent prompt for language-technique combination\"\"\"\n",
    "    return f\"\"\"You are a specialized propaganda technique analyst for {technique} in {language} language.\n",
    "\n",
    "Your task:\n",
    "Analyze the provided article collection and generate:\n",
    "\n",
    "1. **LLM Classification Prompt**\n",
    "   - Clear, actionable definition of {technique}\n",
    "   - How to identify this technique in {language} text\n",
    "   - Specific linguistic markers or patterns\n",
    "   - Few-shot examples (2-3 positive and negative cases)\n",
    "\n",
    "2. **Keywords and Patterns**\n",
    "   - High-frequency keywords characteristic of {technique}\n",
    "   - Language-specific phrases and expressions\n",
    "   - Structural patterns (sentence structures, discourse markers)\n",
    "\n",
    "3. **Language-Specific Insights**\n",
    "   - How {technique} manifests uniquely in {language}\n",
    "   - Cultural or linguistic factors affecting detection\n",
    "   - Comparison with other languages (if applicable)\n",
    "\n",
    "Format your analysis clearly with these sections.\n",
    "Be specific, evidence-based, and actionable.\n",
    "\"\"\"\n",
    "\n",
    "def get_reviewer_prompt():\n",
    "    \"\"\"Reviewer Agent system prompt\"\"\"\n",
    "    return \"\"\"You are the Quality Reviewer Agent responsible for evaluating and improving propaganda technique analyses.\n",
    "\n",
    "For each analysis, check:\n",
    "\n",
    "1. **Completeness**\n",
    "   - Are all required sections present?\n",
    "   - Is the LLM prompt clear and actionable?\n",
    "   - Are keywords comprehensive and relevant?\n",
    "\n",
    "2. **Quality**\n",
    "   - Are definitions precise and accurate?\n",
    "   - Are examples representative and diverse?\n",
    "   - Are insights specific to the language-technique combination?\n",
    "\n",
    "3. **Actionability**\n",
    "   - Can the LLM prompt be directly used for classification?\n",
    "   - Are keywords useful for feature engineering?\n",
    "   - Are recommendations practical?\n",
    "\n",
    "Provide:\n",
    "- Specific feedback on what to improve\n",
    "- Suggestions for missing elements\n",
    "- Rating of current version (1-10)\n",
    "- Whether another iteration is needed\n",
    "\n",
    "Be constructive, specific, and actionable in your feedback.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Agent prompts defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Article Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Article loading function defined!\n"
     ]
    }
   ],
   "source": [
    "def load_articles_for_technique(language, technique, data_structure, max_articles=MAX_ARTICLES_PER_TECHNIQUE):\n",
    "    \"\"\"\n",
    "    Load articles for specific language-technique combination\n",
    "    \n",
    "    Args:\n",
    "        language: Language code (e.g., 'en', 'po', 'ru')\n",
    "        technique: Technique name (e.g., 'Appeal_to_Authority')\n",
    "        data_structure: Data structure from scan_data_structure()\n",
    "        max_articles: Maximum number of articles to load\n",
    "    \n",
    "    Returns:\n",
    "        List of article texts\n",
    "    \"\"\"\n",
    "    if language not in data_structure or technique not in data_structure[language]:\n",
    "        return []\n",
    "    \n",
    "    all_articles = []\n",
    "    \n",
    "    # Collect articles from all frequency levels\n",
    "    for frequency in FREQUENCY_LEVELS:\n",
    "        article_paths = data_structure[language][technique].get(frequency, [])\n",
    "        \n",
    "        for path in article_paths:\n",
    "            try:\n",
    "                with open(path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "                    if content:  # Skip empty files\n",
    "                        all_articles.append({\n",
    "                            'text': content,\n",
    "                            'frequency': frequency,\n",
    "                            'filename': path.name\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Error reading {path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Limit number of articles\n",
    "    if len(all_articles) > max_articles:\n",
    "        # Prioritize: high frequency first, then medium, then low\n",
    "        priority_order = {'high': 0, 'medium': 1, 'low': 2}\n",
    "        all_articles.sort(key=lambda x: priority_order.get(x['frequency'], 3))\n",
    "        all_articles = all_articles[:max_articles]\n",
    "    \n",
    "    return all_articles\n",
    "\n",
    "print(\"âœ… Article loading function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single Language-Technique Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "def analyze_language_technique(language, technique, articles, llm_config, iteration_count=ITERATION_COUNT):\n",
    "    \"\"\"\n",
    "    Analyze specific language-technique combination using multi-agent system\n",
    "    \n",
    "    Args:\n",
    "        language: Language code\n",
    "        technique: Technique name\n",
    "        articles: Article list\n",
    "        llm_config: LLM configuration\n",
    "        iteration_count: Number of improvement iterations\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create specialized analyst agent\n",
    "        analyst = autogen.AssistantAgent(\n",
    "            name=f\"{language}_{technique}_analyst\",\n",
    "            system_message=get_language_technique_agent_prompt(language, technique),\n",
    "            llm_config=llm_config,\n",
    "        )\n",
    "        \n",
    "        # Create reviewer agent\n",
    "        reviewer = autogen.AssistantAgent(\n",
    "            name=\"reviewer\",\n",
    "            system_message=get_reviewer_prompt(),\n",
    "            llm_config=llm_config,\n",
    "        )\n",
    "        \n",
    "        # Create user proxy for interaction\n",
    "        user_proxy = autogen.UserProxyAgent(\n",
    "            name=\"coordinator\",\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=10,\n",
    "            code_execution_config=False,\n",
    "        )\n",
    "        \n",
    "        # Prepare article sample (select representative examples)\n",
    "        sample_size = min(10, len(articles))  # Use up to 10 articles for initial analysis\n",
    "        article_sample = \"\\n\\n---\\n\\n\".join([\n",
    "            f\"Article {i+1} (Frequency: {art['frequency']}):\\n{art['text'][:1000]}...\" \n",
    "            for i, art in enumerate(articles[:sample_size])\n",
    "        ])\n",
    "        \n",
    "        # Initial analysis request\n",
    "        initial_message = f\"\"\"Analyze these {len(articles)} articles for {technique} in {language}.\n",
    "\n",
    "Here is a sample of {sample_size} articles:\n",
    "\n",
    "{article_sample}\n",
    "\n",
    "Generate:\n",
    "1. LLM Classification Prompt\n",
    "2. Keywords and Patterns\n",
    "3. Language-Specific Insights\n",
    "\"\"\"\n",
    "        \n",
    "        # Start conversation\n",
    "        user_proxy.initiate_chat(\n",
    "            analyst,\n",
    "            message=initial_message,\n",
    "            max_turns=2\n",
    "        )\n",
    "        \n",
    "        # Get initial analysis\n",
    "        initial_analysis = analyst.last_message()[\"content\"]\n",
    "        \n",
    "        # Iterative improvement\n",
    "        current_analysis = initial_analysis\n",
    "        feedback_history = []\n",
    "        \n",
    "        for iteration in range(iteration_count):\n",
    "            # Get reviewer feedback\n",
    "            review_message = f\"\"\"Review this analysis for {technique} in {language}:\n",
    "\n",
    "{current_analysis}\n",
    "\n",
    "Iteration {iteration + 1}/{iteration_count}\n",
    "Previous feedback: {feedback_history[-1] if feedback_history else 'None'}\n",
    "\"\"\"\n",
    "            \n",
    "            user_proxy.initiate_chat(\n",
    "                reviewer,\n",
    "                message=review_message,\n",
    "                max_turns=2\n",
    "            )\n",
    "            \n",
    "            reviewer_feedback = reviewer.last_message()[\"content\"]\n",
    "            feedback_history.append(reviewer_feedback)\n",
    "            \n",
    "            # Refine based on feedback\n",
    "            if iteration < iteration_count - 1:  # Don't refine on last iteration\n",
    "                refine_message = f\"\"\"Improve your analysis based on this feedback:\n",
    "\n",
    "{reviewer_feedback}\n",
    "\"\"\"\n",
    "                user_proxy.initiate_chat(\n",
    "                    analyst,\n",
    "                    message=refine_message,\n",
    "                    max_turns=2\n",
    "                )\n",
    "                current_analysis = analyst.last_message()[\"content\"]\n",
    "        \n",
    "        return {\n",
    "            'language': language,\n",
    "            'technique': technique,\n",
    "            'num_articles': len(articles),\n",
    "            'initial_analysis': initial_analysis,\n",
    "            'final_analysis': current_analysis,\n",
    "            'reviewer_feedback': feedback_history,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'language': language,\n",
    "            'technique': technique,\n",
    "            'num_articles': len(articles),\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        }\n",
    "\n",
    "print(\"âœ… Analysis function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Complete Analysis (Main Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting multi-agent analysis...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "analysis_results = []\n",
    "\n",
    "# Iterate through all language-technique combinations\n",
    "for language in tqdm(sorted(data_structure.keys()), desc=\"Languages\"):\n",
    "    lang_techniques = data_structure[language]\n",
    "    \n",
    "    # Create language-specific output directory\n",
    "    lang_output_dir = Path(OUTPUT_DIR) / language\n",
    "    lang_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for technique in tqdm(sorted(lang_techniques.keys()), desc=f\"{language} techniques\", leave=False):\n",
    "        print(f\"\\nProcessing: {language} - {technique}\")\n",
    "        \n",
    "        # Load articles\n",
    "        articles = load_articles_for_technique(language, technique, data_structure)\n",
    "        \n",
    "        if not articles:\n",
    "            print(f\"  âš ï¸ No articles found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Loaded {len(articles)} articles\")\n",
    "        \n",
    "        # Analyze\n",
    "        result = analyze_language_technique(\n",
    "            language=language,\n",
    "            technique=technique,\n",
    "            articles=articles,\n",
    "            llm_config=llm_config,\n",
    "            iteration_count=ITERATION_COUNT\n",
    "        )\n",
    "        \n",
    "        analysis_results.append(result)\n",
    "        \n",
    "        # Save individual result\n",
    "        if result['status'] == 'success':\n",
    "            output_file = lang_output_dir / f\"{technique}_analysis.md\"\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"# {technique} in {language}\\n\\n\")\n",
    "                f.write(f\"Number of articles analyzed: {result['num_articles']}\\n\\n\")\n",
    "                f.write(\"## Final Analysis\\n\\n\")\n",
    "                f.write(result['final_analysis'])\n",
    "                f.write(\"\\n\\n## Reviewer Feedback History\\n\\n\")\n",
    "                for i, feedback in enumerate(result['reviewer_feedback'], 1):\n",
    "                    f.write(f\"### Iteration {i}\\n\\n\")\n",
    "                    f.write(feedback)\n",
    "                    f.write(\"\\n\\n\")\n",
    "            print(f\"  âœ… Saved: {output_file}\")\n",
    "        else:\n",
    "            print(f\"  âŒ Analysis failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        # Brief pause to avoid API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Analysis complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "success_count = sum(1 for r in analysis_results if r['status'] == 'success')\n",
    "failed_count = sum(1 for r in analysis_results if r['status'] == 'failed')\n",
    "\n",
    "print(\"\\nAnalysis Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total tasks: {len(analysis_results)}\")\n",
    "print(f\"Successful: {success_count}\")\n",
    "print(f\"Failed: {failed_count}\")\n",
    "print(f\"Success rate: {success_count/len(analysis_results)*100:.1f}%\")\n",
    "\n",
    "# Statistics by language\n",
    "lang_stats = defaultdict(lambda: {'success': 0, 'failed': 0})\n",
    "for result in analysis_results:\n",
    "    lang = result['language']\n",
    "    status = result['status']\n",
    "    lang_stats[lang][status] += 1\n",
    "\n",
    "print(\"\\nStatistics by language:\")\n",
    "for lang in sorted(lang_stats.keys()):\n",
    "    stats = lang_stats[lang]\n",
    "    total = stats['success'] + stats['failed']\n",
    "    print(f\"  {lang}: {stats['success']}/{total} successful\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame([{\n",
    "    'Language': r['language'],\n",
    "    'Technique': r['technique'],\n",
    "    'Articles': r.get('num_articles', 0),\n",
    "    'Status': r['status'],\n",
    "    'Error': r.get('error', '')\n",
    "} for r in analysis_results])\n",
    "\n",
    "print(\"\\nResults preview:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Method 1: Use print (most reliable)\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "# Or\n",
    "\n",
    "# Method 2: Use IPython display (if in Jupyter)\n",
    "from IPython.display import display\n",
    "display(results_df.head(10))\n",
    "\n",
    "# Or\n",
    "\n",
    "# Method 3: Direct DataFrame output (Jupyter auto-renders)\n",
    "results_df.head(10)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save summary results\n",
    "results_df.to_csv(f\"{OUTPUT_DIR}/analysis_summary.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nâœ… Summary results saved to: {OUTPUT_DIR}/analysis_summary.csv\")\n",
    "\n",
    "# Additional: Display complete statistics\n",
    "print(\"\\nDetailed results:\")\n",
    "print(\"-\" * 80)\n",
    "for i, result in enumerate(analysis_results, 1):\n",
    "    print(f\"{i}. {result['language']} - {result['technique']}\")\n",
    "    print(f\"   Status: {result['status']}\")\n",
    "    print(f\"   Articles: {result.get('num_articles', 0)}\")\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"   Analysis length: {len(result.get('final_analysis', ''))} characters\")\n",
    "    elif result['status'] == 'failed':\n",
    "        print(f\"   Error: {result.get('error', 'Unknown')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Master Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_master_report(results, output_path):\n",
    "    \"\"\"Generate master report\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# AutoGen Propaganda Technique Analysis - Master Report\\n\\n\")\n",
    "        f.write(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        # Overview\n",
    "        f.write(\"## Analysis Overview\\n\\n\")\n",
    "        f.write(f\"- Total tasks: {len(results)}\\n\")\n",
    "        f.write(f\"- Successful: {sum(1 for r in results if r['status'] == 'success')}\\n\")\n",
    "        f.write(f\"- Failed: {sum(1 for r in results if r['status'] == 'failed')}\\n\")\n",
    "        f.write(f\"- Iterations: {ITERATION_COUNT}\\n\")\n",
    "        f.write(f\"- Max articles per technique: {MAX_ARTICLES_PER_TECHNIQUE}\\n\\n\")\n",
    "        \n",
    "        # Group by language\n",
    "        f.write(\"## Results by Language\\n\\n\")\n",
    "        \n",
    "        lang_results = defaultdict(list)\n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                lang_results[result['language']].append(result)\n",
    "        \n",
    "        for language in sorted(lang_results.keys()):\n",
    "            f.write(f\"### {language.upper()}\\n\\n\")\n",
    "            f.write(f\"Techniques analyzed: {len(lang_results[language])}\\n\\n\")\n",
    "            \n",
    "            for result in sorted(lang_results[language], key=lambda x: x['technique']):\n",
    "                f.write(f\"- **{result['technique']}** ({result['num_articles']} articles)\\n\")\n",
    "                f.write(f\"  - Detailed report: `{language}/{result['technique']}_analysis.md`\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # Failed tasks\n",
    "        failed = [r for r in results if r['status'] == 'failed']\n",
    "        if failed:\n",
    "            f.write(\"## Failed Tasks\\n\\n\")\n",
    "            for result in failed:\n",
    "                f.write(f\"- {result['language']} - {result['technique']}: {result.get('error', 'Unknown error')}\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "        f.write(\"## Usage Instructions\\n\\n\")\n",
    "        f.write(\"Detailed analyses for each language-technique combination are saved in corresponding language folders.\\n\\n\")\n",
    "        f.write(\"File format: `{language}/{technique}_analysis.md`\\n\\n\")\n",
    "        f.write(\"Each analysis file contains:\\n\")\n",
    "        f.write(\"1. LLM classification prompts\\n\")\n",
    "        f.write(\"2. Keywords and patterns\\n\")\n",
    "        f.write(\"3. Language-specific insights\\n\")\n",
    "        f.write(\"4. Reviewer feedback\\n\")\n",
    "\n",
    "# Generate report\n",
    "report_path = f\"{OUTPUT_DIR}/MASTER_REPORT.md\"\n",
    "generate_master_report(analysis_results, report_path)\n",
    "\n",
    "print(f\"âœ… Master report generated: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Sample Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a successful result to view\n",
    "success_results = [r for r in analysis_results if r['status'] == 'success']\n",
    "\n",
    "if success_results:\n",
    "    sample = success_results[0]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Sample analysis: {sample['language']} - {sample['technique']}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nNumber of articles: {sample['num_articles']}\")\n",
    "    print(f\"\\nFinal analysis (first 1000 characters):\\n\")\n",
    "    print(sample['final_analysis'][:1000])\n",
    "    print(\"\\n...\")\n",
    "else:\n",
    "    print(\"âš ï¸ No successful analysis results available for display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export to JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results as JSON\n",
    "json_results = []\n",
    "for result in analysis_results:\n",
    "    if result['status'] == 'success':\n",
    "        json_results.append({\n",
    "            'language': result['language'],\n",
    "            'technique': result['technique'],\n",
    "            'num_articles': result['num_articles'],\n",
    "            'analysis': result['final_analysis'],\n",
    "            'reviewer_feedback': result['reviewer_feedback']\n",
    "        })\n",
    "\n",
    "json_path = f\"{OUTPUT_DIR}/all_analyses.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… JSON format results saved: {json_path}\")\n",
    "print(f\"Contains {len(json_results)} successful analyses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸŽ‰ AutoGen Multi-Agent Analysis Complete!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nðŸ“ Output directory: {OUTPUT_DIR}/\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  1. MASTER_REPORT.md - Master report\")\n",
    "print(f\"  2. analysis_summary.csv - Results summary table\")\n",
    "print(f\"  3. all_analyses.json - JSON format all analyses\")\n",
    "print(f\"  4. [language]/[technique]_analysis.md - Detailed analysis for each technique\")\n",
    "\n",
    "print(\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"  - Successful analyses: {success_count}\")\n",
    "print(f\"  - Failed analyses: {failed_count}\")\n",
    "print(f\"  - Total articles: {sum(r.get('num_articles', 0) for r in analysis_results)}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Next steps:\")\n",
    "print(\"  1. Review MASTER_REPORT.md for overall situation\")\n",
    "print(\"  2. Check detailed analyses in each language folder\")\n",
    "print(\"  3. Use generated LLM prompts to train classification models\")\n",
    "print(\"  4. Extract keywords for feature engineering\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}