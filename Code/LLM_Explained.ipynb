{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1536ab32-7a9a-442b-988f-2ad2d1dd12e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Usage example ===\n",
      "\n",
      "1. LoadCSV并Analyze label distribution:\n",
      "df = read_csv_file('true_in_Wha.csv')\n",
      "label_distribution = display_csv_info(df)\n",
      "\n",
      "2. Analyze missed labels:\n",
      "# True labels中havebutPrediction中No\n",
      "results_df, output_file = analyze_missed_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\n",
      "\n",
      "3. Analysis误报Label:\n",
      "# Prediction labels中havebutTrue labels中No\n",
      "results_df, output_file = analyze_false_positive_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\n",
      "\n",
      "4. Analyze multiple labels:\n",
      "labels = ['Whataboutism', 'Loaded_Language']\n",
      "# 默认同时AnalysisMissedand误报\n",
      "results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, max_samples=2)\n",
      "# Only analyzeMissed\n",
      "results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, analysis_types=['missed'], max_samples=2)\n",
      "\n",
      "5. Analyze correctly identified labels:\n",
      "results_df, output_file = analyze_correct_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\n",
      "\n",
      "6. Analyze confused labels:\n",
      "results_df, output_file = analyze_confused_label('true_in_Wha.csv', 'Loaded_Language', 'Appeal_to_Fear-Prejudice', max_samples=3)\n",
      "\n",
      "7. Analyze multiple labels containing confused labels:\n",
      "labels = ['Whataboutism', 'Loaded_Language']\n",
      "confused_pairs = [('Loaded_Language', 'Appeal_to_Fear-Prejudice'), ('Whataboutism', 'Red_Herring')]\n",
      "results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, analysis_types=['missed', 'confused'], max_samples=2, confused_pairs=confused_pairs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# OpenAI APIConfiguration\n",
    "OPENAI_API_KEY = \"your_api_config_file.json\"  # Please replace with your actual API key\n",
    "MODEL = \"gpt-4.1-mini-2025-04-14\"\n",
    "API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# DatabaseConfiguration\n",
    "DB_NAME = \"propaganda_techniques_analysis.db\"\n",
    "\n",
    "# Analysis type constants\n",
    "ANALYSIS_TYPE_MISSED = \"missed\"  # True labels存inbutPredictionnotcontains\n",
    "ANALYSIS_TYPE_FALSE_POSITIVE = \"false_positive\"  # True labels不存inbutPredictioncontains\n",
    "ANALYSIS_TYPE_CORRECT = \"correct\"  # Correctly identifiedof案例\n",
    "ANALYSIS_TYPE_CONFUSED = \"confused\"  # byConfusion为Other labelsof案例\n",
    "\n",
    "# ReadCSVFile\n",
    "def read_csv_file(file_path):\n",
    "    try:\n",
    "        # 首先尝试use制Table符作为分隔符\n",
    "        df = pd.read_csv(file_path, sep='\\t', encoding='utf-8')\n",
    "        \n",
    "        # Check是否Correct解析 - 应该have多个列\n",
    "        if len(df.columns) == 1 and ',' in df.columns[0]:\n",
    "            print(\"警告：FilenotCorrect解析，尝试use逗号分隔符...\")\n",
    "            # 尝试use逗号分隔符\n",
    "            df = pd.read_csv(file_path, sep=',', encoding='utf-8')\n",
    "            \n",
    "        # Check again\n",
    "        if 'true_labels' not in df.columns:\n",
    "            print(f\"当前列名: {df.columns.tolist()}\")\n",
    "            print(\"尝试其他解析方法...\")\n",
    "            # 尝试不同ofRead方式\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                # Check内容中of分隔符\n",
    "                if '\\t' in content:\n",
    "                    print(\"File内容contains制Table符，butpandasnotCorrect解析\")\n",
    "                else:\n",
    "                    print(\"File内容不contains制Table符，Checkactual分隔符\")\n",
    "                \n",
    "                # 尝试手动解析\n",
    "                lines = content.strip().split('\\n')\n",
    "                headers = lines[0].strip().split(',')  # Assume header is comma-separated\n",
    "                print(f\"手动解析of列名: {headers}\")\n",
    "                \n",
    "                # Create自定义DataFrame\n",
    "                data = []\n",
    "                for line in lines[1:]:\n",
    "                    values = line.strip().split(',')\n",
    "                    row_data = {headers[i]: values[i] for i in range(min(len(headers), len(values)))}\n",
    "                    data.append(row_data)\n",
    "                \n",
    "                df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"最终解析Result - 列名: {df.columns.tolist()}, 形状: {df.shape}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Read file出错: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 显示CSVinformation\n",
    "def display_csv_info(df):\n",
    "    print(f\"CSVFilecontains {len(df)} rowsData\")\n",
    "    print(f\"列名: {', '.join(df.columns)}\")\n",
    "    \n",
    "    # 显示前几rowsData\n",
    "    display(df.head())\n",
    "    \n",
    "    # Analyze label distribution\n",
    "    true_labels_count = {}\n",
    "    pred_labels_count = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if isinstance(row['true_labels'], str):\n",
    "            labels = row['true_labels'].split(',')\n",
    "            for label in labels:\n",
    "                true_labels_count[label] = true_labels_count.get(label, 0) + 1\n",
    "        \n",
    "        if isinstance(row['pred_labels'], str):\n",
    "            labels = row['pred_labels'].split(',')\n",
    "            for label in labels:\n",
    "                pred_labels_count[label] = pred_labels_count.get(label, 0) + 1\n",
    "    \n",
    "    # convertCountConvert为DataFrame并显示\n",
    "    true_df = pd.DataFrame(list(true_labels_count.items()), columns=['Label', 'True labels出现次数'])\n",
    "    true_df = true_df.sort_values('True labels出现次数', ascending=False)\n",
    "    \n",
    "    pred_df = pd.DataFrame(list(pred_labels_count.items()), columns=['Label', 'Prediction labels出现次数'])\n",
    "    pred_df = pred_df.sort_values('Prediction labels出现次数', ascending=False)\n",
    "    \n",
    "    # 合并两个DataFrame\n",
    "    merged_df = pd.merge(true_df, pred_df, on='Label', how='outer').fillna(0)\n",
    "    merged_df['差异'] = merged_df['True labels出现次数'] - merged_df['Prediction labels出现次数']\n",
    "    merged_df = merged_df.sort_values('差异', ascending=False)\n",
    "    \n",
    "    print(\"\\nLabel distribution情况:\")\n",
    "    display(merged_df)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# 构建GPTPrompt\n",
    "def build_prompt(row, target_label, analysis_type, confused_label=None):\n",
    "    if analysis_type == ANALYSIS_TYPE_MISSED:\n",
    "        prompt = f\"\"\"请Analysis以下Text中出现of宣传technique，特别关注\"{target_label}\":\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "True labels中contains\"{target_label}\"，but prediction labels do not contain。请用英语Analysis以下问题，并convert回答合并为一个连贯of段落，Total长度不超过150English words:\n",
    "\n",
    "1. This articleText中contains{target_label}of具体原因是什么？\n",
    "2. Text中支持This一判断of关键词或句子是什么？\n",
    "3. {target_label}This种techniqueof典型特征如何inText中体现？\n",
    "4. Model应该关注Text中of哪些额外特征来更准确地识别This种technique？\n",
    "\n",
    "请注意：所have回答必须合并成单个段落，Do not use bullet points or numbering，确保内容连贯流畅且不超过150words。\"\"\"\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_FALSE_POSITIVE:\n",
    "        prompt = f\"\"\"请Analysis以下Text中关于宣传technique\"{target_label}\"ofPredictionError:\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "Prediction labels中contains\"{target_label}\"，but true labels do not contain。请用英语Analysis以下问题，并convert回答合并为一个连贯of段落，Total长度不超过150English words:\n",
    "\n",
    "1. This articleText中不contains{target_label}of具体原因是什么？\n",
    "2. Text中支持This一判断of关键词或句子是什么？\n",
    "3. {target_label}This种techniqueof典型特征如何inText中体现？\n",
    "4. Modelin识别{target_label}时可能存in哪些误解或Error模式？\n",
    "\n",
    "请注意：所have回答必须合并成单个段落，Do not use bullet points or numbering，确保内容连贯流畅且不超过150words。\"\"\"\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_CORRECT:\n",
    "        prompt = f\"\"\"请Analysis以下Text中Correctly identifiedof宣传technique\"{target_label}\":\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "True labelsandPrediction labels都contains\"{target_label}\"。请用英语Analysis以下问题，并convert回答合并为一个连贯of段落，Total长度不超过150English words:\n",
    "\n",
    "1. This articleText中contains{target_label}of具体原因是什么？\n",
    "2. Text中支持This一判断of关键词或句子是什么？\n",
    "3. {target_label}This种techniqueof典型特征如何inText中体现？\n",
    "4. ModelCorrectly identifiedThis种techniqueof关键是什么？\n",
    "\n",
    "请注意：所have回答必须合并成单个段落，Do not use bullet points or numbering，确保内容连贯流畅且不超过150words。\"\"\"\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_CONFUSED:\n",
    "        if not confused_label:\n",
    "            confused_label = \"Other labels\"\n",
    "        \n",
    "        prompt = f\"\"\"请Analysis以下Text中宣传techniqueLabelConfusionof情况:\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "True labels是\"{target_label}\"，but predicted as\"{confused_label}\"。请用英语Analysis以下问题，并convert回答合并为一个连贯of段落，Total长度不超过150English words:\n",
    "\n",
    "1. Why this text is more consistent with{target_label}而不是{confused_label}？\n",
    "2. This两种techniquehave什么关键区别？\n",
    "3. Model可能ConfusionThis两种techniqueof原因是什么？\n",
    "\n",
    "请注意：所have回答必须合并成单个段落，Do not use bullet points or numbering，确保内容连贯流畅且不超过150words。\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# CallGPT API\n",
    "def call_gpt_api(prompt):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 200  # 限制GeneratedtokenQuantity，约对应150English words\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        # Check内容长度，如果超过150words，进rows截断\n",
    "        words = content.split()\n",
    "        if len(words) > 150:\n",
    "            content = ' '.join(words[:150]) + \"...\"\n",
    "            print(\"回答by截断至150words\")\n",
    "        \n",
    "        # 确保Output是单个段落，移除多余of换rowsand标点\n",
    "        content = content.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        while \"  \" in content:\n",
    "            content = content.replace(\"  \", \" \")\n",
    "            \n",
    "        # 移除可能of项目符号或Number\n",
    "        content = re.sub(r'^\\s*[\\d\\.\\-\\*]+\\s*', '', content)\n",
    "        content = re.sub(r'\\n\\s*[\\d\\.\\-\\*]+\\s*', ' ', content)\n",
    "        \n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"APIRequestError: {e}\")\n",
    "        # 添加随机延迟避免Frequency限制\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        return None\n",
    "\n",
    "# Initialize database并Create table（如果不存in）\n",
    "# Initialize database并Create table（如果不存in）\n",
    "def initialize_database():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS label_analysis (\n",
    "        id TEXT,\n",
    "        text TEXT,\n",
    "        true_labels TEXT,\n",
    "        pred_labels TEXT,\n",
    "        language TEXT,\n",
    "        analysis TEXT,\n",
    "        target_label TEXT,\n",
    "        analysis_type TEXT,\n",
    "        confused_label TEXT,\n",
    "        created_at TIMESTAMP,\n",
    "        PRIMARY KEY (id, target_label, analysis_type, confused_label)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "# convertAnalysisResultStore to database\n",
    "# convertAnalysisResultStore to database\n",
    "def save_to_db(conn, cursor, row, analysis, target_label, analysis_type, confused_label=None):\n",
    "    # CheckRecord是否Already exists\n",
    "    if confused_label:\n",
    "        cursor.execute(\n",
    "            \"SELECT id FROM label_analysis WHERE id = ? AND target_label = ? AND analysis_type = ? AND confused_label = ?\", \n",
    "            (row['id'], target_label, analysis_type, confused_label)\n",
    "        )\n",
    "    else:\n",
    "        cursor.execute(\n",
    "            \"SELECT id FROM label_analysis WHERE id = ? AND target_label = ? AND analysis_type = ?\", \n",
    "            (row['id'], target_label, analysis_type)\n",
    "        )\n",
    "    exists = cursor.fetchone()\n",
    "    \n",
    "    if exists:\n",
    "        # Update现haveRecord\n",
    "        if confused_label:\n",
    "            cursor.execute('''\n",
    "            UPDATE label_analysis \n",
    "            SET analysis = ?, created_at = ?\n",
    "            WHERE id = ? AND target_label = ? AND analysis_type = ? AND confused_label = ?\n",
    "            ''', (analysis, datetime.now(), row['id'], target_label, analysis_type, confused_label))\n",
    "        else:\n",
    "            cursor.execute('''\n",
    "            UPDATE label_analysis \n",
    "            SET analysis = ?, created_at = ?\n",
    "            WHERE id = ? AND target_label = ? AND analysis_type = ?\n",
    "            ''', (analysis, datetime.now(), row['id'], target_label, analysis_type))\n",
    "    else:\n",
    "        # Insert新Record\n",
    "        cursor.execute('''\n",
    "        INSERT INTO label_analysis \n",
    "        (id, text, true_labels, pred_labels, language, analysis, target_label, analysis_type, confused_label, created_at)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            row['id'], \n",
    "            row['text'], \n",
    "            row['true_labels'], \n",
    "            row['pred_labels'], \n",
    "            row['language'], \n",
    "            analysis,\n",
    "            target_label,\n",
    "            analysis_type,\n",
    "            confused_label,\n",
    "            datetime.now()\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "# Get analyzed records from database\n",
    "def get_analyzed_records(target_label=None, analysis_type=None):\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = \"SELECT * FROM label_analysis WHERE 1=1\"\n",
    "    params = []\n",
    "    \n",
    "    if target_label:\n",
    "        query += \" AND target_label = ?\"\n",
    "        params.append(target_label)\n",
    "    \n",
    "    if analysis_type:\n",
    "        query += \" AND analysis_type = ?\"\n",
    "        params.append(analysis_type)\n",
    "    \n",
    "    cursor.execute(query, params)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Convert为pandas DataFrame\n",
    "    if rows:\n",
    "        df = pd.DataFrame([dict(row) for row in rows])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['id', 'text', 'true_labels', 'pred_labels', \n",
    "                                 'language', 'analysis', 'target_label', \n",
    "                                 'analysis_type', 'created_at'])\n",
    "    \n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# Main function - Analyze unrecognized labels（Missed）\n",
    "def analyze_missed_label(csv_file_path, target_label, max_samples=None, display_progress=True):\n",
    "    return analyze_label(csv_file_path, target_label, ANALYSIS_TYPE_MISSED, max_samples, display_progress)\n",
    "\n",
    "# Main function - AnalysisErrorPredictionlabels（误报）\n",
    "def analyze_false_positive_label(csv_file_path, target_label, max_samples=None, display_progress=True):\n",
    "    return analyze_label(csv_file_path, target_label, ANALYSIS_TYPE_FALSE_POSITIVE, max_samples, display_progress)\n",
    "\n",
    "# Main function - Analyze correctly identified labels\n",
    "def analyze_correct_label(csv_file_path, target_label, max_samples=None, display_progress=True):\n",
    "    return analyze_label(csv_file_path, target_label, ANALYSIS_TYPE_CORRECT, max_samples, display_progress)\n",
    "\n",
    "# Main function - Analyze confused labels\n",
    "def analyze_confused_label(csv_file_path, target_label, confused_label, max_samples=None, display_progress=True):\n",
    "    return analyze_label(csv_file_path, target_label, ANALYSIS_TYPE_CONFUSED, max_samples, display_progress, confused_label)\n",
    "\n",
    "\n",
    "\n",
    "def save_as_tsv(df, file_path):\n",
    "    \"\"\"\n",
    "    usecsv模块直接convertDataFrameSave asTSVFile\n",
    "    This样可以完全控制Output格式，避免pandasofAutomaticProcess逻辑\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        # CreateTSVwriter，明确指定分隔符为制Table符\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        \n",
    "        # Write column names\n",
    "        writer.writerow(df.columns)\n",
    "        \n",
    "        # Write each row of data\n",
    "        for _, row in df.iterrows():\n",
    "            writer.writerow(row.values)\n",
    "            \n",
    "    print(f\"DataSuccessfully saved为TSVFile: {file_path}\")\n",
    "    return file_path\n",
    "# 通用Analysis函数\n",
    "def analyze_label(csv_file_path, target_label, analysis_type, max_samples=None, display_progress=True, confused_label=None):\n",
    "    analysis_type_names = {\n",
    "        ANALYSIS_TYPE_MISSED: \"Missed\",\n",
    "        ANALYSIS_TYPE_FALSE_POSITIVE: \"误报\",\n",
    "        ANALYSIS_TYPE_CORRECT: \"Correctly identified\",\n",
    "        ANALYSIS_TYPE_CONFUSED: \"Confused labels\"\n",
    "    }\n",
    "    analysis_type_name = analysis_type_names.get(analysis_type, \"not知\")\n",
    "    \n",
    "    confused_info = f\"(Confusion为{confused_label})\" if analysis_type == ANALYSIS_TYPE_CONFUSED and confused_label else \"\"\n",
    "    print(f\"StartAnalyze labels: {target_label} {confused_info}({analysis_type_name})\")\n",
    "    \n",
    "    # Initialize database\n",
    "    conn, cursor = initialize_database()\n",
    "    \n",
    "    # ReadCSV\n",
    "    df = read_csv_file(csv_file_path)\n",
    "    # 调试information\n",
    "    print(f\"ReadofDataFrame列名: {df.columns.tolist()}\")\n",
    "    print(f\"DataFrame形状: {df.shape}\")\n",
    "    print(\"前几rowsData:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Prepare new dataframe for analysis results\n",
    "    result_df = df.copy()\n",
    "    result_df['analysis'] = \"\"\n",
    "    # 确保Label列为字符串Type\n",
    "    df['true_labels'] = df['true_labels'].astype(str)\n",
    "    df['pred_labels'] = df['pred_labels'].astype(str)\n",
    "    \n",
    "    # 根据Analysis type筛选Record\n",
    "    if analysis_type == ANALYSIS_TYPE_MISSED:\n",
    "        # 筛选True labels中存inbutPrediction labels中不存inrecords\n",
    "        filtered_df = df[\n",
    "            (df['true_labels'].str.contains(target_label, na=False)) & \n",
    "            (~df['pred_labels'].str.contains(target_label, na=False))\n",
    "        ]\n",
    "        print(f\"Found{len(filtered_df)}records含have{target_label}but records where predictions do not contain this label（Missed）\")\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_FALSE_POSITIVE:\n",
    "        # 筛选Prediction labels中存inbutTrue labels中不存inrecords\n",
    "        filtered_df = df[\n",
    "            (~df['true_labels'].str.contains(target_label, na=False)) & \n",
    "            (df['pred_labels'].str.contains(target_label, na=False))\n",
    "        ]\n",
    "        print(f\"Found{len(filtered_df)}recordsPredicted as{target_label}but records where true labels do not contain this label（误报）\")\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_CORRECT:\n",
    "        # 筛选True labelsandPrediction labels中都存inrecords\n",
    "        filtered_df = df[\n",
    "            (df['true_labels'].str.contains(target_label, na=False)) & \n",
    "            (df['pred_labels'].str.contains(target_label, na=False))\n",
    "        ]\n",
    "        print(f\"Found{len(filtered_df)}recordsTrue labelsandPrediction labels都contains{target_label}records（Correctly identified）\")\n",
    "    \n",
    "    elif analysis_type == ANALYSIS_TYPE_CONFUSED:\n",
    "        # 筛选True labels是target_labelbut prediction labels containconfused_labelrecords\n",
    "        if not confused_label:\n",
    "            print(\"Error：ConfusionLabel analysisNeed提供confused_label参数\")\n",
    "            return pd.DataFrame(), \"\"\n",
    "        \n",
    "        filtered_df = df[\n",
    "            (df['true_labels'].str.contains(target_label, na=False)) & \n",
    "            (~df['pred_labels'].str.contains(target_label, na=False)) &\n",
    "            (df['pred_labels'].str.contains(confused_label, na=False))\n",
    "        ]\n",
    "        print(f\"Found{len(filtered_df)}recordsTrue labels为{target_label}but predicted as{confused_label}records（Confused labels）\")\n",
    "    \n",
    "    # 限制ProcessNumber of samples\n",
    "    if max_samples and max_samples < len(filtered_df):\n",
    "        filtered_df = filtered_df.sample(max_samples, random_state=42)\n",
    "        print(f\"已随机选择{max_samples}records进rowsAnalysis\")\n",
    "    \n",
    "    # CreateResultOutput file（CSV）\n",
    "    if analysis_type == ANALYSIS_TYPE_CONFUSED:\n",
    "        output_file_name = f\"{target_label.lower()}_confused_as_{confused_label.lower()}_analysis_results.csv\"\n",
    "    else:\n",
    "        output_file_name = f\"{target_label.lower()}_{analysis_type}_analysis_results.csv\"\n",
    "    \n",
    "    # Process每一records\n",
    "    for index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df), desc=f\"Analysis{target_label}({analysis_type_name})\") if display_progress else filtered_df.iterrows():\n",
    "        # CheckDatabase中是否已have此Record\n",
    "        if analysis_type == ANALYSIS_TYPE_CONFUSED:\n",
    "            cursor.execute(\n",
    "                \"SELECT analysis FROM label_analysis WHERE id = ? AND target_label = ? AND analysis_type = ? AND confused_label = ?\", \n",
    "                (row['id'], target_label, analysis_type, confused_label)\n",
    "            )\n",
    "        else:\n",
    "            cursor.execute(\n",
    "                \"SELECT analysis FROM label_analysis WHERE id = ? AND target_label = ? AND analysis_type = ?\", \n",
    "                (row['id'], target_label, analysis_type)\n",
    "            )\n",
    "        existing = cursor.fetchone()\n",
    "        \n",
    "        if existing:\n",
    "            # Use existing analysis results\n",
    "            analysis = existing[0]\n",
    "            print(f\"Record {row['id']} Already exists于Database中，跳过APICall\")\n",
    "        else:\n",
    "            # 构建Prompt并CallAPI\n",
    "            prompt = build_prompt(row, target_label, analysis_type, confused_label)\n",
    "            analysis = call_gpt_api(prompt)\n",
    "            \n",
    "            if analysis:\n",
    "                # Save to database，统一use一个函数\n",
    "                save_to_db(conn, cursor, row, analysis, target_label, analysis_type, confused_label)\n",
    "            else:\n",
    "                print(f\"Record {row['id']} Process失败\")\n",
    "                continue\n",
    "        \n",
    "        # inResultDataframe中Update analysis results\n",
    "        result_df.loc[result_df['id'] == row['id'], 'analysis'] = analysis\n",
    "    \n",
    "    # Save results toCSVFile\n",
    "    filtered_indices = result_df['id'].isin(filtered_df['id'])\n",
    "    filtered_result_df = result_df[filtered_indices]\n",
    "    \n",
    "    # convert缺失ofAnalysis设为Empty字符串\n",
    "    filtered_result_df['analysis'] = filtered_result_df['analysis'].fillna(\"\")\n",
    "    \n",
    "    # 确保CSV格式与原始格式相同，并in最后添加Analysis列\n",
    "    output_file_name = output_file_name.replace('.csv', '.tsv')\n",
    "    # Fixed code\n",
    "    save_as_tsv(filtered_result_df, output_file_name)\n",
    "    \n",
    "    conn.close()\n",
    "    print(f\"All processing completed！ResultSaved到{output_file_name}andDatabase {DB_NAME}\")\n",
    "    \n",
    "    # 显示Result预览\n",
    "    display(filtered_result_df)\n",
    "    \n",
    "    return filtered_result_df, output_file_name\n",
    "\n",
    "\n",
    "# 多LabelProcess函数\n",
    "def process_multiple_labels(csv_file_path, labels, analysis_types=None, max_samples=None, confused_pairs=None):\n",
    "    if analysis_types is None:\n",
    "        # 默认同时AnalysisMissedand误报\n",
    "        analysis_types = [ANALYSIS_TYPE_MISSED, ANALYSIS_TYPE_FALSE_POSITIVE]\n",
    "    \n",
    "    results = {}\n",
    "    summary_data = []\n",
    "    \n",
    "    # ReadCSVto get original format\n",
    "    df = read_csv_file(csv_file_path)\n",
    "    \n",
    "    # Prepare final merged results dataframe\n",
    "    final_result_df = df.copy()\n",
    "    final_result_df['analysis'] = \"\"\n",
    "    \n",
    "    # Process常规Analysis type（非ConfusionType）\n",
    "    for label in labels:\n",
    "        for analysis_type in [at for at in analysis_types if at != ANALYSIS_TYPE_CONFUSED]:\n",
    "            analysis_type_name = \"Missed\" if analysis_type == ANALYSIS_TYPE_MISSED else \"误报\" if analysis_type == ANALYSIS_TYPE_FALSE_POSITIVE else \"Correctly identified\"\n",
    "            print(f\"\\nStart processingLabel: {label} ({analysis_type_name})\")\n",
    "            \n",
    "            # Analyze labels\n",
    "            results_df, output_file = analyze_label(\n",
    "                csv_file_path, \n",
    "                label, \n",
    "                analysis_type,\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            # Update最终ResultDataframe\n",
    "            for idx, row in results_df.iterrows():\n",
    "                if row['analysis']:  # 只UpdatehaveAnalysisResultofrows\n",
    "                    # in现haveResult上添加LabelandAnalysis typeinformation\n",
    "                    analysis_with_tag = f\"[{label}|{analysis_type_name}] {row['analysis']}\"\n",
    "                    \n",
    "                    # 如果该rows已have其他Analysis，则追加；否则直接赋值\n",
    "                    current_analysis = final_result_df.loc[idx, 'analysis']\n",
    "                    if current_analysis:\n",
    "                        final_result_df.loc[idx, 'analysis'] = f\"{current_analysis} | {analysis_with_tag}\"\n",
    "                    else:\n",
    "                        final_result_df.loc[idx, 'analysis'] = analysis_with_tag\n",
    "            \n",
    "            # 添加到Result\n",
    "            key = f\"{label}_{analysis_type}\"\n",
    "            results[key] = {\n",
    "                \"results_df\": results_df,\n",
    "                \"output_file\": output_file\n",
    "            }\n",
    "            \n",
    "            # 添加到摘要\n",
    "            summary_data.append({\n",
    "                \"Label\": label,\n",
    "                \"Analysis type\": analysis_type_name,\n",
    "                \"Number of analysis records\": len(results_df[results_df['analysis'] != \"\"]),\n",
    "                \"Output file\": output_file\n",
    "            })\n",
    "    \n",
    "    # ProcessConfusionLabel analysis\n",
    "    if ANALYSIS_TYPE_CONFUSED in analysis_types and confused_pairs:\n",
    "        for true_label, pred_label in confused_pairs:\n",
    "            print(f\"\\nStart processingConfused labels: True={true_label}, Prediction={pred_label}\")\n",
    "            \n",
    "            # Analyze confused labels\n",
    "            results_df, output_file = analyze_label(\n",
    "                csv_file_path, \n",
    "                true_label,\n",
    "                ANALYSIS_TYPE_CONFUSED,\n",
    "                max_samples=max_samples,\n",
    "                confused_label=pred_label\n",
    "            )\n",
    "            \n",
    "            # Update最终ResultDataframe\n",
    "            for idx, row in results_df.iterrows():\n",
    "                if row['analysis']:  # 只UpdatehaveAnalysisResultofrows\n",
    "                    # in现haveResult上添加LabelandAnalysis typeinformation\n",
    "                    analysis_with_tag = f\"[{true_label}Confusion为{pred_label}] {row['analysis']}\"\n",
    "                    \n",
    "                    # 如果该rows已have其他Analysis，则追加；否则直接赋值\n",
    "                    current_analysis = final_result_df.loc[idx, 'analysis']\n",
    "                    if current_analysis:\n",
    "                        final_result_df.loc[idx, 'analysis'] = f\"{current_analysis} | {analysis_with_tag}\"\n",
    "                    else:\n",
    "                        final_result_df.loc[idx, 'analysis'] = analysis_with_tag\n",
    "            \n",
    "            # 添加到Result\n",
    "            key = f\"{true_label}_confused_as_{pred_label}\"\n",
    "            results[key] = {\n",
    "                \"results_df\": results_df,\n",
    "                \"output_file\": output_file\n",
    "            }\n",
    "            \n",
    "            # 添加到摘要\n",
    "            summary_data.append({\n",
    "                \"Label\": true_label,\n",
    "                \"Analysis type\": f\"Confusion为{pred_label}\",\n",
    "                \"Number of analysis records\": len(results_df[results_df['analysis'] != \"\"]),\n",
    "                \"Output file\": output_file\n",
    "            })\n",
    "    \n",
    "    # Save final merged results\n",
    "    final_output_file = \"all_labels_analysis_results.tsv\"\n",
    "    # Fixed code\n",
    "    save_as_tsv(final_result_df, final_output_file)\n",
    "    \n",
    "    # 显示摘要\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n所haveLabelProcessing completed！\")\n",
    "    display(HTML(\"<h3>Process摘要</h3>\"))\n",
    "    display(summary_df)\n",
    "    \n",
    "    print(f\"所haveAnalysisResult已合并保存到: {final_output_file}\")\n",
    "    \n",
    "    return results, summary_df, final_output_file, final_result_df\n",
    "\n",
    "\n",
    "# Exampleuse方法\n",
    "def usage_example():\n",
    "    print(\"=== Usage example ===\")\n",
    "    print(\"\\n1. LoadCSV并Analyze label distribution:\")\n",
    "    print(\"df = read_csv_file('true_in_Wha.csv')\")\n",
    "    print(\"label_distribution = display_csv_info(df)\")\n",
    "    \n",
    "    print(\"\\n2. Analyze missed labels:\")\n",
    "    print(\"# True labels中havebutPrediction中No\")\n",
    "    print(\"results_df, output_file = analyze_missed_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\")\n",
    "    \n",
    "    print(\"\\n3. Analysis误报Label:\")\n",
    "    print(\"# Prediction labels中havebutTrue labels中No\")\n",
    "    print(\"results_df, output_file = analyze_false_positive_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\")\n",
    "    \n",
    "    print(\"\\n4. Analyze multiple labels:\")\n",
    "    print(\"labels = ['Whataboutism', 'Loaded_Language']\")\n",
    "    print(\"# 默认同时AnalysisMissedand误报\")\n",
    "    print(\"results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, max_samples=2)\")\n",
    "    print(\"# Only analyzeMissed\")\n",
    "    print(\"results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, analysis_types=['missed'], max_samples=2)\")\n",
    "    \n",
    "    print(\"\\n5. Analyze correctly identified labels:\")\n",
    "    print(\"results_df, output_file = analyze_correct_label('true_in_Wha.csv', 'Whataboutism', max_samples=3)\")\n",
    "    \n",
    "    print(\"\\n6. Analyze confused labels:\")\n",
    "    print(\"results_df, output_file = analyze_confused_label('true_in_Wha.csv', 'Loaded_Language', 'Appeal_to_Fear-Prejudice', max_samples=3)\")\n",
    "    \n",
    "    print(\"\\n7. Analyze multiple labels containing confused labels:\")\n",
    "    print(\"labels = ['Whataboutism', 'Loaded_Language']\")\n",
    "    print(\"confused_pairs = [('Loaded_Language', 'Appeal_to_Fear-Prejudice'), ('Whataboutism', 'Red_Herring')]\")\n",
    "    print(\"results, summary, final_file, final_df = process_multiple_labels('true_in_Wha.csv', labels, analysis_types=['missed', 'confused'], max_samples=2, confused_pairs=confused_pairs)\")\n",
    "\n",
    "# 展示use方法\n",
    "usage_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd43e96f-0190-4b86-874a-c978dc3e57d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartAnalyze labels: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language)(Confused labels)\n",
      "警告：FilenotCorrect解析，尝试use逗号分隔符...\n",
      "最终解析Result - 列名: ['id', 'line', 'text', 'true_labels', 'pred_labels', 'match', 'language'], 形状: (21, 7)\n",
      "ReadofDataFrame列名: ['id', 'line', 'text', 'true_labels', 'pred_labels', 'match', 'language']\n",
      "DataFrame形状: (21, 7)\n",
      "前几rowsData:\n",
      "               id  line                                               text  \\\n",
      "0  po_article2551     9  Nie będę tu rozstrzygał, czy ukraińscy polityc...   \n",
      "1   po_article224     3  W środę Parlament Europejski przyjął projekty ...   \n",
      "2  po_article2289    13  Przy przejściu do „kościoła klimatycznego” koś...   \n",
      "3  cr_article2490    17  Za pravoslavne ljude ovaj Četvrti domovinski r...   \n",
      "4  ru_article2227     5  A look at recent headlines also grimly reminds...   \n",
      "\n",
      "                                         true_labels  \\\n",
      "0  Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...   \n",
      "1  Appeal_to_Fear-Prejudice,Doubt,Name_Calling-La...   \n",
      "2  Appeal_to_Fear-Prejudice,Doubt,Exaggeration-Mi...   \n",
      "3  Appeal_to_Fear-Prejudice,Appeal_to_Values,Flag...   \n",
      "4  Appeal_to_Fear-Prejudice,Appeal_to_Hypocrisy,N...   \n",
      "\n",
      "                                         pred_labels  match language  \n",
      "0  Appeal_to_Values,Doubt,Flag_Waving,Loaded_Lang...  False       po  \n",
      "1              Loaded_Language,Name_Calling-Labeling  False       po  \n",
      "2  Appeal_to_Hypocrisy,Doubt,Guilt_by_Association...  False       po  \n",
      "3  Appeal_to_Values,Flag_Waving,Loaded_Language,N...  False       cr  \n",
      "4  Appeal_to_Hypocrisy,Appeal_to_Popularity,Doubt...  False       ru  \n",
      "Found21recordsTrue labels为Appeal_to_Fear-Prejudicebut predicted asLoaded_Languagerecords（Confused labels）\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae4a68d88d74664afb386e40de88db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AnalysisAppeal_to_Fear-Prejudice(Confused labels):   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n",
      "/tmp/ipykernel_137/4061634873.py:276: DeprecationWarning: The default datetime adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSuccessfully saved为TSVFile: appeal_to_fear-prejudice_confused_as_loaded_language_analysis_results.tsv\n",
      "All processing completed！ResultSaved到appeal_to_fear-prejudice_confused_as_loaded_language_analysis_results.tsvandDatabase propaganda_techniques_analysis.db\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>match</th>\n",
       "      <th>language</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>po_article2551</td>\n",
       "      <td>9</td>\n",
       "      <td>Nie będę tu rozstrzygał, czy ukraińscy polityc...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...</td>\n",
       "      <td>Appeal_to_Values,Doubt,Flag_Waving,Loaded_Lang...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text primarily fits \"Appeal_to_Fear-Prejud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po_article224</td>\n",
       "      <td>3</td>\n",
       "      <td>W środę Parlament Europejski przyjął projekty ...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Doubt,Name_Calling-La...</td>\n",
       "      <td>Loaded_Language,Name_Calling-Labeling</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>po_article2289</td>\n",
       "      <td>13</td>\n",
       "      <td>Przy przejściu do „kościoła klimatycznego” koś...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Doubt,Exaggeration-Mi...</td>\n",
       "      <td>Appeal_to_Hypocrisy,Doubt,Guilt_by_Association...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cr_article2490</td>\n",
       "      <td>17</td>\n",
       "      <td>Za pravoslavne ljude ovaj Četvrti domovinski r...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Flag...</td>\n",
       "      <td>Appeal_to_Values,Flag_Waving,Loaded_Language,N...</td>\n",
       "      <td>False</td>\n",
       "      <td>cr</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru_article2227</td>\n",
       "      <td>5</td>\n",
       "      <td>A look at recent headlines also grimly reminds...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Hypocrisy,N...</td>\n",
       "      <td>Appeal_to_Hypocrisy,Appeal_to_Popularity,Doubt...</td>\n",
       "      <td>False</td>\n",
       "      <td>ru</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en_article699478811</td>\n",
       "      <td>5</td>\n",
       "      <td>With the lifting of the nuclear-related sancti...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>po_article22181</td>\n",
       "      <td>5</td>\n",
       "      <td>„Co jeszcze musi się wydarzyć, aby czarno-ziel...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...</td>\n",
       "      <td>Doubt,Loaded_Language,Name_Calling-Labeling,Qu...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>po_article2317</td>\n",
       "      <td>9</td>\n",
       "      <td>Obok tego i tych wszystkich pozornych dobrych ...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Doubt</td>\n",
       "      <td>Doubt,Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bg_article2525</td>\n",
       "      <td>5</td>\n",
       "      <td>Французите вече имат проблеми дори с виното. П...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>bg</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bg_article2551</td>\n",
       "      <td>9</td>\n",
       "      <td>Няма да решавам тук дали украинските политици ...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...</td>\n",
       "      <td>Doubt,Flag_Waving,Loaded_Language,Name_Calling...</td>\n",
       "      <td>False</td>\n",
       "      <td>bg</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>po_article22128</td>\n",
       "      <td>52</td>\n",
       "      <td>Gazeta Neues Deutschland uzupełniła pod koniec...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Name_Calling-Labeling...</td>\n",
       "      <td>Loaded_Language,Name_Calling-Labeling,Question...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>po_article2283</td>\n",
       "      <td>19</td>\n",
       "      <td>Najprawdopodobniej odnosił się tym do Memorand...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Conv...</td>\n",
       "      <td>Appeal_to_Hypocrisy,Flag_Waving,Guilt_by_Assoc...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ru_article2283</td>\n",
       "      <td>19</td>\n",
       "      <td>In doing so, he presumably referred to the Bud...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Conv...</td>\n",
       "      <td>Appeal_to_Hypocrisy,Flag_Waving,Guilt_by_Assoc...</td>\n",
       "      <td>False</td>\n",
       "      <td>ru</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en_article773650987</td>\n",
       "      <td>7</td>\n",
       "      <td>In 1961 President Dwight Eisenhower warned Ame...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Flag_Waving</td>\n",
       "      <td>Flag_Waving,Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>po_article2629</td>\n",
       "      <td>15</td>\n",
       "      <td>Do głównych wrogów, których sympatyczny Klaus ...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Doubt,Name_Calling-La...</td>\n",
       "      <td>Doubt,Loaded_Language,Name_Calling-Labeling,Qu...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>po_article23189</td>\n",
       "      <td>7</td>\n",
       "      <td>Francuzi też będą musieli się do tego dostosow...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...</td>\n",
       "      <td>Appeal_to_Values,Doubt,Loaded_Language,Name_Ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>po_article2316</td>\n",
       "      <td>25</td>\n",
       "      <td>Co do „kryptowalut”, Christine Lagarde ocenia,...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Doubt,Loaded_Language,Name_Calling-Labeling</td>\n",
       "      <td>False</td>\n",
       "      <td>po</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en_article777488669</td>\n",
       "      <td>18</td>\n",
       "      <td>According to one widely held opinion, the deat...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice,Doubt,Repetition</td>\n",
       "      <td>Doubt,Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>en_article694327499</td>\n",
       "      <td>37</td>\n",
       "      <td>In a sense, what Bergoglio is doing is worse t...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Doubt,Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sl_article2568</td>\n",
       "      <td>30</td>\n",
       "      <td>Lagache je tudi priča pogovorom Macrona z njeg...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>sl</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en_article773937361</td>\n",
       "      <td>15</td>\n",
       "      <td>But I think honestly most priests are in this ...</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>The text aligns more with Appeal_to_Fear-Preju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  line  \\\n",
       "0        po_article2551     9   \n",
       "1         po_article224     3   \n",
       "2        po_article2289    13   \n",
       "3        cr_article2490    17   \n",
       "4        ru_article2227     5   \n",
       "5   en_article699478811     5   \n",
       "6       po_article22181     5   \n",
       "7        po_article2317     9   \n",
       "8        bg_article2525     5   \n",
       "9        bg_article2551     9   \n",
       "10      po_article22128    52   \n",
       "11       po_article2283    19   \n",
       "12       ru_article2283    19   \n",
       "13  en_article773650987     7   \n",
       "14       po_article2629    15   \n",
       "15      po_article23189     7   \n",
       "16       po_article2316    25   \n",
       "17  en_article777488669    18   \n",
       "18  en_article694327499    37   \n",
       "19       sl_article2568    30   \n",
       "20  en_article773937361    15   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Nie będę tu rozstrzygał, czy ukraińscy polityc...   \n",
       "1   W środę Parlament Europejski przyjął projekty ...   \n",
       "2   Przy przejściu do „kościoła klimatycznego” koś...   \n",
       "3   Za pravoslavne ljude ovaj Četvrti domovinski r...   \n",
       "4   A look at recent headlines also grimly reminds...   \n",
       "5   With the lifting of the nuclear-related sancti...   \n",
       "6   „Co jeszcze musi się wydarzyć, aby czarno-ziel...   \n",
       "7   Obok tego i tych wszystkich pozornych dobrych ...   \n",
       "8   Французите вече имат проблеми дори с виното. П...   \n",
       "9   Няма да решавам тук дали украинските политици ...   \n",
       "10  Gazeta Neues Deutschland uzupełniła pod koniec...   \n",
       "11  Najprawdopodobniej odnosił się tym do Memorand...   \n",
       "12  In doing so, he presumably referred to the Bud...   \n",
       "13  In 1961 President Dwight Eisenhower warned Ame...   \n",
       "14  Do głównych wrogów, których sympatyczny Klaus ...   \n",
       "15  Francuzi też będą musieli się do tego dostosow...   \n",
       "16  Co do „kryptowalut”, Christine Lagarde ocenia,...   \n",
       "17  According to one widely held opinion, the deat...   \n",
       "18  In a sense, what Bergoglio is doing is worse t...   \n",
       "19  Lagache je tudi priča pogovorom Macrona z njeg...   \n",
       "20  But I think honestly most priests are in this ...   \n",
       "\n",
       "                                          true_labels  \\\n",
       "0   Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...   \n",
       "1   Appeal_to_Fear-Prejudice,Doubt,Name_Calling-La...   \n",
       "2   Appeal_to_Fear-Prejudice,Doubt,Exaggeration-Mi...   \n",
       "3   Appeal_to_Fear-Prejudice,Appeal_to_Values,Flag...   \n",
       "4   Appeal_to_Fear-Prejudice,Appeal_to_Hypocrisy,N...   \n",
       "5                            Appeal_to_Fear-Prejudice   \n",
       "6   Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...   \n",
       "7                      Appeal_to_Fear-Prejudice,Doubt   \n",
       "8                            Appeal_to_Fear-Prejudice   \n",
       "9   Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...   \n",
       "10  Appeal_to_Fear-Prejudice,Name_Calling-Labeling...   \n",
       "11  Appeal_to_Fear-Prejudice,Appeal_to_Values,Conv...   \n",
       "12  Appeal_to_Fear-Prejudice,Appeal_to_Values,Conv...   \n",
       "13               Appeal_to_Fear-Prejudice,Flag_Waving   \n",
       "14  Appeal_to_Fear-Prejudice,Doubt,Name_Calling-La...   \n",
       "15  Appeal_to_Fear-Prejudice,Appeal_to_Values,Doub...   \n",
       "16                           Appeal_to_Fear-Prejudice   \n",
       "17          Appeal_to_Fear-Prejudice,Doubt,Repetition   \n",
       "18                           Appeal_to_Fear-Prejudice   \n",
       "19                           Appeal_to_Fear-Prejudice   \n",
       "20                           Appeal_to_Fear-Prejudice   \n",
       "\n",
       "                                          pred_labels  match language  \\\n",
       "0   Appeal_to_Values,Doubt,Flag_Waving,Loaded_Lang...  False       po   \n",
       "1               Loaded_Language,Name_Calling-Labeling  False       po   \n",
       "2   Appeal_to_Hypocrisy,Doubt,Guilt_by_Association...  False       po   \n",
       "3   Appeal_to_Values,Flag_Waving,Loaded_Language,N...  False       cr   \n",
       "4   Appeal_to_Hypocrisy,Appeal_to_Popularity,Doubt...  False       ru   \n",
       "5                                     Loaded_Language  False       en   \n",
       "6   Doubt,Loaded_Language,Name_Calling-Labeling,Qu...  False       po   \n",
       "7                               Doubt,Loaded_Language  False       po   \n",
       "8                                     Loaded_Language  False       bg   \n",
       "9   Doubt,Flag_Waving,Loaded_Language,Name_Calling...  False       bg   \n",
       "10  Loaded_Language,Name_Calling-Labeling,Question...  False       po   \n",
       "11  Appeal_to_Hypocrisy,Flag_Waving,Guilt_by_Assoc...  False       po   \n",
       "12  Appeal_to_Hypocrisy,Flag_Waving,Guilt_by_Assoc...  False       ru   \n",
       "13                        Flag_Waving,Loaded_Language  False       en   \n",
       "14  Doubt,Loaded_Language,Name_Calling-Labeling,Qu...  False       po   \n",
       "15  Appeal_to_Values,Doubt,Loaded_Language,Name_Ca...  False       po   \n",
       "16        Doubt,Loaded_Language,Name_Calling-Labeling  False       po   \n",
       "17                              Doubt,Loaded_Language  False       en   \n",
       "18                              Doubt,Loaded_Language  False       en   \n",
       "19                                    Loaded_Language  False       sl   \n",
       "20                                    Loaded_Language  False       en   \n",
       "\n",
       "                                             analysis  \n",
       "0   The text primarily fits \"Appeal_to_Fear-Prejud...  \n",
       "1   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "2   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "3   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "4   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "5   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "6   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "7   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "8   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "9   The text aligns more with Appeal_to_Fear-Preju...  \n",
       "10  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "11  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "12  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "13  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "14  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "15  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "16  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "17  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "18  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "19  The text aligns more with Appeal_to_Fear-Preju...  \n",
       "20  The text aligns more with Appeal_to_Fear-Preju...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#results_df, output_file = analyze_missed_label('error/true_in_NA_CA_LA.csv', 'Name_Calling-Labeling') #Missed真have假No\n",
    "\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_QU_TH_RE.csv', 'Questioning_the_Reputation')\n",
    "\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_LO_LA.csv', 'Loaded_Language')\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_EX_MI.csv', 'Exaggeration-Minimisation')\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_DO.csv', 'Doubt')\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_CO_KI.csv', 'Conversation_Killer')\n",
    "#results_df, output_file = analyze_correct_label('confusion/conf_true_AP_TO_FE_PR.csv', 'Appeal_to_Fear-Prejudice')\n",
    "\n",
    "#results_df, output_file = analyze_false_positive_label('error/pres_in_NA_CA_LA.csv', 'Name_Calling-Labeling') #误报真No就假have\n",
    "\n",
    "results_df, output_file = analyze_confused_label('confusion/conf_AP_TO_FE_PR_to_LO_LA.csv', 'Appeal_to_Fear-Prejudice', 'Loaded_Language')#Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8ad7ca7-30eb-422d-9846-ff1b3cd50dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database中Total共have 1531 records\n",
      "\n",
      "按Analysis typeStatistics:\n",
      "  correct(Correctly identified): 467 records\n",
      "  false_positive(误报): 464 records\n",
      "  missed(Missed): 445 records\n",
      "  confused(Confused labels): 155 records\n",
      "\n",
      "按TargetLabel statistics:\n",
      "  Loaded_Language: 179 records\n",
      "  Causal_Oversimplification: 166 records\n",
      "  Doubt: 134 records\n",
      "  Red_Herring: 124 records\n",
      "  Obfuscation-Vagueness-Confusion: 107 records\n",
      "  Name_Calling-Labeling: 96 records\n",
      "  Exaggeration-Minimisation: 92 records\n",
      "  Whataboutism: 89 records\n",
      "  Straw_Man: 83 records\n",
      "  Appeal_to_Fear-Prejudice: 80 records\n",
      "  Conversation_Killer: 78 records\n",
      "  Questioning_the_Reputation: 72 records\n",
      "  False_Dilemma-No_Choice: 69 records\n",
      "  Appeal_to_Authority: 60 records\n",
      "  Flag_Waving: 59 records\n",
      "  Appeal_to_Pity: 43 records\n",
      "\n",
      "ConfusionLabel statistics:\n",
      "  Exaggeration-Minimisation byConfusion为 Loaded_Language: 33 records\n",
      "  Questioning_the_Reputation byConfusion为 Loaded_Language: 28 records\n",
      "  Doubt byConfusion为 Loaded_Language: 24 records\n",
      "  Appeal_to_Fear-Prejudice byConfusion为 Loaded_Language: 21 records\n",
      "  Conversation_Killer byConfusion为 Loaded_Language: 20 records\n",
      "  Questioning_the_Reputation byConfusion为 Doubt: 14 records\n",
      "  Loaded_Language byConfusion为 Doubt: 8 records\n",
      "  Loaded_Language byConfusion为 Questioning_the_Reputation: 4 records\n",
      "  Loaded_Language byConfusion为 Exaggeration-Minimisation: 2 records\n",
      "  Loaded_Language byConfusion为 Appeal_to_Fear-Prejudice: 1 records\n",
      "\n",
      "最近of5recordsAnalysisRecord:\n",
      "  ID: en_article773937361, Label: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language), Type: confused, Time: 2025-04-27 15:41:25.596141\n",
      "  ID: sl_article2568, Label: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language), Type: confused, Time: 2025-04-27 15:41:20.934477\n",
      "  ID: en_article694327499, Label: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language), Type: confused, Time: 2025-04-27 15:41:18.862123\n",
      "  ID: en_article777488669, Label: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language), Type: confused, Time: 2025-04-27 15:41:16.611640\n",
      "  ID: po_article2316, Label: Appeal_to_Fear-Prejudice (Confusion为Loaded_Language), Type: confused, Time: 2025-04-27 15:41:13.545250\n"
     ]
    }
   ],
   "source": [
    "def get_database_stats():\n",
    "    \"\"\"\n",
    "    Get data库中recordsStatistical information\n",
    "    \"\"\"\n",
    "    import sqlite3\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Connection到Database\n",
    "    DB_NAME = \"propaganda_techniques_analysis.db\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # QueryTable中Total number of records\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM label_analysis\")\n",
    "    total_records = cursor.fetchone()[0]\n",
    "    print(f\"Database中Total共have {total_records} records\")\n",
    "    \n",
    "    # 按Analysis typeStatistics\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT analysis_type, COUNT(*) as count \n",
    "    FROM label_analysis \n",
    "    GROUP BY analysis_type\n",
    "    ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    analysis_type_stats = cursor.fetchall()\n",
    "    print(\"\\n按Analysis typeStatistics:\")\n",
    "    for analysis_type, count in analysis_type_stats:\n",
    "        analysis_type_name = \"\"\n",
    "        if analysis_type == \"missed\":\n",
    "            analysis_type_name = \"Missed\"\n",
    "        elif analysis_type == \"false_positive\":\n",
    "            analysis_type_name = \"误报\"\n",
    "        elif analysis_type == \"correct\":\n",
    "            analysis_type_name = \"Correctly identified\"\n",
    "        elif analysis_type == \"confused\":\n",
    "            analysis_type_name = \"Confused labels\"\n",
    "            \n",
    "        print(f\"  {analysis_type}({analysis_type_name}): {count} records\")\n",
    "    \n",
    "    # 按TargetLabel statistics\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT target_label, COUNT(*) as count \n",
    "    FROM label_analysis \n",
    "    GROUP BY target_label\n",
    "    ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    target_label_stats = cursor.fetchall()\n",
    "    print(\"\\n按TargetLabel statistics:\")\n",
    "    for target_label, count in target_label_stats:\n",
    "        print(f\"  {target_label}: {count} records\")\n",
    "    \n",
    "    # ConfusionLabel statistics\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT target_label, confused_label, COUNT(*) as count \n",
    "    FROM label_analysis \n",
    "    WHERE analysis_type = 'confused' AND confused_label IS NOT NULL\n",
    "    GROUP BY target_label, confused_label\n",
    "    ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    confused_stats = cursor.fetchall()\n",
    "    if confused_stats:\n",
    "        print(\"\\nConfusionLabel statistics:\")\n",
    "        for target_label, confused_label, count in confused_stats:\n",
    "            print(f\"  {target_label} byConfusion为 {confused_label}: {count} records\")\n",
    "    \n",
    "    # Get最近ofAnalysisRecord\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT id, target_label, analysis_type, confused_label, created_at \n",
    "    FROM label_analysis \n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 5\n",
    "    \"\"\")\n",
    "    recent_records = cursor.fetchall()\n",
    "    print(\"\\n最近of5recordsAnalysisRecord:\")\n",
    "    for id, target_label, analysis_type, confused_label, created_at in recent_records:\n",
    "        confused_info = f\"(Confusion为{confused_label})\" if confused_label else \"\"\n",
    "        print(f\"  ID: {id}, Label: {target_label} {confused_info}, Type: {analysis_type}, Time: {created_at}\")\n",
    "    \n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    \n",
    "    return {\n",
    "        \"total_records\": total_records,\n",
    "        \"analysis_type_stats\": analysis_type_stats,\n",
    "        \"target_label_stats\": target_label_stats,\n",
    "        \"confused_stats\": confused_stats,\n",
    "        \"recent_records\": recent_records\n",
    "    }\n",
    "\n",
    "# Call函数Get data库Statistical information\n",
    "stats = get_database_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3bcd0b7-b9bf-4f1a-8d5a-b854e49e82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database中of所haveRecordSuccessfully exported到: propaganda_analysis_export_20250427_154826.tsv\n",
      "Total exported 1531 records，contains 10 fields\n",
      "\n",
      "Data分布概况:\n",
      "Analysis type distribution:\n",
      "analysis_type\n",
      "correct           467\n",
      "false_positive    464\n",
      "missed            445\n",
      "confused          155\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TargetLabel distribution:\n",
      "target_label\n",
      "Loaded_Language                    179\n",
      "Causal_Oversimplification          166\n",
      "Doubt                              134\n",
      "Red_Herring                        124\n",
      "Obfuscation-Vagueness-Confusion    107\n",
      "Name_Calling-Labeling               96\n",
      "Exaggeration-Minimisation           92\n",
      "Whataboutism                        89\n",
      "Straw_Man                           83\n",
      "Appeal_to_Fear-Prejudice            80\n",
      "Name: count, dtype: int64 ...\n"
     ]
    }
   ],
   "source": [
    "def export_database_to_tsv():\n",
    "    \"\"\"\n",
    "    convertDatabase中of所haveRecordExport asTSVFile\n",
    "    \"\"\"\n",
    "    import sqlite3\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Connection到Database\n",
    "    DB_NAME = \"propaganda_techniques_analysis.db\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    \n",
    "    # Query所haveData\n",
    "    query = \"SELECT * FROM label_analysis\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    # GenerateOutput file名（containsTimestamp）\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = f\"propaganda_analysis_export_{timestamp}.tsv\"\n",
    "    \n",
    "    # usecsv模块Save asTSVFile，确保CorrectProcess特殊字符and分隔符\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        # CreateTSVwriter，明确指定分隔符为制Table符\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        \n",
    "        # Write column names\n",
    "        writer.writerow(df.columns)\n",
    "        \n",
    "        # Write each row of data\n",
    "        for _, row in df.iterrows():\n",
    "            writer.writerow(row.values)\n",
    "    \n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Database中of所haveRecordSuccessfully exported到: {output_file}\")\n",
    "    print(f\"Total exported {len(df)} records，contains {len(df.columns)} fields\")\n",
    "    \n",
    "    # 显示Data分布information\n",
    "    print(\"\\nData分布概况:\")\n",
    "    print(f\"Analysis type distribution:\\n{df['analysis_type'].value_counts()}\")\n",
    "    print(f\"\\nTargetLabel distribution:\\n{df['target_label'].value_counts().head(10)} ...\")\n",
    "    \n",
    "    return output_file, df\n",
    "\n",
    "# Call函数Export data\n",
    "output_file, exported_df = export_database_to_tsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a1d93-60b7-478f-9ee3-c4054143f183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TRLALenv)",
   "language": "python",
   "name": "trlalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}