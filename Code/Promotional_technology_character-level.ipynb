{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ AI vs Rule-based propaganda techniquecharacter-level span localizationcomparison system\n",
    "\n",
    "**Fully debuggable system** üéØ\n",
    "\n",
    "## üìã System features\n",
    "- ‚úÖ **Rule-based method**: heuristic localization based on expert technique descriptions\n",
    "- ü§ñ **AI method**: semantic localization based on GPT-4o-mini  \n",
    "- üìä **Comparative analysis**: detailed effectiveness and cost comparison\n",
    "- üîß **Step-by-step debugging**: each stage can be tested and verified independently\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Environment setup and dependency check üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 | packaged by conda-forge | (main, Apr 10 2025, 22:21:13) [GCC 13.3.0]\n",
      "‚úÖ pandas imported\n",
      "‚úÖ OpenAI library imported (version: 1.108.2)\n",
      "\n",
      "üöÄ Environment check completed\n",
      "   Rule system: ‚úÖ available\n",
      "   AITODO: translate to English: ‚úÖ available\n"
     ]
    }
   ],
   "source": [
    "# üîß Environment check and basic imports\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Basic imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"‚úÖ pandas imported\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è pandas not installed; some analysis features may be limited\")\n",
    "\n",
    "# Check OpenAI library\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "    print(f\"‚úÖ OpenAI library imported (version: {openai.__version__})\")\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è OpenAI library not installed\")\n",
    "    print(\"   Install command: pip install openai\")\n",
    "\n",
    "print(f\"\\nüöÄ Environment check completed\")\n",
    "print(f\"   Rule system: ‚úÖ available\")\n",
    "print(f\"   AITODO: translate to English: {'‚úÖ available' if OPENAI_AVAILABLE else '‚ùå openai package required'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Config file paths üìÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ TODO: translate to EnglishConfig:\n",
      "   TODO: translate to English: your_llm_tests_results_file_location\n",
      "   ArticleTODO: translate to English: /home/jovyan/2023task3/data/en/dev-articles-subtask-3\n",
      "   TODO: translate to English: /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/data_analy/keyword_find/autogen_propaganda_analysis_results/en/\n",
      "   APIConfigTODO: translate to English: your_api_config_file_location\n",
      "   TODO: translate to English: your_checkthat_data_directory\n",
      "\n",
      "üîç TODO: translate to English:\n",
      "   TODO: translate to English: ‚úÖ your_llm_tests_results_file_location\n",
      "   ArticleTODO: translate to English: ‚úÖ /home/jovyan/2023task3/data/en/dev-articles-subtask-3\n",
      "   TODO: translate to English: ‚úÖ /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/data_analy/keyword_find/autogen_propaganda_analysis_results/en/\n",
      "   APIConfigTODO: translate to English: ‚úÖ your_api_config_file_location\n",
      "\n",
      "‚úÖ TODO: translate to English\n",
      "\n",
      "üîë APIConfigTODO: translate to English:\n",
      "   ConfigTODO: translate to English: TODO: translate to English - your_api_config_file_location\n",
      "   OpenAITODO: translate to English: ‚úÖ TODO: translate to English\n",
      "   üìã TODO: translate to EnglishStep2BTODO: translate to EnglishAPIConfigTODO: translate to English\n",
      "\n",
      "‚öôÔ∏è ProcessingTODO: translate to English:\n",
      "   TODO: translate to English: üöÄ TODO: translate to English - ProcessingTODO: translate to EnglishArticle\n",
      "   AITODO: translate to English: 0.1 TODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üîß Configure your file paths (edit to match your environment)\n",
    "\n",
    "# üåç Language selection\n",
    "LANGUAGE_CODE = \"en\"  # po=Polish, ru=Russian, bg=Bulgarian, sl=Slovenian\n",
    "\n",
    "# TODO: translate to English\n",
    "LANGUAGE_INFO = {\n",
    "    \"po\": {\"name\": \"Polish\", \"expert_desc\": \"Polishpropaganda technique analysis expert\"},\n",
    "    \"ru\": {\"name\": \"Russian\", \"expert_desc\": \"Russianpropaganda technique analysis expert\"},\n",
    "    \"bg\": {\"name\": \"Bulgarian\", \"expert_desc\": \"Bulgarianpropaganda technique analysis expert\"},\n",
    "    \"sl\": {\"name\": \"Slovenian\", \"expert_desc\": \"Slovenianpropaganda technique analysis expert\"},\n",
    "    \"en\": {\"name\": \"English\", \"expert_desc\": \"Englishpropaganda technique analysis expert\"}\n",
    "}\n",
    "\n",
    "ORIGINAL_MODE = \"voting_aggressiv\" #TODO: translate to EnglishÔºåTODO: translate to Englishvoting_aggressivÔºåcontextTODO: translate to Englishmodel\n",
    "\n",
    "CURRENT_LANGUAGE_NAME = LANGUAGE_INFO.get(LANGUAGE_CODE, {}).get(\"name\", \"Unknown\")\n",
    "CURRENT_EXPERT_DESC = LANGUAGE_INFO.get(LANGUAGE_CODE, {}).get(\"expert_desc\", f\"{CURRENT_LANGUAGE_NAME}propaganda technique analysis expert\")\n",
    "\n",
    "\n",
    "# /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests/semeval2023_task3_dev_results_po_po_voting_aggressive_all.tsv\n",
    "# /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/LLM_tests/semeval2023_task3_dev_results_po_po_context_all.tsv\n",
    "# /home/jovyan/TRLAL/Total_work/research_projects/disinformation_detection/notebooks/results/model_tests/semeval_task3_po_dev_predictions_official_format.txt\n",
    "\n",
    "# ‚ö†Ô∏è TODO: translate to English\n",
    "PARAGRAPH_RESULTS_FILE = \"your_llm_tests_results_file_location\" # TODO: translate to Englishfile paths\n",
    "\n",
    "\n",
    "ARTICLES_DIR = f\"your_dev_articles_subtask_3_directory/{LANGUAGE_CODE}/dev-articles-subtask-3\" # TODO: translate to English\n",
    "TECHNIQUE_PROMPTS_DIR = f\"your_autogen_propaganda_analysis_results_directory/{LANGUAGE_CODE}/\" # TODO: translate to English\n",
    "\n",
    "# üîë APIConfig file paths\n",
    "API_CONFIG_FILE = \"your_api_config_file_location\"\n",
    "\n",
    "# TODO: translate to EnglishAPITODO: translate to EnglishÔºàTODO: translate to EnglishStep2BTODO: translate to EnglishConfigÔºâ\n",
    "OPENAI_API_KEY = \"to-be-configured\"  # TODO: translate to EnglishÔºåTODO: translate to EnglishConfigTODO: translate to English\n",
    "\n",
    "# TODO: translate to English\n",
    "OUTPUT_DIR = \"your_checkthat_data_directory\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ProcessingTODO: translate to English\n",
    "# ProcessingTODO: translate to English - TODO: translate to EnglishConfig\n",
    "PRODUCTION_MODE = True  # TODO: translate to English\n",
    "AI_DELAY_SECONDS = 0.1  # AITODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "\n",
    "print(\"üìÅ TODO: translate to EnglishConfig:\")\n",
    "print(f\"   TODO: translate to English: {PARAGRAPH_RESULTS_FILE}\")\n",
    "print(f\"   ArticleTODO: translate to English: {ARTICLES_DIR}\")\n",
    "print(f\"   TODO: translate to English: {TECHNIQUE_PROMPTS_DIR}\")\n",
    "print(f\"   APIConfigTODO: translate to English: {API_CONFIG_FILE}\")\n",
    "print(f\"   TODO: translate to English: {OUTPUT_DIR}\")\n",
    "\n",
    "# TODO: translate to English\n",
    "print(f\"\\nüîç TODO: translate to English:\")\n",
    "files_check = {\n",
    "    \"TODO: translate to English\": PARAGRAPH_RESULTS_FILE,\n",
    "    \"ArticleTODO: translate to English\": ARTICLES_DIR,\n",
    "    \"TODO: translate to English\": TECHNIQUE_PROMPTS_DIR,\n",
    "    \"APIConfigTODO: translate to English\": API_CONFIG_FILE\n",
    "}\n",
    "\n",
    "all_paths_valid = True\n",
    "for name, path in files_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {name}: {status} {path}\")\n",
    "    if not exists:\n",
    "        all_paths_valid = False\n",
    "\n",
    "if all_paths_valid:\n",
    "    print(\"\\n‚úÖ TODO: translate to English\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TODO: translate to EnglishÔºåTODO: translate to EnglishConfig\")\n",
    "\n",
    "# APIConfigTODO: translate to English\n",
    "print(f\"\\nüîë APIConfigTODO: translate to English:\")\n",
    "print(f\"   ConfigTODO: translate to English: {'TODO: translate to English' if os.path.exists(API_CONFIG_FILE) else 'TODO: translate to English'} - {API_CONFIG_FILE}\")\n",
    "if OPENAI_AVAILABLE:\n",
    "    print(f\"   OpenAITODO: translate to English: ‚úÖ TODO: translate to English\")\n",
    "else:\n",
    "    print(f\"   OpenAITODO: translate to English: ‚ùå TODO: translate to English (pip install openai)\")\n",
    "print(f\"   üìã TODO: translate to EnglishStep2BTODO: translate to EnglishAPIConfigTODO: translate to English\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è ProcessingTODO: translate to English:\")#\n",
    "print(f\"   TODO: translate to English: üöÄ TODO: translate to English - ProcessingTODO: translate to EnglishArticle\")\n",
    "print(f\"   AITODO: translate to English: {AI_DELAY_SECONDS} TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2B: TODO: translate to EnglishAPIConfigTODO: translate to English üîë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ APIConfigTODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üîë TODO: translate to EnglishAPIConfigTODO: translate to English\n",
    "\n",
    "class APIConfigLoader:\n",
    "    \"\"\"TODO: translate to EnglishAPIConfigTODO: translate to English\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file_path: str):\n",
    "        self.config_file_path = config_file_path\n",
    "        self.config_data = None\n",
    "        self.available_apis = {}\n",
    "        self.selected_api = None\n",
    "        self.api_key = None\n",
    "        \n",
    "    def load_config(self) -> bool:\n",
    "        \"\"\"TODO: translate to EnglishAPIConfigTODO: translate to English\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.config_file_path):\n",
    "                print(f\"‚ùå ConfigTODO: translate to English: {self.config_file_path}\")\n",
    "                return False\n",
    "            \n",
    "            with open(self.config_file_path, 'r', encoding='utf-8') as f:\n",
    "                self.config_data = json.load(f)\n",
    "            \n",
    "            print(f\"‚úÖ TODO: translate to EnglishAPIConfig: {self.config_data.get('version', 'unknown')}\")\n",
    "            return True\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ùå ConfigTODO: translate to EnglishJSONTODO: translate to English: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ConfigTODO: translate to English: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def scan_available_apis(self) -> Dict[str, Dict]:\n",
    "        \"\"\"TODO: translate to EnglishavailableTODO: translate to EnglishAPIConfig\"\"\"\n",
    "        if not self.config_data:\n",
    "            return {}\n",
    "        \n",
    "        api_keys = self.config_data.get('api_keys', {})\n",
    "        api_configs = self.config_data.get('api_configs', {})\n",
    "        \n",
    "        self.available_apis = {}\n",
    "        \n",
    "        # TODO: translate to EnglishAPITODO: translate to EnglishavailableTODO: translate to English\n",
    "        for api_name, config in api_configs.items():\n",
    "            # TODO: translate to EnglishAPITODO: translate to English\n",
    "            api_key = None\n",
    "            \n",
    "            # TODO: translate to EnglishAPITODO: translate to English\n",
    "            if 'openai' in api_name.lower():\n",
    "                api_key = api_keys.get('openai_api_key')\n",
    "            elif 'anthropic' in api_name.lower():\n",
    "                api_key = api_keys.get('anthropic_api_key')\n",
    "            elif 'google' in api_name.lower():\n",
    "                api_key = api_keys.get('google_api_key')\n",
    "            elif 'huggingface' in api_name.lower():\n",
    "                api_key = api_keys.get('huggingface_token')\n",
    "            elif 'cohere' in api_name.lower():\n",
    "                api_key = api_keys.get('cohere_api_key')\n",
    "            elif 'together' in api_name.lower():\n",
    "                api_key = api_keys.get('together_api_key')\n",
    "            \n",
    "            # TODO: translate to EnglishAPITODO: translate to English\n",
    "            key_valid = self._validate_api_key(api_key, config.get('key_prefix'))\n",
    "            \n",
    "            if key_valid:\n",
    "                self.available_apis[api_name] = {\n",
    "                    'config': config,\n",
    "                    'api_key': api_key,\n",
    "                    'models': config.get('models', []),\n",
    "                    'pricing_tier': config.get('pricing_tier', 'unknown'),\n",
    "                    'features': config.get('features', [])\n",
    "                }\n",
    "        \n",
    "        return self.available_apis\n",
    "    \n",
    "    def _validate_api_key(self, api_key: str, key_prefix: str = None) -> bool:\n",
    "        \"\"\"TODO: translate to EnglishAPITODO: translate to English\"\"\"\n",
    "        if not api_key or api_key in ['null', 'None', None, 'key']:\n",
    "            return False\n",
    "        \n",
    "        if len(api_key) < 10:  # TODO: translate to English\n",
    "            return False\n",
    "        \n",
    "        if key_prefix and not api_key.startswith(key_prefix):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def configure_for_openai(self) -> Tuple[bool, str, str]:\n",
    "        \"\"\"TODO: translate to EnglishConfigOpenAI API\"\"\"\n",
    "        if 'openai' in self.available_apis:\n",
    "            openai_config = self.available_apis['openai']\n",
    "            self.selected_api = 'openai'\n",
    "            self.api_key = openai_config['api_key']\n",
    "            \n",
    "            # TODO: translate to EnglishOpenAITODO: translate to English\n",
    "            available_models = openai_config['models']\n",
    "            preferred_models = ['gpt-4o-mini', 'gpt-4o', 'gpt-3.5-turbo']\n",
    "            \n",
    "            selected_model = None\n",
    "            for model in preferred_models:\n",
    "                if model in available_models:\n",
    "                    selected_model = model\n",
    "                    break\n",
    "            \n",
    "            if not selected_model:\n",
    "                selected_model = available_models[0] if available_models else 'gpt-4o-mini'\n",
    "            \n",
    "            return True, self.api_key, selected_model\n",
    "        \n",
    "        return False, \"\", \"\"\n",
    "    \n",
    "    def get_api_summary(self) -> Dict:\n",
    "        \"\"\"TODO: translate to EnglishAPIConfigTODO: translate to English\"\"\"\n",
    "        if not self.config_data:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'config_version': self.config_data.get('version'),\n",
    "            'total_apis': len(self.config_data.get('api_configs', {})),\n",
    "            'available_apis': len(self.available_apis),\n",
    "            'api_list': list(self.available_apis.keys()),\n",
    "            'preferred_models': self.config_data.get('preferred_models', [])[:5],\n",
    "            'selected_api': self.selected_api\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ APIConfigTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë TODO: translate to EnglishAPIConfig...\n",
      "‚úÖ TODO: translate to EnglishAPIConfig: 1.0\n",
      "\n",
      "üìä APIavailableTODO: translate to English:\n",
      "   ConfigTODO: translate to EnglishAPITODO: translate to English: 6\n",
      "   availableTODO: translate to EnglishAPITODO: translate to English: 4\n",
      "\n",
      "‚úÖ availableTODO: translate to EnglishAPIs:\n",
      "   üü¢ OpenAI: 6TODO: translate to English, premium, TODO: translate to English: sk-proj-G2oN...IDsA\n",
      "   üü¢ Google Gemini: 4TODO: translate to English, free_tier_available, TODO: translate to English: AIzaSyB4Nz9k...QOFo\n",
      "   üü¢ Anthropic Claude: 5TODO: translate to English, premium, TODO: translate to English: sk-ant-api03...twAA\n",
      "   üü¢ Hugging Face: 5TODO: translate to English, free_tier_available, TODO: translate to English: hf_LTTTnEPGR...mygp\n",
      "\n",
      "ü§ñ OpenAIConfigTODO: translate to English:\n",
      "   APITODO: translate to English: sk-proj-G2oN...IDsA\n",
      "   TODO: translate to English: gpt-4o-mini\n",
      "   AITODO: translate to English: üöÄ TODO: translate to English\n",
      "\n",
      "üìã ConfigTODO: translate to English:\n",
      "   Configversion: 1.0\n",
      "   availableAPI: openai, google, anthropic, huggingface\n",
      "   TODO: translate to English: gemini-1.5-flash, gpt-4o-mini, gpt-4o, gpt-3.5-turbo, claude-3-haiku\n",
      "\n",
      "üéØ TODO: translate to EnglishAITODO: translate to English:\n",
      "   üöÄ AITODO: translate to English (TODO: translate to EnglishConfigTODO: translate to English)\n",
      "   üîß Rule systemTODO: translate to English\n",
      "   üìä TODO: translate to EnglishAI vs Rule-basedComparative analysis\n",
      "\n",
      "‚úÖ APIConfigTODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üîÑ TODO: translate to EnglishAPIConfigTODO: translate to English\n",
    "\n",
    "print(\"üîë TODO: translate to EnglishAPIConfig...\")\n",
    "\n",
    "# TODO: translate to EnglishAPIConfigTODO: translate to English\n",
    "api_loader = APIConfigLoader(API_CONFIG_FILE)\n",
    "\n",
    "# TODO: translate to EnglishConfigTODO: translate to English\n",
    "config_loaded = api_loader.load_config()\n",
    "\n",
    "if config_loaded:\n",
    "    # TODO: translate to EnglishavailableTODO: translate to EnglishAPIs\n",
    "    available_apis = api_loader.scan_available_apis()\n",
    "    \n",
    "    print(f\"\\nüìä APIavailableTODO: translate to English:\")\n",
    "    print(f\"   ConfigTODO: translate to EnglishAPITODO: translate to English: {len(api_loader.config_data.get('api_configs', {}))}\")\n",
    "    print(f\"   availableTODO: translate to EnglishAPITODO: translate to English: {len(available_apis)}\")\n",
    "    \n",
    "    if available_apis:\n",
    "        print(f\"\\n‚úÖ availableTODO: translate to EnglishAPIs:\")\n",
    "        for api_name, api_info in available_apis.items():\n",
    "            config = api_info['config']\n",
    "            models_count = len(api_info['models'])\n",
    "            pricing = api_info['pricing_tier']\n",
    "            key_preview = api_info['api_key'][:12] + '...' + api_info['api_key'][-4:] if len(api_info['api_key']) > 16 else api_info['api_key'][:8] + '...'\n",
    "            print(f\"   üü¢ {config['name']}: {models_count}TODO: translate to English, {pricing}, TODO: translate to English: {key_preview}\")\n",
    "        \n",
    "        # ConfigOpenAIÔºàTODO: translate to Englishcharacter-level span localizationÔºâ\n",
    "        openai_configured, openai_key, openai_model = api_loader.configure_for_openai()\n",
    "        \n",
    "        if openai_configured:\n",
    "            OPENAI_API_KEY = openai_key\n",
    "            AI_MODEL = openai_model\n",
    "            ai_ready = OPENAI_AVAILABLE\n",
    "            \n",
    "            print(f\"\\nü§ñ OpenAIConfigTODO: translate to English:\")\n",
    "            print(f\"   APITODO: translate to English: {openai_key[:12]}...{openai_key[-4:]}\")\n",
    "            print(f\"   TODO: translate to English: {openai_model}\")\n",
    "            print(f\"   AITODO: translate to English: üöÄ TODO: translate to English\")\n",
    "        else:\n",
    "            # TODO: translate to EnglishavailableAPI\n",
    "            if available_apis:\n",
    "                alt_api_name = list(available_apis.keys())[0]\n",
    "                alt_config = available_apis[alt_api_name]\n",
    "                print(f\"\\n‚ö†Ô∏è OpenAITODO: translate to EnglishavailableÔºåTODO: translate to EnglishAPI: {alt_config['config']['name']}\")\n",
    "                print(f\"   TODO: translate to EnglishnotebookTODO: translate to EnglishOpenAIÔºåTODO: translate to EnglishAPITODO: translate to English\")\n",
    "            \n",
    "            OPENAI_API_KEY = \"not-available\"\n",
    "            ai_ready = False\n",
    "            print(f\"\\n‚ùå OpenAITODO: translate to Englishavailable\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå TODO: translate to EnglishavailableTODO: translate to EnglishAPITODO: translate to English\")\n",
    "        print(f\"   TODO: translate to EnglishConfigTODO: translate to EnglishAPITODO: translate to English\")\n",
    "        print(f\"   TODO: translate to English'key'\")\n",
    "        OPENAI_API_KEY = \"not-available\"\n",
    "        ai_ready = False\n",
    "    \n",
    "    # TODO: translate to EnglishConfigTODO: translate to English\n",
    "    api_summary = api_loader.get_api_summary()\n",
    "    print(f\"\\nüìã ConfigTODO: translate to English:\")\n",
    "    print(f\"   Configversion: {api_summary['config_version']}\")\n",
    "    if api_summary['api_list']:\n",
    "        print(f\"   availableAPI: {', '.join(api_summary['api_list'])}\")\n",
    "    print(f\"   TODO: translate to English: {', '.join(api_summary['preferred_models'])}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ùå ConfigTODO: translate to English\")\n",
    "    print(f\"   TODO: translate to English: {API_CONFIG_FILE}\")\n",
    "    print(f\"   TODO: translate to EnglishAPITODO: translate to English\")\n",
    "    \n",
    "    # TODO: translate to EnglishConfig\n",
    "    OPENAI_API_KEY = \"your-openai-api-key-here\"\n",
    "    ai_ready = False\n",
    "\n",
    "# TODO: translate to EnglishAITODO: translate to English\n",
    "print(f\"\\nüéØ TODO: translate to EnglishAITODO: translate to English:\")\n",
    "if ai_ready:\n",
    "    print(f\"   üöÄ AITODO: translate to English (TODO: translate to EnglishConfigTODO: translate to English)\")\n",
    "    print(f\"   üîß Rule systemTODO: translate to English\")\n",
    "    print(f\"   üìä TODO: translate to EnglishAI vs Rule-basedComparative analysis\")\n",
    "else:\n",
    "    print(f\"   üìê Rule systemTODO: translate to English\")\n",
    "    print(f\"   ‚ö†Ô∏è AITODO: translate to EnglishAPITODO: translate to English\")\n",
    "    print(f\"   üí° TODO: translate to EnglishRule-based methodTODO: translate to EnglishProcessing\")\n",
    "    print(f\"   üìù TODO: translate to EnglishAI methodÔºåTODO: translate to EnglishConfigTODO: translate to EnglishOpenAI APITODO: translate to English\")\n",
    "\n",
    "print(f\"\\n‚úÖ APIConfigTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: TODO: translate to English üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TODO: translate to English\n",
      "   - ParagraphResult: TODO: translate to English\n",
      "   - CharacterResult: TODO: translate to English (TODO: translate to English)\n",
      "   - ArticleData: ArticleTODO: translate to English\n",
      "   - TechniqueDefinition: TODO: translate to English\n",
      "   - ProcessingStats: ProcessingTODO: translate to English (TODO: translate to EnglishComparative analysis)\n"
     ]
    }
   ],
   "source": [
    "# üìä TODO: translate to English\n",
    "\n",
    "@dataclass\n",
    "class ParagraphResult:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    article_id: str\n",
    "    technique: str\n",
    "    start: int\n",
    "    end: int\n",
    "    text_segment: str = \"\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # TODO: translate to English\n",
    "        assert self.start >= 0, f\"TODO: translate to English: {self.start}\"\n",
    "        assert self.end > self.start, f\"TODO: translate to English: {self.start}-{self.end}\"\n",
    "\n",
    "@dataclass\n",
    "class CharacterResult:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    article_id: str\n",
    "    technique: str\n",
    "    start: int\n",
    "    end: int\n",
    "    confidence: float = 1.0\n",
    "    source: str = \"rule\"  # \"rule\" or \"ai\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # TODO: translate to English\n",
    "        assert 0 <= self.confidence <= 1, f\"confidenceTODO: translate to English0-1TODO: translate to English: {self.confidence}\"\n",
    "        assert self.source in [\"rule\", \"ai\"], f\"TODO: translate to EnglishruleTODO: translate to Englishai: {self.source}\"\n",
    "\n",
    "@dataclass\n",
    "class ArticleData:\n",
    "    \"\"\"TODO: translate to EnglishArticleTODO: translate to English\"\"\"\n",
    "    article_id: str\n",
    "    article_path: str\n",
    "    article_text: str\n",
    "    paragraph_results: List[ParagraphResult]\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        print(f\"   üìÑ Article{self.article_id}: {len(self.article_text):,}TODO: translate to English, {len(self.paragraph_results)}TODO: translate to English\")\n",
    "\n",
    "@dataclass\n",
    "class TechniqueDefinition:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    detection_criteria: List[str]\n",
    "    keywords: List[str]\n",
    "    patterns: List[str]\n",
    "    examples: List[str]\n",
    "    cultural_context: str\n",
    "    file_path: str\n",
    "\n",
    "@dataclass\n",
    "class ProcessingStats:\n",
    "    \"\"\"ProcessingTODO: translate to English\"\"\"\n",
    "    technique: str\n",
    "    total_processed: int\n",
    "    successfully_located: int\n",
    "    avg_positions: float\n",
    "    avg_confidence: float\n",
    "    processing_time: float\n",
    "    source: str  # \"rule\" or \"ai\"\n",
    "    \n",
    "    @property\n",
    "    def success_rate(self) -> float:\n",
    "        return self.successfully_located / self.total_processed if self.total_processed > 0 else 0\n",
    "\n",
    "print(\"‚úÖ TODO: translate to English\")\n",
    "print(\"   - ParagraphResult: TODO: translate to English\")\n",
    "print(\"   - CharacterResult: TODO: translate to English (TODO: translate to English)\")\n",
    "print(\"   - ArticleData: ArticleTODO: translate to English\")\n",
    "print(\"   - TechniqueDefinition: TODO: translate to English\")\n",
    "print(\"   - ProcessingStats: ProcessingTODO: translate to English (TODO: translate to EnglishComparative analysis)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: TODO: translate to English üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üìö TODO: translate to English\n",
    "\n",
    "class TechniqueDefinitionLoader:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    \n",
    "    def __init__(self, prompts_dir: str, debug_mode: bool = True):\n",
    "        self.prompts_dir = prompts_dir\n",
    "        self.debug_mode = debug_mode\n",
    "        self.technique_definitions = {}\n",
    "        self.load_stats = {\n",
    "            'files_found': 0,\n",
    "            'files_loaded': 0,\n",
    "            'total_keywords': 0,\n",
    "            'total_patterns': 0,\n",
    "            'load_errors': []\n",
    "        }\n",
    "    \n",
    "    def load_all_definitions(self) -> Dict[str, TechniqueDefinition]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        print(f\"üìö TODO: translate to English...\")\n",
    "        \n",
    "        if not os.path.exists(self.prompts_dir):\n",
    "            print(f\"‚ùå TODO: translate to English: {self.prompts_dir}\")\n",
    "            return {}\n",
    "        \n",
    "        # TODO: translate to EnglishpromptTODO: translate to English\n",
    "        prompt_files = glob.glob(os.path.join(self.prompts_dir, \"*_prompt.md\"))\n",
    "        self.load_stats['files_found'] = len(prompt_files)\n",
    "        \n",
    "        if not prompt_files:\n",
    "            print(f\"‚ö†Ô∏è TODO: translate to English*_prompt.mdTODO: translate to English\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"   TODO: translate to English {len(prompt_files)} TODO: translate to English\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        for file_path in prompt_files:\n",
    "            try:\n",
    "                technique_name = self._extract_technique_name(file_path)\n",
    "                definition = self._parse_definition_file(file_path, technique_name)\n",
    "                \n",
    "                self.technique_definitions[technique_name] = definition\n",
    "                self.load_stats['files_loaded'] += 1\n",
    "                self.load_stats['total_keywords'] += len(definition.keywords)\n",
    "                self.load_stats['total_patterns'] += len(definition.patterns)\n",
    "                \n",
    "                if self.debug_mode:\n",
    "                    print(f\"   ‚úÖ {technique_name}: {len(definition.keywords)}TODO: translate to English, {len(definition.patterns)}TODO: translate to English\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"TODO: translate to English {os.path.basename(file_path)}: {str(e)}\"\n",
    "                self.load_stats['load_errors'].append(error_msg)\n",
    "                print(f\"   ‚ùå {error_msg}\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        print(f\"\\nüìä TODO: translate to English:\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['files_found']}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['files_loaded']}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['total_keywords']}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['total_patterns']}\")\n",
    "        print(f\"   TODO: translate to English: {len(self.load_stats['load_errors'])}\")\n",
    "        \n",
    "        return self.technique_definitions\n",
    "    \n",
    "    def _extract_technique_name(self, file_path: str) -> str:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        filename = os.path.basename(file_path)\n",
    "        return filename.replace('_prompt.md', '')\n",
    "    \n",
    "    def _parse_definition_file(self, file_path: str, technique_name: str) -> TechniqueDefinition:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        return TechniqueDefinition(\n",
    "            name=technique_name,\n",
    "            description=self._extract_description(content),\n",
    "            detection_criteria=self._extract_detection_criteria(content),\n",
    "            keywords=self._extract_keywords(content),\n",
    "            patterns=self._extract_patterns(content),\n",
    "            examples=self._extract_examples(content),\n",
    "            cultural_context=self._extract_cultural_context(content),\n",
    "            file_path=file_path\n",
    "        )\n",
    "    \n",
    "    def _extract_description(self, content: str) -> str:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        description_lines = []\n",
    "        \n",
    "        for line in lines[:20]:  # TODO: translate to English20TODO: translate to English\n",
    "            if any(keyword in line.lower() for keyword in ['technique', 'fallacy', 'propaganda']):\n",
    "                description_lines.append(line.strip())\n",
    "                break\n",
    "        \n",
    "        return ' '.join(description_lines)[:300]\n",
    "    \n",
    "    def _extract_keywords(self, content: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        keywords = []\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        keyword_patterns = [\n",
    "            r'\"([^\"]{2,50})\"',  # TODO: translate to English\n",
    "            r\"'([^']{2,50})'\",  # TODO: translate to English\n",
    "            r'`([^`]{2,50})`'    # TODO: translate to English\n",
    "        ]\n",
    "        \n",
    "        for pattern in keyword_patterns:\n",
    "            matches = re.findall(pattern, content)\n",
    "            for match in matches:\n",
    "                # TODO: translate to EnglishPolishTODO: translate to English\n",
    "                if self._is_likely_polish_keyword(match):\n",
    "                    keywords.append(match.lower().strip())\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        return list(set(keywords))[:15]\n",
    "    \n",
    "    def _is_likely_polish_keyword(self, text: str) -> bool:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        current_lang = globals().get('LANGUAGE_CODE', 'po')\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        special_chars_map = {\n",
    "            \"po\": \"ƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º\",\n",
    "            \"ru\": \"–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è\",\n",
    "            \"bg\": \"–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—å—é—è\", \n",
    "            \"sl\": \"ƒç≈°≈æ\"\n",
    "        }\n",
    "        \n",
    "        special_chars = special_chars_map.get(current_lang, '')\n",
    "        has_special_chars = any(char in text.lower() for char in special_chars)\n",
    "        reasonable_length = 3 <= len(text) <= 50\n",
    "        not_too_long = len(text.split()) <= 8\n",
    "        \n",
    "        return has_special_chars or (reasonable_length and not_too_long)\n",
    "    \n",
    "    def _extract_detection_criteria(self, content: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        criteria = []\n",
    "        lines = content.split('\\n')\n",
    "        in_criteria = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'detection criteria' in line.lower():\n",
    "                in_criteria = True\n",
    "                continue\n",
    "            elif in_criteria and line.startswith('#') and 'detection' not in line.lower():\n",
    "                break\n",
    "            elif in_criteria and line.strip().startswith(('1.', '2.', '3.', '4.', '5.')):\n",
    "                criteria.append(line.strip())\n",
    "        \n",
    "        return criteria[:5]\n",
    "    \n",
    "    def _extract_patterns(self, content: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        patterns = []\n",
    "        # TODO: translate to English\n",
    "        pattern_indicators = ['pattern', 'example', 'format', 'structure']\n",
    "        \n",
    "        for line in content.split('\\n'):\n",
    "            if any(indicator in line.lower() for indicator in pattern_indicators):\n",
    "                # TODO: translate to English\n",
    "                pattern_matches = re.findall(r'\"([^\"]{5,100})\"', line)\n",
    "                patterns.extend(pattern_matches)\n",
    "        \n",
    "        return patterns[:8]\n",
    "    \n",
    "    def _extract_examples(self, content: str) -> List[str]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        examples = []\n",
    "        lines = content.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'example' in line.lower() and '\"' in line:\n",
    "                example_matches = re.findall(r'\"([^\"]{10,200})\"', line)\n",
    "                examples.extend(example_matches)\n",
    "        \n",
    "        return examples[:3]\n",
    "    \n",
    "    def _extract_cultural_context(self, content: str) -> str:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        context_keywords = ['polish', 'cultural', 'context', 'language-specific']\n",
    "        \n",
    "        for line in content.split('\\n'):\n",
    "            if any(keyword in line.lower() for keyword in context_keywords):\n",
    "                return line.strip()[:200]\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def get_loading_report(self) -> Dict:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        return {\n",
    "            'stats': self.load_stats,\n",
    "            'definitions_loaded': list(self.technique_definitions.keys()),\n",
    "            'total_definitions': len(self.technique_definitions)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ TODO: translate to English...\n",
      "üìö TODO: translate to English...\n",
      "   TODO: translate to English 19 TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "   TODO: translate to English: 19\n",
      "   TODO: translate to English: 19\n",
      "   TODO: translate to English: 260\n",
      "   TODO: translate to English: 33\n",
      "   TODO: translate to English: 0\n",
      "\n",
      "üìö TODO: translate to English:\n",
      "   TODO: translate to English: 19 TODO: translate to English\n",
      "   TODO: translate to English: 260\n",
      "   TODO: translate to English: 33\n",
      "\n",
      "üîç TODO: translate to English:\n",
      "   1. Appeal_to_Fear_Prejudice:\n",
      "      TODO: translate to English(15): epidemic, worse than, crisis...\n",
      "      TODO: translate to English: 5 TODO: translate to English\n",
      "   2. Name_Calling_Labeling:\n",
      "      TODO: translate to English(15): hate group,, and the term, anti-semitic...\n",
      "      TODO: translate to English: 5 TODO: translate to English\n",
      "   3. Conversation_Killer:\n",
      "      TODO: translate to English(15): anyone with common sense knows., ridiculous, art of the deal...\n",
      "      TODO: translate to English: 5 TODO: translate to English\n",
      "   4. Flag_Waving:\n",
      "      TODO: translate to English(15): fight against terror, incompetent authorities, this is america...\n",
      "      TODO: translate to English: 5 TODO: translate to English\n",
      "   5. Repetition:\n",
      "      TODO: translate to English(8): crisis, anti-zionism, plague,...\n",
      "      TODO: translate to English: 5 TODO: translate to English\n",
      "\n",
      "‚úÖ TODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üîÑ TODO: translate to English\n",
    "print(\"üîÑ TODO: translate to English...\")\n",
    "\n",
    "# TODO: translate to English\n",
    "definition_loader = TechniqueDefinitionLoader(TECHNIQUE_PROMPTS_DIR, debug_mode=False)\n",
    "\n",
    "# TODO: translate to English\n",
    "technique_definitions = definition_loader.load_all_definitions()\n",
    "\n",
    "# TODO: translate to English\n",
    "loading_report = definition_loader.get_loading_report()\n",
    "\n",
    "print(f\"\\nüìö TODO: translate to English:\")\n",
    "print(f\"   TODO: translate to English: {loading_report['total_definitions']} TODO: translate to English\")\n",
    "print(f\"   TODO: translate to English: {loading_report['stats']['total_keywords']}\")\n",
    "print(f\"   TODO: translate to English: {loading_report['stats']['total_patterns']}\")\n",
    "\n",
    "if loading_report['stats']['load_errors']:\n",
    "    print(f\"\\n‚ö†Ô∏è TODO: translate to English:\")\n",
    "    for error in loading_report['stats']['load_errors']:\n",
    "        print(f\"   ‚Ä¢ {error}\")\n",
    "\n",
    "# TODO: translate to English5TODO: translate to English\n",
    "if technique_definitions:\n",
    "    print(f\"\\nüîç TODO: translate to English:\")\n",
    "    for i, (name, definition) in enumerate(list(technique_definitions.items())[:5]):\n",
    "        print(f\"   {i+1}. {name}:\")\n",
    "        print(f\"      TODO: translate to English({len(definition.keywords)}): {', '.join(definition.keywords[:3])}{'...' if len(definition.keywords) > 3 else ''}\")\n",
    "        print(f\"      TODO: translate to English: {len(definition.detection_criteria)} TODO: translate to English\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå TODO: translate to English\")\n",
    "\n",
    "print(f\"\\n‚úÖ TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: TODO: translate to English üìñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üìñ TODO: translate to English\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    \n",
    "    def __init__(self, paragraph_file: str, articles_dir: str, debug_mode: bool = True):\n",
    "        self.paragraph_file = paragraph_file\n",
    "        self.articles_dir = articles_dir\n",
    "        self.debug_mode = debug_mode\n",
    "        self.load_stats = {\n",
    "            'articles_found': 0,\n",
    "            'articles_loaded': 0,\n",
    "            'total_detections': 0,\n",
    "            'total_characters': 0,\n",
    "            'load_errors': [],\n",
    "            'missing_articles': []\n",
    "        }\n",
    "    \n",
    "    def load_all_data(self) -> List[ArticleData]:\n",
    "        \"\"\"TODO: translate to EnglishArticleTODO: translate to English\"\"\"\n",
    "        print(f\"üìñ TODO: translate to English...\")\n",
    "        \n",
    "        # TODO: translate to English1TODO: translate to English: TODO: translate to English\n",
    "        paragraph_results_by_article = self._load_paragraph_results()\n",
    "        if not paragraph_results_by_article:\n",
    "            return []\n",
    "        \n",
    "        # TODO: translate to English2TODO: translate to English: TODO: translate to EnglishArticleTODO: translate to English\n",
    "        all_articles = self._load_article_texts(paragraph_results_by_article)\n",
    "        \n",
    "        # TODO: translate to English3TODO: translate to English: TODO: translate to English\n",
    "        self._validate_and_stats(all_articles)\n",
    "        \n",
    "        return all_articles\n",
    "    \n",
    "    def _load_paragraph_results(self) -> Dict[str, List[ParagraphResult]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if not os.path.exists(self.paragraph_file):\n",
    "            print(f\"‚ùå TODO: translate to English: {self.paragraph_file}\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"   üìÑ TODO: translate to English: {os.path.basename(self.paragraph_file)}\")\n",
    "        \n",
    "        results_by_article = defaultdict(list)\n",
    "        line_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        with open(self.paragraph_file, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                    \n",
    "                line_count += 1\n",
    "                parts = line.split('\\t')\n",
    "                \n",
    "                if len(parts) >= 4:\n",
    "                    try:\n",
    "                        article_id = parts[0]\n",
    "                        technique = parts[1]\n",
    "                        start = int(parts[2])\n",
    "                        end = int(parts[3])\n",
    "                        \n",
    "                        result = ParagraphResult(\n",
    "                            article_id=article_id,\n",
    "                            technique=technique,\n",
    "                            start=start,\n",
    "                            end=end\n",
    "                        )\n",
    "                        \n",
    "                        results_by_article[article_id].append(result)\n",
    "                        \n",
    "                    except (ValueError, AssertionError) as e:\n",
    "                        error_count += 1\n",
    "                        error_msg = f\"TODO: translate to English{line_num}TODO: translate to English: {str(e)}\"\n",
    "                        self.load_stats['load_errors'].append(error_msg)\n",
    "                        if self.debug_mode and error_count <= 5:\n",
    "                            print(f\"   ‚ö†Ô∏è {error_msg}\")\n",
    "                else:\n",
    "                    error_count += 1\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"   ‚ö†Ô∏è TODO: translate to English{line_num}TODO: translate to English: {line}\")\n",
    "        \n",
    "        self.load_stats['articles_found'] = len(results_by_article)\n",
    "        self.load_stats['total_detections'] = sum(len(results) for results in results_by_article.values())\n",
    "        \n",
    "        print(f\"   ‚úÖ TODO: translate to English: {line_count}TODO: translate to English, {len(results_by_article)}TODO: translate to EnglishArticle, {self.load_stats['total_detections']}TODO: translate to English\")\n",
    "        if error_count > 0:\n",
    "            print(f\"   ‚ö†Ô∏è TODO: translate to English: {error_count}TODO: translate to English\")\n",
    "        \n",
    "        return dict(results_by_article)\n",
    "    \n",
    "    def _load_article_texts(self, paragraph_results_by_article: Dict[str, List[ParagraphResult]]) -> List[ArticleData]:\n",
    "        \"\"\"TODO: translate to EnglishArticleTODO: translate to English\"\"\"\n",
    "        print(f\"\\n   üìö TODO: translate to EnglishArticleTODO: translate to English...\")\n",
    "        \n",
    "        all_articles = []\n",
    "        \n",
    "        for article_id, paragraph_results in paragraph_results_by_article.items():\n",
    "            # TODO: translate to EnglishArticleTODO: translate to English\n",
    "            article_id_str = str(article_id)\n",
    "\n",
    "            if article_id_str.startswith('article'):\n",
    "                article_filename = f\"{article_id_str}.txt\"  # TODO: translate to EnglishÔºåTODO: translate to English\n",
    "            else:\n",
    "                article_filename = f\"article{article_id_str}.txt\"  # TODO: translate to EnglishÔºåTODO: translate to English\n",
    "                \n",
    "            article_path = os.path.join(self.articles_dir, article_filename)\n",
    "            \n",
    "            if not os.path.exists(article_path):\n",
    "                self.load_stats['missing_articles'].append(article_id)\n",
    "                if self.debug_mode:\n",
    "                    print(f\"   ‚ùå Article{article_id}: TODO: translate to English\")\n",
    "                continue\n",
    "            \n",
    "            # TODO: translate to EnglishArticleTODO: translate to English\n",
    "            try:\n",
    "                with open(article_path, 'r', encoding='utf-8') as f:\n",
    "                    article_text = f.read()\n",
    "                \n",
    "                # TODO: translate to English\n",
    "                for result in paragraph_results:\n",
    "                    if result.end <= len(article_text):\n",
    "                        result.text_segment = article_text[result.start:result.end]\n",
    "                    else:\n",
    "                        result.text_segment = article_text[result.start:]\n",
    "                        if self.debug_mode:\n",
    "                            print(f\"   ‚ö†Ô∏è Article{article_id}: TODO: translate to English {result.start}-{result.end} > {len(article_text)}\")\n",
    "                \n",
    "                # TODO: translate to EnglishArticleTODO: translate to English\n",
    "                article_data = ArticleData(\n",
    "                    article_id=article_id,\n",
    "                    article_path=article_path,\n",
    "                    article_text=article_text,\n",
    "                    paragraph_results=paragraph_results\n",
    "                )\n",
    "                \n",
    "                all_articles.append(article_data)\n",
    "                self.load_stats['articles_loaded'] += 1\n",
    "                self.load_stats['total_characters'] += len(article_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Article{article_id}TODO: translate to English: {str(e)}\"\n",
    "                self.load_stats['load_errors'].append(error_msg)\n",
    "                if self.debug_mode:\n",
    "                    print(f\"   ‚ùå {error_msg}\")\n",
    "        \n",
    "        return all_articles\n",
    "    \n",
    "    def _validate_and_stats(self, all_articles: List[ArticleData]) -> None:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        print(f\"\\nüìä TODO: translate to English:\")\n",
    "        print(f\"   TODO: translate to EnglishArticle: {self.load_stats['articles_found']}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['articles_loaded']}\")\n",
    "        print(f\"   TODO: translate to EnglishArticle: {len(self.load_stats['missing_articles'])}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['total_detections']:,}\")\n",
    "        print(f\"   TODO: translate to English: {self.load_stats['total_characters']:,}\")\n",
    "        \n",
    "        if all_articles:\n",
    "            avg_article_length = self.load_stats['total_characters'] / len(all_articles)\n",
    "            avg_detections = self.load_stats['total_detections'] / len(all_articles)\n",
    "            print(f\"   TODO: translate to EnglishArticleTODO: translate to English: {avg_article_length:,.0f} TODO: translate to English\")\n",
    "            print(f\"   TODO: translate to English: {avg_detections:.1f} TODO: translate to English\")\n",
    "        \n",
    "        if self.load_stats['missing_articles']:\n",
    "            print(f\"\\n‚ö†Ô∏è TODO: translate to EnglishArticleID: {', '.join(self.load_stats['missing_articles'][:10])}{'...' if len(self.load_stats['missing_articles']) > 10 else ''}\")\n",
    "        \n",
    "        if self.load_stats['load_errors']:\n",
    "            print(f\"\\n‚ùå TODO: translate to English: {len(self.load_stats['load_errors'])}TODO: translate to English\")\n",
    "            if self.debug_mode:\n",
    "                for error in self.load_stats['load_errors'][:3]:\n",
    "                    print(f\"   ‚Ä¢ {error}\")\n",
    "    \n",
    "    def get_technique_distribution(self, all_articles: List[ArticleData]) -> Dict[str, int]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        technique_counts = {}\n",
    "        for article in all_articles:\n",
    "            for result in article.paragraph_results:\n",
    "                technique_counts[result.technique] = technique_counts.get(result.technique, 0) + 1\n",
    "        return technique_counts\n",
    "\n",
    "print(\"‚úÖ TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ TODO: translate to EnglishArticleTODO: translate to English...\n",
      "üìñ TODO: translate to English...\n",
      "   üìÑ TODO: translate to English: results_en_results_semeval_task3_dev_en_voting_aggressive_all.tsv\n",
      "   ‚úÖ TODO: translate to English: 1851TODO: translate to English, 81TODO: translate to EnglishArticle, 1851TODO: translate to English\n",
      "\n",
      "   üìö TODO: translate to EnglishArticleTODO: translate to English...\n",
      "   üìÑ Article813452859: 2,887TODO: translate to English, 8TODO: translate to English\n",
      "   üìÑ Article813494037: 3,082TODO: translate to English, 25TODO: translate to English\n",
      "   üìÑ Article813547724: 1,811TODO: translate to English, 3TODO: translate to English\n",
      "   üìÑ Article813552066: 7,863TODO: translate to English, 55TODO: translate to English\n",
      "   üìÑ Article813601978: 6,306TODO: translate to English, 9TODO: translate to English\n",
      "   üìÑ Article813602345: 2,824TODO: translate to English, 9TODO: translate to English\n",
      "   üìÑ Article813603860: 5,519TODO: translate to English, 38TODO: translate to English\n",
      "   üìÑ Article813623212: 7,619TODO: translate to English, 15TODO: translate to English\n",
      "   üìÑ Article813714967: 6,362TODO: translate to English, 11TODO: translate to English\n",
      "   üìÑ Article813949697: 11,453TODO: translate to English, 31TODO: translate to English\n",
      "   üìÑ Article813953273: 5,860TODO: translate to English, 72TODO: translate to English\n",
      "   üìÑ Article813953435: 3,765TODO: translate to English, 4TODO: translate to English\n",
      "   üìÑ Article813992175: 3,044TODO: translate to English, 21TODO: translate to English\n",
      "   üìÑ Article814251296: 3,079TODO: translate to English, 1TODO: translate to English\n",
      "   üìÑ Article814371058: 399TODO: translate to English, 6TODO: translate to English\n",
      "   üìÑ Article814403543: 3,633TODO: translate to English, 26TODO: translate to English\n",
      "   üìÑ Article814403783: 3,272TODO: translate to English, 14TODO: translate to English\n",
      "   üìÑ Article814403875: 2,177TODO: translate to English, 1TODO: translate to English\n",
      "   üìÑ Article814404002: 4,707TODO: translate to English, 72TODO: translate to English\n",
      "   üìÑ Article814427361: 6,478TODO: translate to English, 26TODO: translate to English\n",
      "   üìÑ Article814435435: 2,721TODO: translate to English, 20TODO: translate to English\n",
      "   üìÑ Article814630609: 3,763TODO: translate to English, 24TODO: translate to English\n",
      "   üìÑ Article814777937: 5,900TODO: translate to English, 43TODO: translate to English\n",
      "   üìÑ Article815412286: 3,231TODO: translate to English, 17TODO: translate to English\n",
      "   üìÑ Article815858385: 2,988TODO: translate to English, 22TODO: translate to English\n",
      "   üìÑ Article816460196: 6,148TODO: translate to English, 51TODO: translate to English\n",
      "   üìÑ Article816720060: 6,780TODO: translate to English, 41TODO: translate to English\n",
      "   üìÑ Article817147979: 8,038TODO: translate to English, 61TODO: translate to English\n",
      "   üìÑ Article817176202: 4,581TODO: translate to English, 28TODO: translate to English\n",
      "   üìÑ Article817190270: 7,424TODO: translate to English, 38TODO: translate to English\n",
      "   üìÑ Article817408115: 7,424TODO: translate to English, 61TODO: translate to English\n",
      "   üìÑ Article817449755: 4,870TODO: translate to English, 21TODO: translate to English\n",
      "   üìÑ Article818141325: 2,821TODO: translate to English, 1TODO: translate to English\n",
      "   üìÑ Article820419869: 4,823TODO: translate to English, 4TODO: translate to English\n",
      "   üìÑ Article820791520: 12,471TODO: translate to English, 77TODO: translate to English\n",
      "   üìÑ Article821040551: 1,043TODO: translate to English, 2TODO: translate to English\n",
      "   üìÑ Article821744708: 2,700TODO: translate to English, 13TODO: translate to English\n",
      "   üìÑ Article822220578: 5,033TODO: translate to English, 3TODO: translate to English\n",
      "   üìÑ Article822942601: 5,728TODO: translate to English, 50TODO: translate to English\n",
      "   üìÑ Article824256050: 7,666TODO: translate to English, 14TODO: translate to English\n",
      "   üìÑ Article824350729: 2,905TODO: translate to English, 14TODO: translate to English\n",
      "   üìÑ Article824658990: 5,505TODO: translate to English, 21TODO: translate to English\n",
      "   üìÑ Article824684605: 3,853TODO: translate to English, 15TODO: translate to English\n",
      "   üìÑ Article829267754: 7,972TODO: translate to English, 16TODO: translate to English\n",
      "   üìÑ Article829815104: 6,368TODO: translate to English, 12TODO: translate to English\n",
      "   üìÑ Article830274102: 7,722TODO: translate to English, 22TODO: translate to English\n",
      "   üìÑ Article830359136: 3,250TODO: translate to English, 56TODO: translate to English\n",
      "   üìÑ Article830359423: 5,220TODO: translate to English, 45TODO: translate to English\n",
      "   üìÑ Article830821478: 4,864TODO: translate to English, 22TODO: translate to English\n",
      "   üìÑ Article832918490: 1,314TODO: translate to English, 1TODO: translate to English\n",
      "   üìÑ Article832920387: 5,171TODO: translate to English, 2TODO: translate to English\n",
      "   üìÑ Article832926076: 4,960TODO: translate to English, 5TODO: translate to English\n",
      "   üìÑ Article832931332: 5,647TODO: translate to English, 39TODO: translate to English\n",
      "   üìÑ Article832940138: 6,981TODO: translate to English, 9TODO: translate to English\n",
      "   üìÑ Article832941978: 9,712TODO: translate to English, 29TODO: translate to English\n",
      "   üìÑ Article832947554: 1,535TODO: translate to English, 9TODO: translate to English\n",
      "   üìÑ Article832947600: 1,799TODO: translate to English, 5TODO: translate to English\n",
      "   üìÑ Article832947852: 4,371TODO: translate to English, 20TODO: translate to English\n",
      "   üìÑ Article832948083: 9,162TODO: translate to English, 21TODO: translate to English\n",
      "   üìÑ Article832956618: 5,330TODO: translate to English, 4TODO: translate to English\n",
      "   üìÑ Article832959523: 4,871TODO: translate to English, 9TODO: translate to English\n",
      "   üìÑ Article832971448: 10,151TODO: translate to English, 7TODO: translate to English\n",
      "   üìÑ Article832984694: 2,954TODO: translate to English, 20TODO: translate to English\n",
      "   üìÑ Article833013834: 5,108TODO: translate to English, 37TODO: translate to English\n",
      "   üìÑ Article833018464: 4,242TODO: translate to English, 30TODO: translate to English\n",
      "   üìÑ Article833021113: 2,415TODO: translate to English, 2TODO: translate to English\n",
      "   üìÑ Article833024133: 1,831TODO: translate to English, 3TODO: translate to English\n",
      "   üìÑ Article833024696: 4,043TODO: translate to English, 24TODO: translate to English\n",
      "   üìÑ Article833028146: 1,290TODO: translate to English, 20TODO: translate to English\n",
      "   üìÑ Article833028932: 5,096TODO: translate to English, 6TODO: translate to English\n",
      "   üìÑ Article833032366: 2,263TODO: translate to English, 4TODO: translate to English\n",
      "   üìÑ Article833032367: 3,998TODO: translate to English, 16TODO: translate to English\n",
      "   üìÑ Article833036176: 3,008TODO: translate to English, 28TODO: translate to English\n",
      "   üìÑ Article833036489: 2,749TODO: translate to English, 12TODO: translate to English\n",
      "   üìÑ Article833039623: 7,099TODO: translate to English, 135TODO: translate to English\n",
      "   üìÑ Article833040400: 1,976TODO: translate to English, 3TODO: translate to English\n",
      "   üìÑ Article833041409: 2,523TODO: translate to English, 11TODO: translate to English\n",
      "   üìÑ Article833050243: 4,241TODO: translate to English, 17TODO: translate to English\n",
      "   üìÑ Article833052347: 6,305TODO: translate to English, 32TODO: translate to English\n",
      "   üìÑ Article833053628: 10,256TODO: translate to English, 27TODO: translate to English\n",
      "   üìÑ Article833067493: 2,460TODO: translate to English, 3TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "   TODO: translate to EnglishArticle: 81\n",
      "   TODO: translate to English: 81\n",
      "   TODO: translate to EnglishArticle: 0\n",
      "   TODO: translate to English: 1,851\n",
      "   TODO: translate to English: 390,813\n",
      "   TODO: translate to EnglishArticleTODO: translate to English: 4,825 TODO: translate to English\n",
      "   TODO: translate to English: 22.9 TODO: translate to English\n",
      "\n",
      "‚úÖ TODO: translate to English: 81 TODO: translate to EnglishArticle\n",
      "\n",
      "üè∑Ô∏è TODO: translate to English (Top 10):\n",
      "   1. Loaded_Language: 369TODO: translate to English ‚úÖ TODO: translate to English\n",
      "   2. Exaggeration-Minimisation: 169TODO: translate to English ‚ùå TODO: translate to English\n",
      "   3. Name_Calling-Labeling: 168TODO: translate to English ‚ùå TODO: translate to English\n",
      "   4. Conversation_Killer: 159TODO: translate to English ‚úÖ TODO: translate to English\n",
      "   5. Appeal_to_Fear-Prejudice: 136TODO: translate to English ‚ùå TODO: translate to English\n",
      "   6. Doubt: 117TODO: translate to English ‚úÖ TODO: translate to English\n",
      "   7. Obfuscation-Vagueness-Confusion: 112TODO: translate to English ‚ùå TODO: translate to English\n",
      "   8. Causal_Oversimplification: 107TODO: translate to English ‚úÖ TODO: translate to English\n",
      "   9. Repetition: 89TODO: translate to English ‚úÖ TODO: translate to English\n",
      "   10. Straw_Man: 74TODO: translate to English ‚úÖ TODO: translate to English\n",
      "\n",
      "üìà TODO: translate to English:\n",
      "   TODO: translate to English: 14 TODO: translate to English\n",
      "   TODO: translate to English: 5 TODO: translate to English\n",
      "   Coverage of detections: 65.7% (1217/1851)\n",
      "\n",
      "‚ö†Ô∏è TODO: translate to English:\n",
      "   ‚Ä¢ Appeal_to_Fear-Prejudice (136TODO: translate to English)\n",
      "   ‚Ä¢ Exaggeration-Minimisation (169TODO: translate to English)\n",
      "   ‚Ä¢ False_Dilemma-No_Choice (49TODO: translate to English)\n",
      "   ‚Ä¢ Name_Calling-Labeling (168TODO: translate to English)\n",
      "   ‚Ä¢ Obfuscation-Vagueness-Confusion (112TODO: translate to English)\n"
     ]
    }
   ],
   "source": [
    "# üîÑ TODO: translate to English\n",
    "print(\"üîÑ TODO: translate to EnglishArticleTODO: translate to English...\")\n",
    "\n",
    "# TODO: translate to English\n",
    "data_loader = DataLoader(PARAGRAPH_RESULTS_FILE, ARTICLES_DIR, debug_mode=False)\n",
    "\n",
    "# TODO: translate to English\n",
    "all_articles = data_loader.load_all_data()\n",
    "\n",
    "if not all_articles:\n",
    "    print(\"‚ùå TODO: translate to EnglishArticleTODO: translate to EnglishÔºåTODO: translate to EnglishConfig\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ TODO: translate to English: {len(all_articles)} TODO: translate to EnglishArticle\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    technique_distribution = data_loader.get_technique_distribution(all_articles)\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è TODO: translate to English (Top 10):\")\n",
    "    sorted_techniques = sorted(technique_distribution.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i, (technique, count) in enumerate(sorted_techniques[:10]):\n",
    "        # TODO: translate to English\n",
    "        has_def = \"‚úÖ\" if technique in technique_definitions else \"‚ùå\"\n",
    "        coverage = \"TODO: translate to English\" if technique in technique_definitions else \"TODO: translate to English\"\n",
    "        print(f\"   {i+1}. {technique}: {count}TODO: translate to English {has_def} {coverage}\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    techniques_with_def = set(technique_distribution.keys()) & set(technique_definitions.keys())\n",
    "    techniques_without_def = set(technique_distribution.keys()) - set(technique_definitions.keys())\n",
    "    \n",
    "    covered_detections = sum(technique_distribution[tech] for tech in techniques_with_def)\n",
    "    total_detections = sum(technique_distribution.values())\n",
    "    coverage_rate = covered_detections / total_detections * 100 if total_detections > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìà TODO: translate to English:\")\n",
    "    print(f\"   TODO: translate to English: {len(techniques_with_def)} TODO: translate to English\")\n",
    "    print(f\"   TODO: translate to English: {len(techniques_without_def)} TODO: translate to English\")\n",
    "    print(f\"   Coverage of detections: {coverage_rate:.1f}% ({covered_detections}/{total_detections})\")\n",
    "    \n",
    "    if techniques_without_def:\n",
    "        print(f\"\\n‚ö†Ô∏è TODO: translate to English:\")\n",
    "        for tech in sorted(techniques_without_def):\n",
    "            count = technique_distribution[tech]\n",
    "            print(f\"   ‚Ä¢ {tech} ({count}TODO: translate to English)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: TODO: translate to English üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ TODO: translate to English...\n",
      "   TODO: translate to English: 14 TODO: translate to English\n",
      "   ‚úÖ TODO: translate to English: False_Dilemma-No_Choice ‚Üí False_Dilemma_No_Choice\n",
      "   ‚úÖ TODO: translate to English: Name_Calling-Labeling ‚Üí Name_Calling_Labeling\n",
      "   ‚úÖ TODO: translate to English: Exaggeration-Minimisation ‚Üí Exaggeration_Minimisation\n",
      "   ‚úÖ TODO: translate to English: Appeal_to_Fear-Prejudice ‚Üí Appeal_to_Fear_Prejudice\n",
      "   ‚úÖ TODO: translate to English: Obfuscation-Vagueness-Confusion ‚Üí Obfuscation_Vagueness_Confusion\n",
      "   TODO: translate to English: 5 TODO: translate to English\n",
      "   TODO: translate to English: 0 TODO: translate to English\n",
      "\n",
      "üìä TODO: translate to English:\n",
      "   TODO: translate to English: 19\n",
      "   TODO: translate to English: 19\n",
      "   TODO: translate to English: 100.0%\n",
      "\n",
      "‚úÖ TODO: translate to English\n",
      "   availableTODO: translate to English: 19 TODO: translate to English\n",
      "   Coverage of detections: 100.0% (1851/1851)\n",
      "   üìà TODO: translate to English: +34.3%\n"
     ]
    }
   ],
   "source": [
    "# üîß TODO: translate to English\n",
    "# TODO: translate to English\n",
    "\n",
    "def create_smart_technique_mapping(technique_definitions: Dict[str, TechniqueDefinition], \n",
    "                                  data_techniques: List[str]) -> Dict[str, TechniqueDefinition]:\n",
    "    \"\"\"TODO: translate to English\"\"\"\n",
    "    print(\"üîÑ TODO: translate to English...\")\n",
    "    \n",
    "    mapping_stats = {\n",
    "        'direct_matches': 0,\n",
    "        'smart_matches': 0,\n",
    "        'unmatched': 0,\n",
    "        'mapping_details': []\n",
    "    }\n",
    "    \n",
    "    technique_mapping = {}\n",
    "    \n",
    "    # TODO: translate to English1TODO: translate to English: TODO: translate to English\n",
    "    for data_technique in data_techniques:\n",
    "        if data_technique in technique_definitions:\n",
    "            technique_mapping[data_technique] = technique_definitions[data_technique]\n",
    "            mapping_stats['direct_matches'] += 1\n",
    "            mapping_stats['mapping_details'].append(f\"TODO: translate to English: {data_technique}\")\n",
    "    \n",
    "    print(f\"   TODO: translate to English: {mapping_stats['direct_matches']} TODO: translate to English\")\n",
    "    \n",
    "    # TODO: translate to English2TODO: translate to English: TODO: translate to English (ProcessingTODO: translate to English)\n",
    "    unmatched = set(data_techniques) - set(technique_mapping.keys())\n",
    "    \n",
    "    for data_technique in unmatched:\n",
    "        # TODO: translate to English\n",
    "        variations = [\n",
    "            data_technique.replace('-', '_'),    # Appeal_to_Fear-Prejudice ‚Üí Appeal_to_Fear_Prejudice\n",
    "            data_technique.replace('_', '-'),    # TODO: translate to English\n",
    "            data_technique.replace('-', ''),     # TODO: translate to English\n",
    "            data_technique.replace('_', ''),     # TODO: translate to English\n",
    "        ]\n",
    "        \n",
    "        matched = False\n",
    "        for variation in variations:\n",
    "            if variation in technique_definitions:\n",
    "                technique_mapping[data_technique] = technique_definitions[variation]\n",
    "                mapping_stats['smart_matches'] += 1\n",
    "                mapping_stats['mapping_details'].append(f\"TODO: translate to English: {data_technique} ‚Üí {variation}\")\n",
    "                print(f\"   ‚úÖ TODO: translate to English: {data_technique} ‚Üí {variation}\")\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            mapping_stats['unmatched'] += 1\n",
    "    \n",
    "    print(f\"   TODO: translate to English: {mapping_stats['smart_matches']} TODO: translate to English\")\n",
    "    print(f\"   TODO: translate to English: {mapping_stats['unmatched']} TODO: translate to English\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    still_unmatched = set(data_techniques) - set(technique_mapping.keys())\n",
    "    if still_unmatched:\n",
    "        print(f\"\\n‚ö†Ô∏è TODO: translate to English:\")\n",
    "        for tech in sorted(still_unmatched):\n",
    "            count = technique_distribution.get(tech, 0)\n",
    "            print(f\"   ‚Ä¢ {tech} ({count}TODO: translate to English)\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    total_techniques = len(data_techniques)\n",
    "    matched_techniques = len(technique_mapping)\n",
    "    final_coverage = matched_techniques / total_techniques * 100 if total_techniques > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä TODO: translate to English:\")\n",
    "    print(f\"   TODO: translate to English: {total_techniques}\")\n",
    "    print(f\"   TODO: translate to English: {matched_techniques}\")\n",
    "    print(f\"   TODO: translate to English: {final_coverage:.1f}%\")\n",
    "    \n",
    "    return technique_mapping, mapping_stats\n",
    "\n",
    "# TODO: translate to English\n",
    "if all_articles and technique_definitions:\n",
    "    # TODO: translate to English\n",
    "    data_technique_names = list(technique_distribution.keys())\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    smart_mapping, mapping_stats = create_smart_technique_mapping(\n",
    "        technique_definitions, data_technique_names\n",
    "    )\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    technique_definitions = smart_mapping\n",
    "    \n",
    "    print(f\"\\n‚úÖ TODO: translate to English\")\n",
    "    print(f\"   availableTODO: translate to English: {len(technique_definitions)} TODO: translate to English\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    covered_detections_new = sum(technique_distribution[tech] for tech in technique_definitions.keys())\n",
    "    total_detections = sum(technique_distribution.values())\n",
    "    new_coverage_rate = covered_detections_new / total_detections * 100\n",
    "    \n",
    "    print(f\"   Coverage of detections: {new_coverage_rate:.1f}% ({covered_detections_new}/{total_detections})\")\n",
    "    \n",
    "    improvement = new_coverage_rate - coverage_rate\n",
    "    if improvement > 0:\n",
    "        print(f\"   üìà TODO: translate to English: +{improvement:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TODO: translate to EnglishÔºöTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: Rule-based methodcharacter-level span localizationTODO: translate to English üìê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Rule-based methodcharacter-level span localizationTODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üìê TODO: translate to EnglishRule-basedTODO: translate to Englishcharacter-level span localizationTODO: translate to English\n",
    "\n",
    "class RuleBasedCharacterLocator:\n",
    "    \"\"\"TODO: translate to EnglishRule-basedTODO: translate to Englishcharacter-level span localizationTODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\"\"\"\n",
    "    \n",
    "    def __init__(self, technique_definitions: Dict[str, TechniqueDefinition], debug_mode: bool = True):\n",
    "        self.technique_definitions = technique_definitions\n",
    "        self.debug_mode = debug_mode\n",
    "        self.processing_stats = defaultdict(lambda: {\n",
    "            'total': 0, 'found': 0, 'positions': 0, 'time': 0, 'errors': 0\n",
    "        })\n",
    "    \n",
    "    def process_articles(self, articles: List[ArticleData]) -> List[CharacterResult]:\n",
    "        \"\"\"ProcessingArticleTODO: translate to English\"\"\"\n",
    "        print(f\"üìê Rule-based methodTODO: translate to EnglishProcessing...\")\n",
    "        print(f\"   ProcessingArticle: {len(articles)} TODO: translate to English\")\n",
    "        \n",
    "        all_results = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, article in enumerate(articles):\n",
    "            if self.debug_mode:\n",
    "                print(f\"\\nüìÑ Processing {i+1}/{len(articles)}: Article{article.article_id}\")\n",
    "                print(f\"   ArticleTODO: translate to English: {len(article.article_text):,} TODO: translate to English\")\n",
    "                print(f\"   TODO: translate to English: {len(article.paragraph_results)} TODO: translate to English\")\n",
    "            \n",
    "            article_results = self._process_single_article(article)\n",
    "            all_results.extend(article_results)\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print(f\"   ‚úÖ TODO: translate to English: {len(article_results)} TODO: translate to English\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüìä Rule-based methodProcessingTODO: translate to English:\")\n",
    "        print(f\"   ProcessingTODO: translate to English: {total_time:.2f} TODO: translate to English\")\n",
    "        print(f\"   TODO: translate to English: {len(all_results)} TODO: translate to English\")\n",
    "        print(f\"   Avg speed: {len(all_results)/total_time:.1f} results/sec\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _process_single_article(self, article: ArticleData) -> List[CharacterResult]:\n",
    "        \"\"\"ProcessingTODO: translate to EnglishArticle\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, paragraph_result in enumerate(article.paragraph_results):\n",
    "            technique = paragraph_result.technique\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print(f\"      {i+1:3d}/{len(article.paragraph_results)}: {technique:<25}\", end=\"\")\n",
    "            \n",
    "            self.processing_stats[technique]['total'] += 1\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                positions = self._locate_technique_positions(paragraph_result)\n",
    "                process_time = time.time() - start_time\n",
    "                \n",
    "                self.processing_stats[technique]['time'] += process_time\n",
    "                \n",
    "                if positions:\n",
    "                    self.processing_stats[technique]['found'] += 1\n",
    "                    self.processing_stats[technique]['positions'] += len(positions)\n",
    "                \n",
    "                # TODO: translate to English\n",
    "                for rel_start, rel_end in positions:\n",
    "                    abs_start = paragraph_result.start + rel_start\n",
    "                    abs_end = paragraph_result.start + rel_end\n",
    "                    \n",
    "                    results.append(CharacterResult(\n",
    "                        article_id=article.article_id,\n",
    "                        technique=technique,\n",
    "                        start=abs_start,\n",
    "                        end=abs_end,\n",
    "                        confidence=0.8,  # Rule-based methodTODO: translate to Englishconfidence\n",
    "                        source=\"rule\"\n",
    "                    ))\n",
    "                \n",
    "                if self.debug_mode:\n",
    "                    print(f\" ‚Üí {len(positions):2d}TODO: translate to English\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.processing_stats[technique]['errors'] += 1\n",
    "                if self.debug_mode:\n",
    "                    print(f\" ‚Üí ‚ùå TODO: translate to English: {str(e)[:30]}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _locate_technique_positions(self, paragraph_result: ParagraphResult) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        text = paragraph_result.text_segment\n",
    "        technique = paragraph_result.technique\n",
    "        positions = []\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        tech_def = self.technique_definitions.get(technique)\n",
    "        \n",
    "        if tech_def:\n",
    "            # TODO: translate to English1: TODO: translate to English\n",
    "            keyword_positions = self._find_by_keywords(text, tech_def.keywords)\n",
    "            positions.extend(keyword_positions)\n",
    "            \n",
    "            # TODO: translate to English2: TODO: translate to English\n",
    "            pattern_positions = self._find_by_patterns(text, tech_def.patterns)\n",
    "            positions.extend(pattern_positions)\n",
    "            \n",
    "            # TODO: translate to English3: TODO: translate to EnglishRule-based\n",
    "            specific_positions = self._find_by_technique_rules(text, technique)\n",
    "            positions.extend(specific_positions)\n",
    "        else:\n",
    "            # TODO: translate to English\n",
    "            positions = self._fallback_detection(text, technique)\n",
    "        \n",
    "        # TODO: translate to English4: TODO: translate to EnglishÔºàTODO: translate to EnglishÔºâ\n",
    "        if not positions:\n",
    "            positions = self._intelligent_chunking(text)\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        return self._optimize_positions(positions, len(text))\n",
    "    \n",
    "    def _find_by_keywords(self, text: str, keywords: List[str]) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        positions = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if len(keyword) < 3:\n",
    "                continue\n",
    "                \n",
    "            # TODO: translate to English\n",
    "            for match in re.finditer(re.escape(keyword), text, re.IGNORECASE):\n",
    "                positions.append((match.start(), match.end()))\n",
    "            \n",
    "            # TODO: translate to EnglishÔºàProcessingPolishTODO: translate to EnglishÔºâ\n",
    "            if len(keyword) > 4:\n",
    "                root = keyword[:4]\n",
    "                pattern = rf'\\b{re.escape(root)}\\w*\\b'\n",
    "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                    positions.append((match.start(), match.end()))\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _find_by_patterns(self, text: str, patterns: List[str]) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        positions = []\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            try:\n",
    "                # TODO: translate to EnglishProcessing\n",
    "                regex_pattern = pattern.replace('[TODO: translate to English]', r'\\w+').replace('...', r'.*?')\n",
    "                for match in re.finditer(regex_pattern, text, re.IGNORECASE):\n",
    "                    positions.append((match.start(), match.end()))\n",
    "            except re.error:\n",
    "                continue\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _find_by_technique_rules(self, text: str, technique: str) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to EnglishRule-basedTODO: translate to English\"\"\"\n",
    "        positions = []\n",
    "        \n",
    "        if technique == \"Appeal_to_Authority\":\n",
    "            # TODO: translate to English\n",
    "            authority_patterns = [\n",
    "                r'wed≈Çug\\s+\\w+', r'\\w*naukowc\\w*', r'\\w*ekspert\\w*',\n",
    "                r'\\w*badani\\w*', r'profesor\\w*', r'doktor\\w*'\n",
    "            ]\n",
    "            for pattern in authority_patterns:\n",
    "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                    positions.append((match.start(), match.end()))\n",
    "        \n",
    "        elif technique == \"Doubt\":\n",
    "            # TODO: translate to English\n",
    "            doubt_patterns = [\n",
    "                r'\\bczy\\b.*?\\?', r'naprawdƒô.*?\\?', r'wƒÖtpliw\\w*',\n",
    "                r'niepewn\\w*', r'mo≈ºliw\\w*', r'\\?'\n",
    "            ]\n",
    "            for pattern in doubt_patterns:\n",
    "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                    if pattern == r'\\?':\n",
    "                        # TODO: translate to English\n",
    "                        start = max(0, match.start() - 20)\n",
    "                        end = match.end()\n",
    "                    else:\n",
    "                        start = match.start()\n",
    "                        end = match.end()\n",
    "                    positions.append((start, end))\n",
    "        \n",
    "        elif technique == \"Loaded_Language\":\n",
    "            # TODO: translate to English\n",
    "            emotional_words = [\n",
    "                r'skandal', r'szokuj\\w*', r'niesamowit\\w*', r'ekstrem\\w*',\n",
    "                r'tragedi\\w*', r'dramat\\w*', r'katastrofa'\n",
    "            ]\n",
    "            for word in emotional_words:\n",
    "                for match in re.finditer(word, text, re.IGNORECASE):\n",
    "                    positions.append((match.start(), match.end()))\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _fallback_detection(self, text: str, technique: str) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        current_lang = globals().get('LANGUAGE_CODE', 'po')\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        multilingual_keywords = {\n",
    "            \"Appeal_to_Authority\": {\n",
    "                \"po\": [\"wed≈Çug\", \"ekspert\", \"naukowcy\"],\n",
    "                \"ru\": [\"–ø–æ –º–Ω–µ–Ω–∏—é\", \"—ç–∫—Å–ø–µ—Ä—Ç\", \"—É—á–µ–Ω—ã–µ\"], \n",
    "                \"bg\": [\"—Å–ø–æ—Ä–µ–¥\", \"–µ–∫—Å–ø–µ—Ä—Ç\", \"—É—á–µ–Ω–∏\"],\n",
    "                \"sl\": [\"po mnenju\", \"strokovnjak\", \"znanstveniki\"]\n",
    "            },\n",
    "            \"Doubt\": {\n",
    "                \"po\": [\"czy\", \"?\", \"mo≈ºliw\"],\n",
    "                \"ru\": [\"–ª–∏\", \"?\", \"–≤–æ–∑–º–æ–∂–Ω–æ\"],\n",
    "                \"bg\": [\"–ª–∏\", \"?\", \"–≤—ä–∑–º–æ–∂–Ω–æ\"], \n",
    "                \"sl\": [\"ali\", \"?\", \"mogoƒçe\"]\n",
    "            },\n",
    "            \"Loaded_Language\": {\n",
    "                \"po\": [\"skandal\", \"dramat\"],\n",
    "                \"ru\": [\"—Å–∫–∞–Ω–¥–∞–ª\", \"–¥—Ä–∞–º–∞\"],\n",
    "                \"bg\": [\"—Å–∫–∞–Ω–¥–∞–ª\", \"–¥—Ä–∞–º–∞\"],\n",
    "                \"sl\": [\"≈°kandal\", \"drama\"]\n",
    "            },\n",
    "            \"Slogans\": {\n",
    "                \"po\": [\"!\"],\n",
    "                \"ru\": [\"!\"],\n",
    "                \"bg\": [\"!\"],\n",
    "                \"sl\": [\"!\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        technique_keywords = multilingual_keywords.get(technique, {})\n",
    "        keywords = technique_keywords.get(current_lang, [])\n",
    "        \n",
    "        # TODO: translate to EnglishÔºåTODO: translate to EnglishPolish\n",
    "        if not keywords and current_lang != 'po':\n",
    "            keywords = technique_keywords.get('po', [])\n",
    "        \n",
    "        positions = []\n",
    "        for keyword in keywords:\n",
    "            for match in re.finditer(re.escape(keyword), text, re.IGNORECASE):\n",
    "                positions.append((match.start(), match.end()))\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _intelligent_chunking(self, text: str) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if len(text) <= 50:\n",
    "            return [(0, len(text))]\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        positions = []\n",
    "        current_pos = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                sentence_start = text.find(sentence.strip(), current_pos)\n",
    "                if sentence_start >= 0:\n",
    "                    sentence_end = sentence_start + len(sentence.strip())\n",
    "                    positions.append((sentence_start, sentence_end))\n",
    "                    current_pos = sentence_end\n",
    "        \n",
    "        if not positions:\n",
    "            # TODO: translate to English\n",
    "            chunk_size = max(30, len(text) // 3)\n",
    "            for i in range(0, len(text), chunk_size):\n",
    "                positions.append((i, min(i + chunk_size, len(text))))\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _optimize_positions(self, positions: List[Tuple[int, int]], text_length: int) -> List[Tuple[int, int]]:\n",
    "        \"\"\"TODO: translate to English\"\"\"\n",
    "        if not positions:\n",
    "            return [(0, text_length)]\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        positions = list(set(positions))\n",
    "        positions.sort()\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        merged = []\n",
    "        for start, end in positions:\n",
    "            if not merged or start > merged[-1][1] + 3:\n",
    "                merged.append((start, end))\n",
    "            else:\n",
    "                merged[-1] = (merged[-1][0], max(end, merged[-1][1]))\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"TODO: translate to EnglishProcessingTODO: translate to English\"\"\"\n",
    "        stats = {}\n",
    "        for technique, data in self.processing_stats.items():\n",
    "            stats[technique] = ProcessingStats(\n",
    "                technique=technique,\n",
    "                total_processed=data['total'],\n",
    "                successfully_located=data['found'],\n",
    "                avg_positions=data['positions'] / data['found'] if data['found'] > 0 else 0,\n",
    "                avg_confidence=0.8,  # Rule-based methodTODO: translate to Englishconfidence\n",
    "                processing_time=data['time'],\n",
    "                source=\"rule\"\n",
    "            )\n",
    "        return stats\n",
    "\n",
    "print(\"‚úÖ Rule-based methodcharacter-level span localizationTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8: AI methodcharacter-level span localizationTODO: translate to English ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AITODO: translate to Englishcharacter-level span localizationTODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# ü§ñ TODO: translate to EnglishAITODO: translate to Englishcharacter-level span localizationTODO: translate to English\n",
    "\n",
    "class AICharacterLocator:\n",
    "    \"\"\"TODO: translate to EnglishGPT-4o-miniTODO: translate to Englishcharacter-level span localizationTODO: translate to English\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, technique_definitions: Dict[str, TechniqueDefinition], \n",
    "                 debug_mode: bool = True):\n",
    "        if not OPENAI_AVAILABLE:\n",
    "            raise ImportError(\"OpenAI library not installedÔºåTODO: translate to English: pip install openai\")\n",
    "            \n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        self.technique_definitions = technique_definitions\n",
    "        self.debug_mode = debug_mode\n",
    "        self.model = globals().get('AI_MODEL', 'gpt-4o-mini')  # TODO: translate to EnglishConfigTODO: translate to English\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        self.processing_stats = defaultdict(lambda: {\n",
    "            'total': 0, 'found': 0, 'positions': 0, 'time': 0, \n",
    "            'api_calls': 0, 'tokens': 0, 'errors': 0\n",
    "        })\n",
    "        \n",
    "        self.api_stats = {\n",
    "            'total_calls': 0,\n",
    "            'total_tokens': 0,\n",
    "            'total_errors': 0,\n",
    "            'estimated_cost': 0.0\n",
    "        }\n",
    "    \n",
    "    def process_articles(self, articles: List[ArticleData], delay_seconds: float = 0.1) -> List[CharacterResult]:\n",
    "        \"\"\"AI processingArticleTODO: translate to English\"\"\"\n",
    "        print(f\"ü§ñ AITODO: translate to EnglishProcessing...\")\n",
    "        print(f\"   ProcessingArticle: {len(articles)} TODO: translate to English\")\n",
    "        print(f\"   APITODO: translate to English: {delay_seconds} TODO: translate to English\")\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        total_detections = sum(len(article.paragraph_results) for article in articles)\n",
    "        estimated_cost = total_detections * 0.002  # TODO: translate to English\n",
    "        print(f\"   TODO: translate to EnglishAPITODO: translate to English: {total_detections} TODO: translate to English\")\n",
    "        print(f\"   TODO: translate to English: ~${estimated_cost:.2f}\")\n",
    "        \n",
    "        all_results = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, article in enumerate(articles):\n",
    "            if self.debug_mode:\n",
    "                print(f\"\\nüìÑ AI processing {i+1}/{len(articles)}: Article{article.article_id}\")\n",
    "                print(f\"   ArticleTODO: translate to English: {len(article.article_text):,} TODO: translate to English\")\n",
    "                print(f\"   TODO: translate to English: {len(article.paragraph_results)} TODO: translate to English\")\n",
    "            \n",
    "            article_results = self._process_single_article(article, delay_seconds)\n",
    "            all_results.extend(article_results)\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print(f\"   ‚úÖ AITODO: translate to English: {len(article_results)} TODO: translate to English\")\n",
    "                print(f\"   üìä TODO: translate to EnglishAPITODO: translate to English: {self.api_stats['total_calls']} TODO: translate to English\")\n",
    "                print(f\"   üí∞ TODO: translate to English: ${self.api_stats['estimated_cost']:.3f}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüìä AI processingTODO: translate to English:\")\n",
    "        print(f\"   ProcessingTODO: translate to English: {total_time:.2f} TODO: translate to English\")\n",
    "        print(f\"   TODO: translate to English: {len(all_results)} TODO: translate to English\")\n",
    "        print(f\"   APITODO: translate to English: {self.api_stats['total_calls']} TODO: translate to English\")\n",
    "        print(f\"   TokenTODO: translate to English: {self.api_stats['total_tokens']:,}\")\n",
    "        print(f\"   TODO: translate to English: ${self.api_stats['estimated_cost']:.3f}\")\n",
    "        print(f\"   APITODO: translate to English: {self.api_stats['total_errors']} TODO: translate to English\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _process_single_article(self, article: ArticleData, delay_seconds: float) -> List[CharacterResult]:\n",
    "        \"\"\"AI processingTODO: translate to EnglishArticle\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, paragraph_result in enumerate(article.paragraph_results):\n",
    "            technique = paragraph_result.technique\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print(f\"      {i+1:3d}/{len(article.paragraph_results)}: {technique:<25}\", end=\"\")\n",
    "            \n",
    "            self.processing_stats[technique]['total'] += 1\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                positions = self._ai_locate_positions(paragraph_result)\n",
    "                process_time = time.time() - start_time\n",
    "                \n",
    "                self.processing_stats[technique]['time'] += process_time\n",
    "                \n",
    "                if positions:\n",
    "                    self.processing_stats[technique]['found'] += 1\n",
    "                    self.processing_stats[technique]['positions'] += len(positions)\n",
    "                \n",
    "                # TODO: translate to English\n",
    "                for rel_start, rel_end, confidence in positions:\n",
    "                    abs_start = paragraph_result.start + rel_start\n",
    "                    abs_end = paragraph_result.start + rel_end\n",
    "                    \n",
    "                    results.append(CharacterResult(\n",
    "                        article_id=article.article_id,\n",
    "                        technique=technique,\n",
    "                        start=abs_start,\n",
    "                        end=abs_end,\n",
    "                        confidence=confidence,\n",
    "                        source=\"ai\"\n",
    "                    ))\n",
    "                \n",
    "                if self.debug_mode:\n",
    "                    avg_conf = sum(c for _, _, c in positions) / len(positions) if positions else 0\n",
    "                    print(f\" ‚Üí {len(positions):2d}TODO: translate to English (AI, conf:{avg_conf:.2f})\")\n",
    "                \n",
    "                # APITODO: translate to English\n",
    "                if delay_seconds > 0 and i < len(article.paragraph_results) - 1:\n",
    "                    time.sleep(delay_seconds)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.processing_stats[technique]['errors'] += 1\n",
    "                self.api_stats['total_errors'] += 1\n",
    "                \n",
    "                if self.debug_mode:\n",
    "                    print(f\" ‚Üí ‚ùå AITODO: translate to English: {str(e)[:30]}\")\n",
    "                \n",
    "                # TODO: translate to English\n",
    "                fallback_positions = self._fallback_detection(paragraph_result)\n",
    "                for rel_start, rel_end in fallback_positions:\n",
    "                    abs_start = paragraph_result.start + rel_start\n",
    "                    abs_end = paragraph_result.start + rel_end\n",
    "                    \n",
    "                    results.append(CharacterResult(\n",
    "                        article_id=article.article_id,\n",
    "                        technique=technique,\n",
    "                        start=abs_start,\n",
    "                        end=abs_end,\n",
    "                        confidence=0.5,  # TODO: translate to Englishconfidence\n",
    "                        source=\"rule\" \n",
    "                    ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _ai_locate_positions(self, paragraph_result: ParagraphResult) -> List[Tuple[int, int, float]]:\n",
    "        \"\"\"AITODO: translate to English\"\"\"\n",
    "        text = paragraph_result.text_segment\n",
    "        technique = paragraph_result.technique\n",
    "        \n",
    "        # TODO: translate to EnglishAITODO: translate to English\n",
    "        prompt = self._build_ai_prompt(text, technique)\n",
    "        \n",
    "        # TODO: translate to EnglishAI API\n",
    "        self.api_stats['total_calls'] += 1\n",
    "        self.processing_stats[technique]['api_calls'] += 1\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self._get_system_prompt()},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=500,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        # TODO: translate to EnglishtokenTODO: translate to English\n",
    "        if hasattr(response, 'usage'):\n",
    "            tokens = response.usage.total_tokens\n",
    "            self.api_stats['total_tokens'] += tokens\n",
    "            self.processing_stats[technique]['tokens'] += tokens\n",
    "            # GPT-4o-mini TODO: translate to English\n",
    "            self.api_stats['estimated_cost'] += tokens * 0.00015 / 1000\n",
    "        \n",
    "        # TODO: translate to EnglishAITODO: translate to English\n",
    "        ai_response = response.choices[0].message.content\n",
    "        positions = self._parse_ai_response(ai_response, len(text))\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        \"\"\"TODO: translate to EnglishAITODO: translate to English\"\"\"\n",
    "        language_name = globals().get('CURRENT_LANGUAGE_NAME', 'Unknown')\n",
    "        expert_desc = globals().get('CURRENT_EXPERT_DESC', f'{language_name}propaganda technique analysis expert')\n",
    "        \n",
    "        return f\"\"\"TODO: translate to English{expert_desc}„ÄÇTODO: translate to Englishpropaganda techniqueTODO: translate to English{language_name}TODO: translate to English„ÄÇ\n",
    "\n",
    "    TODO: translate to English:\n",
    "    1. TODO: translate to English{language_name}TODO: translate to EnglishÔºåTODO: translate to English\n",
    "    2. TODO: translate to English(TODO: translate to English0TODO: translate to English)\n",
    "    3. TODO: translate to Englishconfidence(0.0-1.0)\n",
    "    4. TODO: translate to EnglishJSONTODO: translate to EnglishÔºåTODO: translate to English\n",
    "\n",
    "    TODO: translate to English:\n",
    "    {{\n",
    "        \"positions\": [\n",
    "            {{\"start\": TODO: translate to English, \"end\": TODO: translate to English, \"confidence\": 0.9, \"text\": \"TODO: translate to English\"}},\n",
    "            {{\"start\": TODO: translate to English, \"end\": TODO: translate to English, \"confidence\": 0.8, \"text\": \"TODO: translate to English\"}}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    TODO: translate to English: {{\"positions\": []}}\"\"\"\n",
    "    \n",
    "    def _build_ai_prompt(self, text: str, technique: str) -> str:\n",
    "        \"\"\"TODO: translate to EnglishAITODO: translate to English\"\"\"\n",
    "        tech_def = self.technique_definitions.get(technique)\n",
    "        \n",
    "        prompt = f\"\"\"TODO: translate to English:\n",
    "\"{text}\"\n",
    "\n",
    "TODO: translate to English: TODO: translate to English \"{technique}\" propaganda techniqueTODO: translate to English„ÄÇ\n",
    "\"\"\"\n",
    "        \n",
    "        if tech_def:\n",
    "            if tech_def.description:\n",
    "                prompt += f\"\\nTODO: translate to English: {tech_def.description[:200]}\"\n",
    "            \n",
    "            if tech_def.detection_criteria:\n",
    "                criteria_text = \"; \".join(tech_def.detection_criteria[:3])\n",
    "                prompt += f\"\\nTODO: translate to English: {criteria_text[:300]}\"\n",
    "            \n",
    "            if tech_def.keywords:\n",
    "                keywords_sample = \", \".join(tech_def.keywords[:6])\n",
    "                prompt += f\"\\nTODO: translate to English: {keywords_sample}\"\n",
    "        \n",
    "        prompt += \"\\n\\nTODO: translate to English:\\n1. TODO: translate to English\\n2. TODO: translate to English\\n3. TODO: translate to Englishconfidence\\n4. TODO: translate to EnglishJSONTODO: translate to English\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _parse_ai_response(self, response: str, text_length: int) -> List[Tuple[int, int, float]]:\n",
    "        \"\"\"TODO: translate to EnglishAITODO: translate to English\"\"\"\n",
    "        positions = []\n",
    "        \n",
    "        try:\n",
    "            # TODO: translate to English\n",
    "            cleaned = response.strip()\n",
    "            if cleaned.startswith(\"```json\"):\n",
    "                cleaned = cleaned.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            \n",
    "            # TODO: translate to EnglishJSON\n",
    "            data = json.loads(cleaned)\n",
    "            \n",
    "            if \"positions\" in data:\n",
    "                for pos in data[\"positions\"]:\n",
    "                    try:\n",
    "                        start = int(pos[\"start\"])\n",
    "                        end = int(pos[\"end\"])\n",
    "                        confidence = float(pos.get(\"confidence\", 0.8))\n",
    "                        \n",
    "                        # TODO: translate to English\n",
    "                        if 0 <= start < end <= text_length:\n",
    "                            positions.append((start, end, confidence))\n",
    "                    except (KeyError, ValueError, TypeError):\n",
    "                        continue\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # TODO: translate to English\n",
    "            patterns = [\n",
    "                r'\"start\":\\s*(\\d+).*?\"end\":\\s*(\\d+)',\n",
    "                r'(\\d+)\\s*[-,]\\s*(\\d+)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, response)\n",
    "                for match in matches:\n",
    "                    try:\n",
    "                        start, end = int(match[0]), int(match[1])\n",
    "                        if 0 <= start < end <= text_length:\n",
    "                            positions.append((start, end, 0.7))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def _fallback_detection(self, paragraph_result: ParagraphResult) -> List[Tuple[int, int]]:\n",
    "        \"\"\"AITODO: translate to English\"\"\"\n",
    "        text = paragraph_result.text_segment\n",
    "        \n",
    "        if len(text) <= 50:\n",
    "            return [(0, len(text))]\n",
    "        else:\n",
    "            # TODO: translate to English\n",
    "            chunk_size = len(text) // 3\n",
    "            return [(0, chunk_size), (chunk_size, chunk_size*2), (chunk_size*2, len(text))]\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"TODO: translate to EnglishAI processingTODO: translate to English\"\"\"\n",
    "        stats = {}\n",
    "        for technique, data in self.processing_stats.items():\n",
    "            avg_confidence = 0.85  # AITODO: translate to Englishconfidence\n",
    "            stats[technique] = ProcessingStats(\n",
    "                technique=technique,\n",
    "                total_processed=data['total'],\n",
    "                successfully_located=data['found'],\n",
    "                avg_positions=data['positions'] / data['found'] if data['found'] > 0 else 0,\n",
    "                avg_confidence=avg_confidence,\n",
    "                processing_time=data['time'],\n",
    "                source=\"ai\"\n",
    "            )\n",
    "        \n",
    "        # TODO: translate to English\n",
    "        stats['_ai_system'] = {\n",
    "            'total_api_calls': self.api_stats['total_calls'],\n",
    "            'total_tokens': self.api_stats['total_tokens'],\n",
    "            'estimated_cost': self.api_stats['estimated_cost'],\n",
    "            'error_rate': self.api_stats['total_errors'] / max(self.api_stats['total_calls'], 1)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "print(\"‚úÖ AITODO: translate to Englishcharacter-level span localizationTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9: TODO: translate to English üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TODO: translate to English\n",
      "   ProcessingArticle: 81 TODO: translate to English\n",
      "   1. Article813452859: 8TODO: translate to English, 2,887TODO: translate to English\n",
      "   2. Article813494037: 25TODO: translate to English, 3,082TODO: translate to English\n",
      "   3. Article813547724: 3TODO: translate to English, 1,811TODO: translate to English\n",
      "   4. Article813552066: 55TODO: translate to English, 7,863TODO: translate to English\n",
      "   5. Article813601978: 9TODO: translate to English, 6,306TODO: translate to English\n",
      "   6. Article813602345: 9TODO: translate to English, 2,824TODO: translate to English\n",
      "   7. Article813603860: 38TODO: translate to English, 5,519TODO: translate to English\n",
      "   8. Article813623212: 15TODO: translate to English, 7,619TODO: translate to English\n",
      "   9. Article813714967: 11TODO: translate to English, 6,362TODO: translate to English\n",
      "   10. Article813949697: 31TODO: translate to English, 11,453TODO: translate to English\n",
      "   11. Article813953273: 72TODO: translate to English, 5,860TODO: translate to English\n",
      "   12. Article813953435: 4TODO: translate to English, 3,765TODO: translate to English\n",
      "   13. Article813992175: 21TODO: translate to English, 3,044TODO: translate to English\n",
      "   14. Article814251296: 1TODO: translate to English, 3,079TODO: translate to English\n",
      "   15. Article814371058: 6TODO: translate to English, 399TODO: translate to English\n",
      "   16. Article814403543: 26TODO: translate to English, 3,633TODO: translate to English\n",
      "   17. Article814403783: 14TODO: translate to English, 3,272TODO: translate to English\n",
      "   18. Article814403875: 1TODO: translate to English, 2,177TODO: translate to English\n",
      "   19. Article814404002: 72TODO: translate to English, 4,707TODO: translate to English\n",
      "   20. Article814427361: 26TODO: translate to English, 6,478TODO: translate to English\n",
      "   21. Article814435435: 20TODO: translate to English, 2,721TODO: translate to English\n",
      "   22. Article814630609: 24TODO: translate to English, 3,763TODO: translate to English\n",
      "   23. Article814777937: 43TODO: translate to English, 5,900TODO: translate to English\n",
      "   24. Article815412286: 17TODO: translate to English, 3,231TODO: translate to English\n",
      "   25. Article815858385: 22TODO: translate to English, 2,988TODO: translate to English\n",
      "   26. Article816460196: 51TODO: translate to English, 6,148TODO: translate to English\n",
      "   27. Article816720060: 41TODO: translate to English, 6,780TODO: translate to English\n",
      "   28. Article817147979: 61TODO: translate to English, 8,038TODO: translate to English\n",
      "   29. Article817176202: 28TODO: translate to English, 4,581TODO: translate to English\n",
      "   30. Article817190270: 38TODO: translate to English, 7,424TODO: translate to English\n",
      "   31. Article817408115: 61TODO: translate to English, 7,424TODO: translate to English\n",
      "   32. Article817449755: 21TODO: translate to English, 4,870TODO: translate to English\n",
      "   33. Article818141325: 1TODO: translate to English, 2,821TODO: translate to English\n",
      "   34. Article820419869: 4TODO: translate to English, 4,823TODO: translate to English\n",
      "   35. Article820791520: 77TODO: translate to English, 12,471TODO: translate to English\n",
      "   36. Article821040551: 2TODO: translate to English, 1,043TODO: translate to English\n",
      "   37. Article821744708: 13TODO: translate to English, 2,700TODO: translate to English\n",
      "   38. Article822220578: 3TODO: translate to English, 5,033TODO: translate to English\n",
      "   39. Article822942601: 50TODO: translate to English, 5,728TODO: translate to English\n",
      "   40. Article824256050: 14TODO: translate to English, 7,666TODO: translate to English\n",
      "   41. Article824350729: 14TODO: translate to English, 2,905TODO: translate to English\n",
      "   42. Article824658990: 21TODO: translate to English, 5,505TODO: translate to English\n",
      "   43. Article824684605: 15TODO: translate to English, 3,853TODO: translate to English\n",
      "   44. Article829267754: 16TODO: translate to English, 7,972TODO: translate to English\n",
      "   45. Article829815104: 12TODO: translate to English, 6,368TODO: translate to English\n",
      "   46. Article830274102: 22TODO: translate to English, 7,722TODO: translate to English\n",
      "   47. Article830359136: 56TODO: translate to English, 3,250TODO: translate to English\n",
      "   48. Article830359423: 45TODO: translate to English, 5,220TODO: translate to English\n",
      "   49. Article830821478: 22TODO: translate to English, 4,864TODO: translate to English\n",
      "   50. Article832918490: 1TODO: translate to English, 1,314TODO: translate to English\n",
      "   51. Article832920387: 2TODO: translate to English, 5,171TODO: translate to English\n",
      "   52. Article832926076: 5TODO: translate to English, 4,960TODO: translate to English\n",
      "   53. Article832931332: 39TODO: translate to English, 5,647TODO: translate to English\n",
      "   54. Article832940138: 9TODO: translate to English, 6,981TODO: translate to English\n",
      "   55. Article832941978: 29TODO: translate to English, 9,712TODO: translate to English\n",
      "   56. Article832947554: 9TODO: translate to English, 1,535TODO: translate to English\n",
      "   57. Article832947600: 5TODO: translate to English, 1,799TODO: translate to English\n",
      "   58. Article832947852: 20TODO: translate to English, 4,371TODO: translate to English\n",
      "   59. Article832948083: 21TODO: translate to English, 9,162TODO: translate to English\n",
      "   60. Article832956618: 4TODO: translate to English, 5,330TODO: translate to English\n",
      "   61. Article832959523: 9TODO: translate to English, 4,871TODO: translate to English\n",
      "   62. Article832971448: 7TODO: translate to English, 10,151TODO: translate to English\n",
      "   63. Article832984694: 20TODO: translate to English, 2,954TODO: translate to English\n",
      "   64. Article833013834: 37TODO: translate to English, 5,108TODO: translate to English\n",
      "   65. Article833018464: 30TODO: translate to English, 4,242TODO: translate to English\n",
      "   66. Article833021113: 2TODO: translate to English, 2,415TODO: translate to English\n",
      "   67. Article833024133: 3TODO: translate to English, 1,831TODO: translate to English\n",
      "   68. Article833024696: 24TODO: translate to English, 4,043TODO: translate to English\n",
      "   69. Article833028146: 20TODO: translate to English, 1,290TODO: translate to English\n",
      "   70. Article833028932: 6TODO: translate to English, 5,096TODO: translate to English\n",
      "   71. Article833032366: 4TODO: translate to English, 2,263TODO: translate to English\n",
      "   72. Article833032367: 16TODO: translate to English, 3,998TODO: translate to English\n",
      "   73. Article833036176: 28TODO: translate to English, 3,008TODO: translate to English\n",
      "   74. Article833036489: 12TODO: translate to English, 2,749TODO: translate to English\n",
      "   75. Article833039623: 135TODO: translate to English, 7,099TODO: translate to English\n",
      "   76. Article833040400: 3TODO: translate to English, 1,976TODO: translate to English\n",
      "   77. Article833041409: 11TODO: translate to English, 2,523TODO: translate to English\n",
      "   78. Article833050243: 17TODO: translate to English, 4,241TODO: translate to English\n",
      "   79. Article833052347: 32TODO: translate to English, 6,305TODO: translate to English\n",
      "   80. Article833053628: 27TODO: translate to English, 10,256TODO: translate to English\n",
      "   81. Article833067493: 3TODO: translate to English, 2,460TODO: translate to English\n",
      "   TODO: translate to English: 1851\n",
      "\n",
      "============================================================\n",
      "üìê TODO: translate to EnglishRule-based method (TODO: translate to English)\n",
      "============================================================\n",
      "üìê Rule-based methodTODO: translate to EnglishProcessing...\n",
      "   ProcessingArticle: 81 TODO: translate to English\n",
      "\n",
      "üìä Rule-based methodProcessingTODO: translate to English:\n",
      "   ProcessingTODO: translate to English: 0.59 TODO: translate to English\n",
      "   TODO: translate to English: 4416 TODO: translate to English\n",
      "   Avg speed: 7531.5 results/sec\n",
      "\n",
      "üìä Rule-based methodTODO: translate to English:\n",
      "   TODO: translate to English: 4416 TODO: translate to English\n",
      "   granularity ratio: 2.39x\n",
      "\n",
      "üèÜ Rule-based methodTODO: translate to English (Top 10):\n",
      "    1. Conversation_Killer       100.0% success rate, 3.0 positions/detection\n",
      "    2. False_Dilemma-No_Choice   100.0% success rate, 3.0 positions/detection\n",
      "    3. Loaded_Language           100.0% success rate, 2.3 positions/detection\n",
      "    4. Straw_Man                 100.0% success rate, 4.3 positions/detection\n",
      "    5. Name_Calling-Labeling     100.0% success rate, 2.8 positions/detection\n",
      "    6. Obfuscation-Vagueness-Confusion 100.0% success rate, 3.7 positions/detection\n",
      "    7. Repetition                100.0% success rate, 1.0 positions/detection\n",
      "    8. Slogans                   100.0% success rate, 1.1 positions/detection\n",
      "    9. Causal_Oversimplification 100.0% success rate, 3.1 positions/detection\n",
      "   10. Doubt                     100.0% success rate, 3.1 positions/detection\n"
     ]
    }
   ],
   "source": [
    "# üîç TODO: translate to English - TODO: translate to EnglishRule-based method\n",
    "\n",
    "if all_articles:\n",
    "    # TODO: translate to EnglishArticle\n",
    "    articles_to_process = all_articles  # ProcessingTODO: translate to EnglishArticle\n",
    "    \n",
    "    print(f\"üîç TODO: translate to English\")\n",
    "    print(f\"   ProcessingArticle: {len(articles_to_process)} TODO: translate to English\")\n",
    "    \n",
    "    # TODO: translate to EnglishArticleTODO: translate to English\n",
    "    for i, article in enumerate(articles_to_process):\n",
    "        print(f\"   {i+1}. Article{article.article_id}: {len(article.paragraph_results)}TODO: translate to English, {len(article.article_text):,}TODO: translate to English\")\n",
    "    \n",
    "    total_debug_detections = sum(len(article.paragraph_results) for article in articles_to_process)\n",
    "    print(f\"   TODO: translate to English: {total_debug_detections}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"üìê TODO: translate to EnglishRule-based method (TODO: translate to English)\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    rule_locator = RuleBasedCharacterLocator(\n",
    "        technique_definitions=technique_definitions,\n",
    "        debug_mode=False\n",
    "    )\n",
    "\n",
    "    rule_results = rule_locator.process_articles(articles_to_process)\n",
    "    \n",
    "    # TODO: translate to EnglishRule-based methodTODO: translate to English\n",
    "    rule_stats = rule_locator.get_stats()\n",
    "    \n",
    "    print(f\"\\nüìä Rule-based methodTODO: translate to English:\")\n",
    "    print(f\"   TODO: translate to English: {len(rule_results)} TODO: translate to English\")\n",
    "    print(f\"   granularity ratio: {len(rule_results)/total_debug_detections:.2f}x\")\n",
    "    \n",
    "    # TODO: translate to English\n",
    "    print(f\"\\nüèÜ Rule-based methodTODO: translate to English (Top 10):\")\n",
    "    sorted_rule_stats = sorted(\n",
    "        [(name, stat) for name, stat in rule_stats.items()],\n",
    "        key=lambda x: x[1].success_rate,\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for i, (technique, stat) in enumerate(sorted_rule_stats[:10]):\n",
    "        print(f\"   {i+1:2d}. {technique:<25} {stat.success_rate:.1%} success rate, {stat.avg_positions:.1f} positions/detection\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå TODO: translate to EnglishArticleTODO: translate to EnglishavailableTODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üß™ TODO: translate to EnglishArticleTODO: translate to English - TODO: translate to EnglishnotebookTODO: translate to English\n",
    "\n",
    "# # TODO: translate to EnglishArticleÔºàTODO: translate to Englisharticle_idÔºâ\n",
    "# TEST_ARTICLE_ID = \"351\"  # TODO: translate to EnglishArticle\n",
    "\n",
    "# print(f\"üß™ TODO: translate to EnglishArticle {TEST_ARTICLE_ID}\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# # 1. TODO: translate to EnglishArticle\n",
    "# test_article = None\n",
    "# for article in all_articles:\n",
    "#     if article.article_id == TEST_ARTICLE_ID:\n",
    "#         test_article = article\n",
    "#         break\n",
    "\n",
    "# if not test_article:\n",
    "#     print(f\"‚ùå TODO: translate to EnglishArticle {TEST_ARTICLE_ID}\")\n",
    "#     print(f\"availableArticle: {[a.article_id for a in all_articles[:5]]}\")\n",
    "# else:\n",
    "#     print(f\"üìÑ ArticleTODO: translate to English:\")\n",
    "#     print(f\"   ID: {test_article.article_id}\")\n",
    "#     print(f\"   TODO: translate to English: {len(test_article.article_text):,} TODO: translate to English\")\n",
    "#     print(f\"   TODO: translate to English: {len(test_article.paragraph_results)} TODO: translate to English\")\n",
    "    \n",
    "#     # TODO: translate to English\n",
    "#     preview = test_article.article_text[:150] + \"...\" if len(test_article.article_text) > 150 else test_article.article_text\n",
    "#     print(f\"   TODO: translate to English: {preview}\")\n",
    "    \n",
    "#     print(\"\\n\" + \"-\"*40)\n",
    "    \n",
    "#     # 2. Rule-based methodTODO: translate to English\n",
    "#     print(\"üìê Rule-based methodTODO: translate to English...\")\n",
    "#     rule_locator = RuleBasedCharacterLocator(\n",
    "#         technique_definitions=technique_definitions,\n",
    "#         debug_mode=False  # TODO: translate to English\n",
    "#     )\n",
    "    \n",
    "#     rule_results = rule_locator.process_articles([test_article])\n",
    "    \n",
    "#     print(f\"   TODO: translate to English: {len(rule_results)} TODO: translate to Englishcharacter-level span localization\")\n",
    "#     print(f\"   confidence: {sum(r.confidence for r in rule_results) / len(rule_results):.3f}\" if rule_results else \"   TODO: translate to English\")\n",
    "    \n",
    "#     # Rule-based methodTODO: translate to English\n",
    "#     if rule_results:\n",
    "#         print(\"   TODO: translate to English (TODO: translate to English2TODO: translate to English):\")\n",
    "#         for i, r in enumerate(rule_results[:2]):\n",
    "#             snippet = test_article.article_text[r.start:r.end][:25] + \"...\"\n",
    "#             print(f\"     {i+1}. {r.technique} [{r.start}:{r.end}] source:{r.source}\")\n",
    "#             print(f\"        \\\"{snippet}\\\"\")\n",
    "    \n",
    "#     print(\"\\n\" + \"-\"*40)\n",
    "    \n",
    "#     # 3. AI methodTODO: translate to English\n",
    "#     if ai_ready:\n",
    "#         print(\"ü§ñ AI methodTODO: translate to English...\")\n",
    "        \n",
    "#         try:\n",
    "#             ai_locator = AICharacterLocator(\n",
    "#                 api_key=OPENAI_API_KEY,\n",
    "#                 technique_definitions=technique_definitions,\n",
    "#                 debug_mode=False\n",
    "#             )\n",
    "            \n",
    "#             cost_estimate = len(test_article.paragraph_results) * 0.002\n",
    "#             print(f\"   TODO: translate to English: ${cost_estimate:.3f}\")\n",
    "            \n",
    "#             ai_results = ai_locator.process_articles([test_article], delay_seconds=1.0)\n",
    "#             ai_stats = ai_locator.get_stats()\n",
    "            \n",
    "#             print(f\"   TODO: translate to English: {len(ai_results)} TODO: translate to Englishcharacter-level span localization\")\n",
    "#             print(f\"   confidence: {sum(r.confidence for r in ai_results) / len(ai_results):.3f}\" if ai_results else \"   TODO: translate to English\")\n",
    "            \n",
    "#             if '_ai_system' in ai_stats:\n",
    "#                 actual_cost = ai_stats['_ai_system'].get('estimated_cost', 0)\n",
    "#                 print(f\"   TODO: translate to English: ${actual_cost:.3f}\")\n",
    "            \n",
    "#             # AI methodTODO: translate to English\n",
    "#             if ai_results:\n",
    "#                 print(\"   TODO: translate to English (TODO: translate to English2TODO: translate to English):\")\n",
    "#                 for i, r in enumerate(ai_results[:2]):\n",
    "#                     snippet = test_article.article_text[r.start:r.end][:25] + \"...\"\n",
    "#                     print(f\"     {i+1}. {r.technique} [{r.start}:{r.end}] source:{r.source}\")\n",
    "#                     print(f\"        \\\"{snippet}\\\"\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"   ‚ùå AITODO: translate to English: {e}\")\n",
    "#             ai_results = []\n",
    "#     else:\n",
    "#         print(\"ü§ñ AI methodTODO: translate to English (TODO: translate to EnglishConfig)\")\n",
    "#         ai_results = []\n",
    "    \n",
    "#     print(\"\\n\" + \"-\"*40)\n",
    "    \n",
    "#     # 4. TODO: translate to English\n",
    "#     print(\"üìä TODO: translate to English:\")\n",
    "#     print(f\"   TODO: translate to English: {len(test_article.paragraph_results)} TODO: translate to English\")\n",
    "#     print(f\"   Rule-basedTODO: translate to English: {len(rule_results)} TODO: translate to English\")\n",
    "#     if ai_results:\n",
    "#         print(f\"   AITODO: translate to English: {len(ai_results)} TODO: translate to English\")\n",
    "#         improvement = (len(ai_results) - len(rule_results)) / len(rule_results) * 100 if len(rule_results) > 0 else 0\n",
    "#         print(f\"   TODO: translate to English: {improvement:+.1f}%\")\n",
    "    \n",
    "#     # 5. üîç TODO: translate to EnglishÔºöSourceTODO: translate to English\n",
    "#     print(f\"\\nüîç SourceTODO: translate to English:\")\n",
    "#     rule_sources = [r.source for r in rule_results]\n",
    "#     print(f\"   Rule-based method: {set(rule_sources)} (TODO: translate to English{len(rule_sources)}TODO: translate to English)\")\n",
    "    \n",
    "#     if ai_results:\n",
    "#         ai_sources = [r.source for r in ai_results]\n",
    "#         print(f\"   AI method: {set(ai_sources)} (TODO: translate to English{len(ai_sources)}TODO: translate to English)\")\n",
    "        \n",
    "#         # TODO: translate to English\n",
    "#         rule_in_ai = sum(1 for s in ai_sources if s == \"rule\")\n",
    "#         if rule_in_ai > 0:\n",
    "#             print(f\"   ‚ö†Ô∏è TODO: translate to English: AITODO: translate to English{rule_in_ai}TODO: translate to English'rule'\")\n",
    "#             print(f\"   üí° TODO: translate to EnglishAITODO: translate to EnglishsourceTODO: translate to English\")\n",
    "#         else:\n",
    "#             print(f\"   ‚úÖ SourceTODO: translate to English\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"üß™ TODO: translate to English\")\n",
    "    \n",
    "#     # TODO: translate to English\n",
    "#     test_rule_results = rule_results\n",
    "#     test_ai_results = ai_results if ai_ready else []\n",
    "    \n",
    "#     print(f\"\\nüí° TODO: translate to English:\")\n",
    "#     print(f\"   test_rule_results: {len(rule_results)} TODO: translate to EnglishRule-basedTODO: translate to English\")\n",
    "#     if ai_ready:\n",
    "#         print(f\"   test_ai_results: {len(ai_results)} TODO: translate to EnglishAITODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ü§ñ TODO: translate to EnglishAI method (TODO: translate to English)\n",
      "============================================================\n",
      "   TODO: translate to EnglishAPITODO: translate to English: 1851 TODO: translate to English\n",
      "   TODO: translate to English: ~$3.70\n",
      "   TODO: translate to English: gpt-4o-mini\n",
      "   üö® TODO: translate to English: 2-3TODO: translate to English (TODO: translate to EnglishAPITODO: translate to English)\n",
      "\n",
      "üîÑ TODO: translate to EnglishAI processing...\n",
      "   TODO: translate to English: 0.1TODO: translate to English\n",
      "ü§ñ AITODO: translate to EnglishProcessing...\n",
      "   ProcessingArticle: 81 TODO: translate to English\n",
      "   APITODO: translate to English: 0.1 TODO: translate to English\n",
      "   TODO: translate to EnglishAPITODO: translate to English: 1851 TODO: translate to English\n",
      "   TODO: translate to English: ~$3.70\n",
      "\n",
      "üìä AI processingTODO: translate to English:\n",
      "   ProcessingTODO: translate to English: 4455.89 TODO: translate to English\n",
      "   TODO: translate to English: 3582 TODO: translate to English\n",
      "   APITODO: translate to English: 1851 TODO: translate to English\n",
      "   TokenTODO: translate to English: 958,343\n",
      "   TODO: translate to English: $0.144\n",
      "   APITODO: translate to English: 0 TODO: translate to English\n",
      "\n",
      "üìä AI methodTODO: translate to English:\n",
      "   TODO: translate to English: 3582 TODO: translate to English\n",
      "   granularity ratio: 1.94x\n",
      "   APITODO: translate to English: 1851 TODO: translate to English\n",
      "   TokenTODO: translate to English: 958,343\n",
      "   TODO: translate to English: $0.144\n",
      "   TODO: translate to English: 0.0%\n",
      "\n",
      "üèÜ AI methodTODO: translate to English (Top 10):\n",
      "    1. Conversation_Killer       100.0% success rate, 2.8 positions/detection\n",
      "    2. Obfuscation-Vagueness-Confusion 100.0% success rate, 1.5 positions/detection\n",
      "    3. Appeal_to_Hypocrisy       100.0% success rate, 1.2 positions/detection\n",
      "    4. Whataboutism              100.0% success rate, 1.0 positions/detection\n",
      "    5. Loaded_Language           99.7% success rate, 2.9 positions/detection\n",
      "    6. Appeal_to_Fear-Prejudice  99.3% success rate, 2.1 positions/detection\n",
      "    7. Appeal_to_Authority       97.7% success rate, 1.1 positions/detection\n",
      "    8. False_Dilemma-No_Choice   95.9% success rate, 1.2 positions/detection\n",
      "    9. Doubt                     94.9% success rate, 2.2 positions/detection\n",
      "   10. Guilt_by_Association      89.1% success rate, 1.5 positions/detection\n"
     ]
    }
   ],
   "source": [
    "# ü§ñ TODO: translate to English - AI method (TODO: translate to English)\n",
    "\n",
    "# TODO: translate to EnglishAITODO: translate to Englishavailable\n",
    "if ai_ready and 'articles_to_process' in locals():\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"ü§ñ TODO: translate to EnglishAI method (TODO: translate to English)\")\n",
    "    print(f\"=\"*60)\n",
    "\n",
    "    # TODO: translate to English\n",
    "    total_detections = sum(len(article.paragraph_results) for article in articles_to_process)\n",
    "\n",
    "    print(f\"   TODO: translate to EnglishAPITODO: translate to English: {total_detections} TODO: translate to English\")\n",
    "    print(f\"   TODO: translate to English: ~${total_detections * 0.002:.2f}\")\n",
    "    print(f\"   TODO: translate to English: {globals().get('AI_MODEL', 'gpt-4o-mini')}\")\n",
    "    print(f\"   üö® TODO: translate to English: 2-3TODO: translate to English (TODO: translate to EnglishAPITODO: translate to English)\")\n",
    "    \n",
    "    # TODO: translate to EnglishAI processingÔºàTODO: translate to EnglishÔºâ\n",
    "    print(f\"\\nüîÑ TODO: translate to EnglishAI processing...\")\n",
    "    \n",
    "    try:\n",
    "        # TODO: translate to EnglishAITODO: translate to English\n",
    "        ai_locator = AICharacterLocator(\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            technique_definitions=technique_definitions,\n",
    "            debug_mode=False\n",
    "        )\n",
    "        \n",
    "        # TODO: translate to EnglishAPITODO: translate to English\n",
    "        safe_delay = max(AI_DELAY_SECONDS, 0.1)  # TODO: translate to English2TODO: translate to English\n",
    "        print(f\"   TODO: translate to English: {safe_delay}TODO: translate to English\")\n",
    "        \n",
    "        # TODO: translate to EnglishAI method\n",
    "        ai_results = ai_locator.process_articles(\n",
    "            articles_to_process,\n",
    "            delay_seconds=AI_DELAY_SECONDS\n",
    "        )\n",
    "        \n",
    "        # TODO: translate to EnglishAITODO: translate to English\n",
    "        ai_stats = ai_locator.get_stats()\n",
    "        \n",
    "        print(f\"\\nüìä AI methodTODO: translate to English:\")\n",
    "        print(f\"   TODO: translate to English: {len(ai_results)} TODO: translate to English\")\n",
    "        if total_debug_detections > 0:\n",
    "            print(f\"   granularity ratio: {len(ai_results)/total_debug_detections:.2f}x\")\n",
    "        \n",
    "        # AITODO: translate to English\n",
    "        if '_ai_system' in ai_stats:\n",
    "            sys_stats = ai_stats['_ai_system']\n",
    "            print(f\"   APITODO: translate to English: {sys_stats['total_api_calls']} TODO: translate to English\")\n",
    "            print(f\"   TokenTODO: translate to English: {sys_stats['total_tokens']:,}\")\n",
    "            print(f\"   TODO: translate to English: ${sys_stats['estimated_cost']:.3f}\")\n",
    "            print(f\"   TODO: translate to English: {sys_stats['error_rate']:.1%}\")\n",
    "        \n",
    "        # TODO: translate to EnglishAITODO: translate to English\n",
    "        print(f\"\\nüèÜ AI methodTODO: translate to English (Top 10):\")\n",
    "        tech_stats = [(name, stat) for name, stat in ai_stats.items() if name != '_ai_system']\n",
    "        sorted_ai_stats = sorted(tech_stats, key=lambda x: x[1].success_rate, reverse=True)\n",
    "        \n",
    "        for i, (technique, stat) in enumerate(sorted_ai_stats[:10]):\n",
    "            print(f\"   {i+1:2d}. {technique:<25} {stat.success_rate:.1%} success rate, {stat.avg_positions:.1f} positions/detection\")\n",
    "        \n",
    "        ai_method_available = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå AI methodTODO: translate to English: {e}\")\n",
    "        print(f\"üí° TODO: translate to English:\")\n",
    "        print(f\"   1. TODO: translate to EnglishAPITODO: translate to English\")\n",
    "        print(f\"   2. TODO: translate to EnglishÔºàAPITODO: translate to EnglishÔºâ\")\n",
    "        print(f\"   3. TODO: translate to English3-5TODO: translate to English\")\n",
    "        print(f\"   4. TODO: translate to EnglishRule-based methodTODO: translate to EnglishProcessing\")\n",
    "        ai_method_available = False\n",
    "        \n",
    "else:\n",
    "    if not ai_ready:\n",
    "        print(f\"\\n‚ö†Ô∏è AI methodTODO: translate to Englishavailable: TODO: translate to EnglishAPITODO: translate to EnglishConfig\")\n",
    "    ai_method_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ TODO: translate to English...\n",
      "   ‚úÖ Rule-basedTODO: translate to English: 4416TODO: translate to English ‚Üí your_checkthat_data_directory/debug_results/en_voting_aggressiv_all_rule_results.tsv\n",
      "   ‚úÖ AITODO: translate to English: 3582TODO: translate to English ‚Üí your_checkthat_data_directory/debug_results/en_voting_aggressiv_all_ai_results.tsv\n",
      "   ‚úÖ TODO: translate to English: 7998TODO: translate to English ‚Üí your_checkthat_data_directory/debug_results/en_voting_aggressiv_all_combined_results.tsv\n",
      "   ‚úÖ TODO: translate to English: your_checkthat_data_directory/debug_results/debug_analysis.json\n",
      "   ‚úÖ TODO: translate to English: your_checkthat_data_directory/debug_results/DEBUG_SUMMARY.md\n",
      "\n",
      "üìÅ TODO: translate to English:\n",
      "   TODO: translate to English: your_checkthat_data_directory/debug_results\n",
      "   TODO: translate to English: 5\n",
      "   ‚úÖ TODO: translate to EnglishÔºåTODO: translate to English\n"
     ]
    }
   ],
   "source": [
    "# üíæ TODO: translate to English\n",
    "\n",
    "\n",
    "if 'rule_results' in locals():\n",
    "    print(f\"üíæ TODO: translate to English...\")\n",
    "    \n",
    "    debug_output_dir = os.path.join(OUTPUT_DIR, \"debug_results\")\n",
    "    os.makedirs(debug_output_dir, exist_ok=True)\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    # 1. TODO: translate to EnglishRule-based methodTODO: translate to English\n",
    "    rule_results_file = os.path.join(debug_output_dir, f\"{LANGUAGE_CODE}_{ORIGINAL_MODE}_all_rule_results.tsv\")\n",
    "    with open(rule_results_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"article_id\\ttechnique\\tstart\\tend\\tconfidence\\tsource\\n\")\n",
    "        for result in rule_results:\n",
    "            f.write(f\"{result.article_id}\\t{result.technique}\\t{result.start}\\t{result.end}\\t{result.confidence:.3f}\\t{result.source}\\n\")\n",
    "    \n",
    "    saved_files.append(rule_results_file)\n",
    "    print(f\"   ‚úÖ Rule-basedTODO: translate to English: {len(rule_results)}TODO: translate to English ‚Üí {rule_results_file}\")\n",
    "    \n",
    "    # 2. TODO: translate to EnglishAI methodTODO: translate to English (TODO: translate to English)\n",
    "    if 'ai_results' in locals():\n",
    "        ai_results_file = os.path.join(debug_output_dir, f\"{LANGUAGE_CODE}_{ORIGINAL_MODE}_all_ai_results.tsv\")\n",
    "        with open(ai_results_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"article_id\\ttechnique\\tstart\\tend\\tconfidence\\tsource\\n\")\n",
    "            for result in ai_results:\n",
    "                f.write(f\"{result.article_id}\\t{result.technique}\\t{result.start}\\t{result.end}\\t{result.confidence:.3f}\\t{result.source}\\n\")\n",
    "        \n",
    "        saved_files.append(ai_results_file)\n",
    "        print(f\"   ‚úÖ AITODO: translate to English: {len(ai_results)}TODO: translate to English ‚Üí {ai_results_file}\")\n",
    "        \n",
    "        # 3. TODO: translate to English\n",
    "        combined_results = rule_results + ai_results\n",
    "        combined_file = os.path.join(debug_output_dir, f\"{LANGUAGE_CODE}_{ORIGINAL_MODE}_all_combined_results.tsv\")\n",
    "        with open(combined_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"article_id\\ttechnique\\tstart\\tend\\tconfidence\\tsource\\n\")\n",
    "            for result in combined_results:\n",
    "                f.write(f\"{result.article_id}\\t{result.technique}\\t{result.start}\\t{result.end}\\t{result.confidence:.3f}\\t{result.source}\\n\")\n",
    "        \n",
    "        saved_files.append(combined_file)\n",
    "        print(f\"   ‚úÖ TODO: translate to English: {len(combined_results)}TODO: translate to English ‚Üí {combined_file}\")\n",
    "    \n",
    "    # 4. TODO: translate to English\n",
    "    analysis_data = {\n",
    "        \"debug_summary\": {\n",
    "            \"articles_processed\": len(articles_to_process),\n",
    "            \"total_detections\": total_debug_detections,\n",
    "            \"rule_results\": len(rule_results),\n",
    "            \"ai_results\": len(ai_results) if 'ai_results' in locals() else 0,\n",
    "            \"processing_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        },\n",
    "        \"rule_method_stats\": {\n",
    "            name: {\n",
    "                \"total_processed\": stat.total_processed,\n",
    "                \"success_rate\": stat.success_rate,\n",
    "                \"avg_positions\": stat.avg_positions,\n",
    "                \"avg_confidence\": stat.avg_confidence\n",
    "            }\n",
    "            for name, stat in rule_stats.items()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if 'ai_results' in locals():\n",
    "        analysis_data[\"ai_method_stats\"] = {\n",
    "            name: {\n",
    "                \"total_processed\": stat.total_processed,\n",
    "                \"success_rate\": stat.success_rate,\n",
    "                \"avg_positions\": stat.avg_positions,\n",
    "                \"avg_confidence\": stat.avg_confidence\n",
    "            }\n",
    "            for name, stat in ai_stats.items() if name != '_ai_system'\n",
    "        }\n",
    "        \n",
    "        if '_ai_system' in ai_stats:\n",
    "            analysis_data[\"ai_system_stats\"] = ai_stats['_ai_system']\n",
    "    \n",
    "    analysis_file = os.path.join(debug_output_dir, \"debug_analysis.json\")\n",
    "    with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(analysis_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    saved_files.append(analysis_file)\n",
    "    print(f\"   ‚úÖ TODO: translate to English: {analysis_file}\")\n",
    "    \n",
    "    # 5. TODO: translate to English\n",
    "    summary_file = os.path.join(debug_output_dir, \"DEBUG_SUMMARY.md\")\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# TODO: translate to EnglishProcessingTODO: translate to English\\n\\n\")\n",
    "        f.write(f\"## TODO: translate to English\\n\")\n",
    "        f.write(f\"- ProcessingTODO: translate to English: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"- ProcessingArticle: {len(articles_to_process)} TODO: translate to English\\n\")\n",
    "        f.write(f\"- TODO: translate to English: {total_debug_detections} TODO: translate to English\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## ProcessingTODO: translate to English\\n\")\n",
    "        f.write(f\"- Rule-based method: {len(rule_results)} TODO: translate to English\\n\")\n",
    "        if 'ai_results' in locals():\n",
    "            f.write(f\"- AI method: {len(ai_results)} TODO: translate to English\\n\")\n",
    "            f.write(f\"- AITODO: translate to English: ${ai_stats['_ai_system']['estimated_cost']:.3f}\\n\")\n",
    "        f.write(f\"\\n## TODO: translate to English\\n\")\n",
    "        for i, file_path in enumerate(saved_files, 1):\n",
    "            f.write(f\"{i}. {os.path.basename(file_path)}\\n\")\n",
    "    \n",
    "    saved_files.append(summary_file)\n",
    "    print(f\"   ‚úÖ TODO: translate to English: {summary_file}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ TODO: translate to English:\")\n",
    "    print(f\"   TODO: translate to English: {debug_output_dir}\")\n",
    "    print(f\"   TODO: translate to English: {len(saved_files)}\")\n",
    "    print(f\"   ‚úÖ TODO: translate to EnglishÔºåTODO: translate to English\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå TODO: translate to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}